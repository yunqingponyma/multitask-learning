{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c792c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "from tensorflow.keras import optimizers,initializers\n",
    "from tensorflow.python.keras.initializers import glorot_normal\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "05bd56d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1da42",
   "metadata": {},
   "source": [
    "https://github.com/ShowMeAI-Hub/multi-task-learning/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3eecdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = pd.read_excel('D:/OneDrive - University of South Carolina/Research/multitasking learning/data cleaning/DHEC_tests_final_lag1.xlsx', sheet_name='Sheet1', engine='openpyxl')\n",
    "variables = pd.read_excel(\"D:/OneDrive - University of South Carolina/Research/multitasking learning/data cleaning/0130variables-VSVBVR.xlsx\", sheet_name='Sheet1', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94c9b0",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f839512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VS</th>\n",
       "      <th>VR</th>\n",
       "      <th>VB</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "      <th>region</th>\n",
       "      <th>CD4_baseline</th>\n",
       "      <th>VL_baseline_interpretation</th>\n",
       "      <th>VL_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>=</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40279 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  VS  VR  VB  dx_yr  \\\n",
       "0                591.000000                       2   0   0   0   2005   \n",
       "1               1018.000000                       3   0   0   0   2005   \n",
       "2               2072.250000                       6   1   0   0   2005   \n",
       "3               2495.333333                       7   1   0   0   2005   \n",
       "4               2793.333333                       8   1   0   0   2005   \n",
       "...                     ...                     ...  ..  ..  ..    ...   \n",
       "40274           2737.500000                       8   1   0   0   2009   \n",
       "40275           3193.000000                       9   1   0   0   2009   \n",
       "40276           3499.666667                      10   1   0   0   2009   \n",
       "40277           3884.000000                      11   1   0   0   2009   \n",
       "40278            755.000000                       2   0   1   0   2016   \n",
       "\n",
       "       dx_mth  age sex   race    risk region  CD4_baseline  \\\n",
       "0          12   39   F  Black  Others  Urban         401.0   \n",
       "1          12   39   F  Black  Others  Urban         401.0   \n",
       "2          12   39   F  Black  Others  Urban         401.0   \n",
       "3          12   39   F  Black  Others  Urban         401.0   \n",
       "4          12   39   F  Black  Others  Urban         401.0   \n",
       "...       ...  ...  ..    ...     ...    ...           ...   \n",
       "40274       9   48   M  Black     MSM  Urban         414.0   \n",
       "40275       9   48   M  Black     MSM  Urban         414.0   \n",
       "40276       9   48   M  Black     MSM  Urban         414.0   \n",
       "40277       9   48   M  Black     MSM  Urban         414.0   \n",
       "40278      11   21   M  Black     MSM  Urban        1012.0   \n",
       "\n",
       "      VL_baseline_interpretation  VL_baseline  \n",
       "0                              =     160288.0  \n",
       "1                              =     160288.0  \n",
       "2                              =     160288.0  \n",
       "3                              =     160288.0  \n",
       "4                              =     160288.0  \n",
       "...                          ...          ...  \n",
       "40274                          =      15127.0  \n",
       "40275                          =      15127.0  \n",
       "40276                          =      15127.0  \n",
       "40277                          =      15127.0  \n",
       "40278                          =        200.0  \n",
       "\n",
       "[40279 rows x 15 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = variables[variables['model1'] != 'delete']\n",
    "data = data_origin[temp['variables'].tolist()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7bfc2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = variables[variables['model1'] == 'outcome']['variables'].tolist()\n",
    "sparse_features = variables[variables['model1'] == 'cat']['variables'].tolist()\n",
    "dense_features = variables[variables['model1'] == 'num']['variables'].tolist()\n",
    "varlen_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d480ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VS', 'VR', 'VB']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8b174052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_40004\\2408031544.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n"
     ]
    }
   ],
   "source": [
    "encoder = {}\n",
    "# 稀疏特征编码\n",
    "for featid in sparse_features:\n",
    "    # print(f\"编码ID字段：{featid}\")\n",
    "    encoder[featid] = {uid:ucode+1 for ucode,uid in enumerate(data[featid].unique())} \n",
    "    data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n",
    "    \n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cfd1dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(data.shape[0] * 0.6)\n",
    "n_val = round(data.shape[0] * 0.2)\n",
    "\n",
    "train = data[:n_train]\n",
    "val = data[n_train:(n_train+n_val)]\n",
    "test = data[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f218a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "test_labels = [test[y].values for y in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba174a2d",
   "metadata": {},
   "source": [
    "### Seperate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dba16a",
   "metadata": {},
   "source": [
    "#### VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "617d0be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32223, 12)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VS\"]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d7f03d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_distribution(y):\n",
    "    class_counts = pd.Series(y).value_counts(normalize=True)  # 计算比例\n",
    "    print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04318061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.714893\n",
      "0    0.285107\n",
      "Name: VS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "check_class_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "662017cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "232a5a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "      <th>region</th>\n",
       "      <th>CD4_baseline</th>\n",
       "      <th>VL_baseline_interpretation</th>\n",
       "      <th>VL_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46067</th>\n",
       "      <td>3289.496781</td>\n",
       "      <td>8</td>\n",
       "      <td>2010</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>103.579503</td>\n",
       "      <td>1</td>\n",
       "      <td>18327.528528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46068</th>\n",
       "      <td>584.955121</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1124.299176</td>\n",
       "      <td>1</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46069</th>\n",
       "      <td>3634.435072</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>116.403422</td>\n",
       "      <td>1</td>\n",
       "      <td>186215.368465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46070</th>\n",
       "      <td>786.515509</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1004.639387</td>\n",
       "      <td>1</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46071</th>\n",
       "      <td>2681.900607</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>334.169958</td>\n",
       "      <td>1</td>\n",
       "      <td>21838.428703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46072 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  dx_yr  dx_mth  age  sex  \\\n",
       "0                591.000000                       2   2005      12   39    1   \n",
       "1               1018.000000                       3   2005      12   39    1   \n",
       "2               2072.250000                       6   2005      12   39    1   \n",
       "3               2495.333333                       7   2005      12   39    1   \n",
       "4               2793.333333                       8   2005      12   39    1   \n",
       "...                     ...                     ...    ...     ...  ...  ...   \n",
       "46067           3289.496781                       8   2010      11   24    1   \n",
       "46068            584.955121                       2   2006       5   36    1   \n",
       "46069           3634.435072                       8   2007       7   35    2   \n",
       "46070            786.515509                       2   2011       9   24    1   \n",
       "46071           2681.900607                       8   2011       2   31    1   \n",
       "\n",
       "       race  risk  region  CD4_baseline  VL_baseline_interpretation  \\\n",
       "0         1     1       1    401.000000                           1   \n",
       "1         1     1       1    401.000000                           1   \n",
       "2         1     1       1    401.000000                           1   \n",
       "3         1     1       1    401.000000                           1   \n",
       "4         1     1       1    401.000000                           1   \n",
       "...     ...   ...     ...           ...                         ...   \n",
       "46067     1     2       1    103.579503                           1   \n",
       "46068     1     2       1   1124.299176                           1   \n",
       "46069     1     2       1    116.403422                           1   \n",
       "46070     1     1       1   1004.639387                           1   \n",
       "46071     1     2       1    334.169958                           1   \n",
       "\n",
       "         VL_baseline  \n",
       "0      160288.000000  \n",
       "1      160288.000000  \n",
       "2      160288.000000  \n",
       "3      160288.000000  \n",
       "4      160288.000000  \n",
       "...              ...  \n",
       "46067   18327.528528  \n",
       "46068     200.000000  \n",
       "46069  186215.368465  \n",
       "46070     200.000000  \n",
       "46071   21838.428703  \n",
       "\n",
       "[46072 rows x 12 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db144e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,473\n",
      "Trainable params: 17,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=focal_loss(alpha=0.25, gamma=2),\n",
    "              metrics=['AUC'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e0cb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 1s 9ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3432 - auc: 0.5000 - val_loss: 4.0295 - val_auc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_resampled.to_numpy(), np.array(y_resampled), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4c22cac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13586709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7602228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2fcb92c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VL_interpretation</th>\n",
       "      <th>VL</th>\n",
       "      <th>Months_to_ini_VS</th>\n",
       "      <th>VR_N</th>\n",
       "      <th>VR_size</th>\n",
       "      <th>prop_time</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32223</th>\n",
       "      <td>3510.333333</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900985</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32224</th>\n",
       "      <td>3894.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909405</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32225</th>\n",
       "      <td>4198.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915052</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32226</th>\n",
       "      <td>590.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>19.677778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524486</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32227</th>\n",
       "      <td>967.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>19.677778</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675868</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885198</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.898272</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.907792</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915576</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8056 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  VL_interpretation     VL  \\\n",
       "32223           3510.333333                      10                  2  200.0   \n",
       "32224           3894.000000                      11                  2  200.0   \n",
       "32225           4198.500000                      12                  2  200.0   \n",
       "32226            590.333333                       2                  2  200.0   \n",
       "32227            967.000000                       3                  2  200.0   \n",
       "...                     ...                     ...                ...    ...   \n",
       "40274           2737.500000                       8                  2  200.0   \n",
       "40275           3193.000000                       9                  2  200.0   \n",
       "40276           3499.666667                      10                  2  200.0   \n",
       "40277           3884.000000                      11                  2  200.0   \n",
       "40278            755.000000                       2                  1  200.0   \n",
       "\n",
       "       Months_to_ini_VS  VR_N  VR_size  prop_time  dx_yr  dx_mth  ...  \\\n",
       "32223         18.966667     0        1   0.900985   2009       4  ...   \n",
       "32224         18.966667     0        1   0.909405   2009       4  ...   \n",
       "32225         18.966667     0        1   0.915052   2009       4  ...   \n",
       "32226         19.677778     0        1   0.524486   2008       4  ...   \n",
       "32227         19.677778     0        1   0.675868   2008       4  ...   \n",
       "...                 ...   ...      ...        ...    ...     ...  ...   \n",
       "40274         17.616667     0        1   0.885198   2009       9  ...   \n",
       "40275         17.616667     0        1   0.898272   2009       9  ...   \n",
       "40276         17.616667     0        1   0.907792   2009       9  ...   \n",
       "40277         17.616667     0        1   0.915576   2009       9  ...   \n",
       "40278          5.150000     1        4   1.000000   2016      11  ...   \n",
       "\n",
       "       msld.cum_1  metacanc.cum_1  aids.cum_1  Depression_1  Anxiety_1  \\\n",
       "32223         0.0             0.0         0.0             1          1   \n",
       "32224         0.0             0.0         0.0             1          1   \n",
       "32225         0.0             0.0         0.0             1          1   \n",
       "32226         0.0             0.0         0.0             1          1   \n",
       "32227         0.0             0.0         0.0             1          1   \n",
       "...           ...             ...         ...           ...        ...   \n",
       "40274         0.0             0.0         0.0             1          1   \n",
       "40275         0.0             0.0         0.0             1          1   \n",
       "40276         0.0             0.0         0.0             1          1   \n",
       "40277         0.0             0.0         0.0             1          1   \n",
       "40278         0.0             0.0         0.0             1          1   \n",
       "\n",
       "       Psychiatric_disorder_1  Alcohol_use_1  Tobacco_use_1  \\\n",
       "32223                       1              1              1   \n",
       "32224                       1              1              1   \n",
       "32225                       1              1              1   \n",
       "32226                       1              1              1   \n",
       "32227                       1              1              1   \n",
       "...                       ...            ...            ...   \n",
       "40274                       1              1              1   \n",
       "40275                       1              1              1   \n",
       "40276                       1              1              1   \n",
       "40277                       1              1              1   \n",
       "40278                       1              1              1   \n",
       "\n",
       "       Illicit_drug_use_1  visits_1  \n",
       "32223                   1         3  \n",
       "32224                   1         6  \n",
       "32225                   1         4  \n",
       "32226                   1        10  \n",
       "32227                   1         6  \n",
       "...                   ...       ...  \n",
       "40274                   1         3  \n",
       "40275                   1         8  \n",
       "40276                   1         3  \n",
       "40277                   1         6  \n",
       "40278                   1         4  \n",
       "\n",
       "[8056 rows x 121 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fd26e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.4916\n",
      "Logistic Regression AUC: 0.5348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "log_reg = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train.to_numpy(), np.array(y_train))\n",
    "\n",
    "# 在测试集上进行预测\n",
    "log_pred_prob = log_reg.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
    "log_pred = (log_pred_prob > 0.5).astype(int)  # 转换为二分类预测\n",
    "\n",
    "# 计算 Accuracy 和 AUC\n",
    "log_accuracy = accuracy_score(test_labels[0], log_pred)\n",
    "log_auc = roc_auc_score(test_labels[0], log_pred_prob)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression AUC: {log_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9adec",
   "metadata": {},
   "source": [
    "#### VB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c242d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1b0289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,473\n",
      "Trainable params: 17,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d023f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1743.3679 - auc: 0.5050 - val_loss: 1238.1223 - val_auc: 0.5000\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 745.6780 - auc: 0.5038 - val_loss: 26429.3477 - val_auc: 0.5037\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 5984.8154 - auc: 0.5023 - val_loss: 1283.3124 - val_auc: 0.5000\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1488.8557 - auc: 0.4987 - val_loss: 215.5039 - val_auc: 0.5034\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1285.7673 - auc: 0.5050 - val_loss: 740.1873 - val_auc: 0.5000\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2491.4844 - auc: 0.4989 - val_loss: 255.0821 - val_auc: 0.5000\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1055.2250 - auc: 0.5208 - val_loss: 819.9633 - val_auc: 0.4994\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2493.6108 - auc: 0.4944 - val_loss: 277.5213 - val_auc: 0.5000\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 692.5271 - auc: 0.4922 - val_loss: 20041.5645 - val_auc: 0.5130\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1871.6451 - auc: 0.5116 - val_loss: 198.7493 - val_auc: 0.5000\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 999.8830 - auc: 0.5233 - val_loss: 717.8082 - val_auc: 0.5000\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2335.0771 - auc: 0.5012 - val_loss: 571.2230 - val_auc: 0.5053\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1562.0638 - auc: 0.4905 - val_loss: 391.2473 - val_auc: 0.5000\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2149.0713 - auc: 0.5048 - val_loss: 187.5965 - val_auc: 0.5000\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 1519.6642 - auc: 0.4999 - val_loss: 95.6150 - val_auc: 0.5068\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 682.0923 - auc: 0.4895 - val_loss: 1083.3481 - val_auc: 0.5000\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 2339.5715 - auc: 0.4992 - val_loss: 18.3635 - val_auc: 0.5000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 917.6601 - auc: 0.5060 - val_loss: 690.3449 - val_auc: 0.5000\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2612.1375 - auc: 0.4999 - val_loss: 383.5319 - val_auc: 0.5030\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 10804.7715 - auc: 0.5008 - val_loss: 765.8541 - val_auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94d64e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0246d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046673286991063\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac445d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303642cc",
   "metadata": {},
   "source": [
    "#### VR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cac6bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e795e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,473\n",
      "Trainable params: 17,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d851364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 1065.0470 - auc: 0.5037 - val_loss: 404.3300 - val_auc: 0.4885\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 303.3209 - auc: 0.5061 - val_loss: 967.5033 - val_auc: 0.5144\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 3358.1228 - auc: 0.5046 - val_loss: 15368.1416 - val_auc: 0.5000\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1905.2600 - auc: 0.4971 - val_loss: 9672.7422 - val_auc: 0.5000\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 1279.3486 - auc: 0.4968 - val_loss: 4514.6592 - val_auc: 0.5000\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 595.0134 - auc: 0.4947 - val_loss: 182.9757 - val_auc: 0.5014\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 2675.8789 - auc: 0.5002 - val_loss: 10419.4785 - val_auc: 0.5000\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1046.3134 - auc: 0.5018 - val_loss: 1279.1477 - val_auc: 0.5000\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 418.4075 - auc: 0.5055 - val_loss: 1774.8921 - val_auc: 0.5050\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 217.8707 - auc: 0.5077 - val_loss: 1285.5336 - val_auc: 0.4999\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 293.2547 - auc: 0.5019 - val_loss: 476.7087 - val_auc: 0.5068\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 145.6201 - auc: 0.5152 - val_loss: 85.5368 - val_auc: 0.5370\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 93.1873 - auc: 0.5209 - val_loss: 166.9306 - val_auc: 0.5515\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 239.8900 - auc: 0.5097 - val_loss: 585.8516 - val_auc: 0.5006\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 173.3250 - auc: 0.5106 - val_loss: 154.6578 - val_auc: 0.5425\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 247.3038 - auc: 0.5163 - val_loss: 494.4245 - val_auc: 0.5000\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 117.9354 - auc: 0.5114 - val_loss: 2584.9170 - val_auc: 0.5190\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 626.9828 - auc: 0.5100 - val_loss: 7759.9131 - val_auc: 0.5000\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1448.8701 - auc: 0.4977 - val_loss: 527.7059 - val_auc: 0.4919\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 264.2806 - auc: 0.5033 - val_loss: 2466.2141 - val_auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0b628ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.8340146e-28]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "feefc934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046673286991063\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "992c3efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5145067591131541\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8333b",
   "metadata": {},
   "source": [
    "### MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c3b041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers\n",
    "\n",
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc8e3317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 64)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 64)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 64)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 327)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 64)           20992       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 128)          8320        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           8256        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer (MmoeLayer)          [(None, 32), (None,  13650       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            33          mmoe_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "VR (Dense)                      (None, 1)            33          mmoe_layer[0][1]                 \n",
      "__________________________________________________________________________________________________\n",
      "VB (Dense)                      (None, 1)            33          mmoe_layer[0][2]                 \n",
      "==================================================================================================\n",
      "Total params: 52,533\n",
      "Trainable params: 52,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_mmoe(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 32,\n",
    "          n_task = 3,n_expert = 6,varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "          dnn_hidden_units = (64,128,64),target = target,dnn_reg_l2 = 0.001,drop_rate = 0.1)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"AUC\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6cd34b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 5s 74ms/step - loss: 3463.0479 - VS_loss: 1225.5150 - VR_loss: 533.1174 - VB_loss: 1704.1809 - VS_auc: 0.4963 - VR_auc_1: 0.4968 - VB_auc_2: 0.5020 - val_loss: 894.4553 - val_VS_loss: 768.9643 - val_VR_loss: 88.5228 - val_VB_loss: 36.7463 - val_VS_auc: 0.5048 - val_VR_auc_1: 0.5023 - val_VB_auc_2: 0.4887\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 487.3417 - VS_loss: 144.0578 - VR_loss: 42.3614 - VB_loss: 300.7110 - VS_auc: 0.5018 - VR_auc_1: 0.4948 - VB_auc_2: 0.5027 - val_loss: 317.7374 - val_VS_loss: 154.8771 - val_VR_loss: 148.9227 - val_VB_loss: 13.7355 - val_VS_auc: 0.5094 - val_VR_auc_1: 0.4916 - val_VB_auc_2: 0.4896\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 83.2599 - VS_loss: 38.0693 - VR_loss: 17.8367 - VB_loss: 27.1558 - VS_auc: 0.4988 - VR_auc_1: 0.4918 - VB_auc_2: 0.4772 - val_loss: 1.6686 - val_VS_loss: 0.6535 - val_VR_loss: 0.4750 - val_VB_loss: 0.3458 - val_VS_auc: 0.4993 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5002\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 44.9724 - VS_loss: 1.7839 - VR_loss: 0.7247 - VB_loss: 42.2715 - VS_auc: 0.5020 - VR_auc_1: 0.5024 - VB_auc_2: 0.4898 - val_loss: 1.3291 - val_VS_loss: 0.6045 - val_VR_loss: 0.3613 - val_VB_loss: 0.1728 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.8141 - VS_loss: 0.8337 - VR_loss: 0.5756 - VB_loss: 0.2156 - VS_auc: 0.5134 - VR_auc_1: 0.5061 - VB_auc_2: 0.5182 - val_loss: 1.2355 - val_VS_loss: 0.5803 - val_VR_loss: 0.3379 - val_VB_loss: 0.1294 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 1.3199 - VS_loss: 0.6141 - VR_loss: 0.3863 - VB_loss: 0.1327 - VS_auc: 0.4964 - VR_auc_1: 0.5010 - VB_auc_2: 0.4889 - val_loss: 1.2119 - val_VS_loss: 0.5742 - val_VR_loss: 0.3346 - val_VB_loss: 0.1175 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 1.3849 - VS_loss: 0.6671 - VR_loss: 0.3971 - VB_loss: 0.1361 - VS_auc: 0.5009 - VR_auc_1: 0.4980 - VB_auc_2: 0.4826 - val_loss: 1.2055 - val_VS_loss: 0.5735 - val_VR_loss: 0.3346 - val_VB_loss: 0.1138 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.9428 - VS_loss: 1.1176 - VR_loss: 0.4006 - VB_loss: 0.2418 - VS_auc: 0.4990 - VR_auc_1: 0.4992 - VB_auc_2: 0.5016 - val_loss: 1.2030 - val_VS_loss: 0.5731 - val_VR_loss: 0.3349 - val_VB_loss: 0.1128 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 31ms/step - loss: 1.3260 - VS_loss: 0.6412 - VR_loss: 0.3818 - VB_loss: 0.1215 - VS_auc: 0.5003 - VR_auc_1: 0.4991 - VB_auc_2: 0.4976 - val_loss: 1.2005 - val_VS_loss: 0.5725 - val_VR_loss: 0.3350 - val_VB_loss: 0.1123 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.3471 - VS_loss: 0.6663 - VR_loss: 0.3877 - VB_loss: 0.1130 - VS_auc: 0.4958 - VR_auc_1: 0.4972 - VB_auc_2: 0.4976 - val_loss: 1.1988 - val_VS_loss: 0.5721 - val_VR_loss: 0.3351 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 1.2839 - VS_loss: 0.6106 - VR_loss: 0.3808 - VB_loss: 0.1138 - VS_auc: 0.4927 - VR_auc_1: 0.4940 - VB_auc_2: 0.5003 - val_loss: 1.1982 - val_VS_loss: 0.5727 - val_VR_loss: 0.3353 - val_VB_loss: 0.1122 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.5467 - VS_loss: 0.7994 - VR_loss: 0.4062 - VB_loss: 0.1635 - VS_auc: 0.4998 - VR_auc_1: 0.4989 - VB_auc_2: 0.5002 - val_loss: 1.1965 - val_VS_loss: 0.5721 - val_VR_loss: 0.3352 - val_VB_loss: 0.1122 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 1.4760 - VS_loss: 0.7996 - VR_loss: 0.3860 - VB_loss: 0.1138 - VS_auc: 0.4994 - VR_auc_1: 0.5002 - VB_auc_2: 0.4972 - val_loss: 1.1960 - val_VS_loss: 0.5725 - val_VR_loss: 0.3353 - val_VB_loss: 0.1122 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 1.2823 - VS_loss: 0.6185 - VR_loss: 0.3780 - VB_loss: 0.1103 - VS_auc: 0.4996 - VR_auc_1: 0.4875 - VB_auc_2: 0.4997 - val_loss: 1.1948 - val_VS_loss: 0.5724 - val_VR_loss: 0.3352 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 1.2710 - VS_loss: 0.6080 - VR_loss: 0.3770 - VB_loss: 0.1116 - VS_auc: 0.5005 - VR_auc_1: 0.4976 - VB_auc_2: 0.5001 - val_loss: 1.1941 - val_VS_loss: 0.5727 - val_VR_loss: 0.3354 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 1.2735 - VS_loss: 0.6069 - VR_loss: 0.3816 - VB_loss: 0.1116 - VS_auc: 0.4969 - VR_auc_1: 0.4984 - VB_auc_2: 0.4986 - val_loss: 1.1936 - val_VS_loss: 0.5732 - val_VR_loss: 0.3355 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 1.2918 - VS_loss: 0.6183 - VR_loss: 0.3771 - VB_loss: 0.1241 - VS_auc: 0.4963 - VR_auc_1: 0.4952 - VB_auc_2: 0.5019 - val_loss: 1.1915 - val_VS_loss: 0.5723 - val_VR_loss: 0.3352 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 1.2775 - VS_loss: 0.6093 - VR_loss: 0.3866 - VB_loss: 0.1101 - VS_auc: 0.4948 - VR_auc_1: 0.4977 - VB_auc_2: 0.5003 - val_loss: 1.1910 - val_VS_loss: 0.5726 - val_VR_loss: 0.3353 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.3039 - VS_loss: 0.6403 - VR_loss: 0.3826 - VB_loss: 0.1105 - VS_auc: 0.4970 - VR_auc_1: 0.4951 - VB_auc_2: 0.5001 - val_loss: 1.1899 - val_VS_loss: 0.5724 - val_VR_loss: 0.3354 - val_VB_loss: 0.1121 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 1.2970 - VS_loss: 0.6402 - VR_loss: 0.3772 - VB_loss: 0.1100 - VS_auc: 0.4995 - VR_auc_1: 0.5010 - VB_auc_2: 0.5014 - val_loss: 1.1889 - val_VS_loss: 0.5722 - val_VR_loss: 0.3353 - val_VB_loss: 0.1122 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3dd99e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.7064768],\n",
       "        [0.7064768],\n",
       "        [0.7064768],\n",
       "        ...,\n",
       "        [0.7064768],\n",
       "        [0.7064768],\n",
       "        [0.7064768]], dtype=float32),\n",
       " array([[0.12527491],\n",
       "        [0.12527491],\n",
       "        [0.12527491],\n",
       "        ...,\n",
       "        [0.12527491],\n",
       "        [0.12527491],\n",
       "        [0.12527491]], dtype=float32),\n",
       " array([[0.02263079],\n",
       "        [0.02263079],\n",
       "        [0.02263079],\n",
       "        ...,\n",
       "        [0.02263079],\n",
       "        [0.02263079],\n",
       "        [0.02263079]], dtype=float32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42ea4a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.9046673286991063\n",
      "0.974180734856008\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc0af1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08b7bf",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1132e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class PleLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    n_experts:list,每个任务使用几个expert。[2,3]第一个任务使用2个expert，第二个任务使用3个expert。\n",
    "    n_expert_share:int,共享的部分设置的expert个数。\n",
    "    expert_dim:int,每个专家网络输出的向量维度。\n",
    "    n_task:int,任务个数。\n",
    "    '''\n",
    "    def __init__(self,n_task,n_experts,expert_dim,n_expert_share,dnn_reg_l2 = 1e-5):\n",
    "        super(PleLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        \n",
    "        # 生成多个任务特定网络和1个共享网络。\n",
    "        self.E_layer = []\n",
    "        for i in range(n_task):\n",
    "            sub_exp = [Dense(expert_dim,activation = 'relu') for j in range(n_experts[i])]\n",
    "            self.E_layer.append(sub_exp)\n",
    "            \n",
    "        self.share_layer = [Dense(expert_dim,activation = 'relu') for j in range(n_expert_share)]\n",
    "        #定义门控网络\n",
    "        self.gate_layers = [Dense(n_expert_share+n_experts[i],kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                                  activation = 'softmax') for i in range(n_task)]\n",
    "\n",
    "    def call(self,x):\n",
    "        #特定网络和共享网络\n",
    "        E_net = [[expert(x) for expert in sub_expert] for sub_expert in self.E_layer]\n",
    "        share_net = [expert(x) for expert in self.share_layer]\n",
    "        \n",
    "        #门的权重乘上，指定任务和共享任务的输出。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = self.gate_layers[i](x)\n",
    "            g = tf.expand_dims(g,axis = -1) #(bs,n_expert_share+n_experts[i],1)\n",
    "            _e = share_net+E_net[i]  \n",
    "            _e = Concatenate(axis = 1)([expert[:,tf.newaxis,:] for expert in _e]) #(bs,n_expert_share+n_experts[i],expert_dim)\n",
    "            _tower = tf.matmul(_e, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower)) #(bs,expert_dim)\n",
    "        return towers\n",
    "\n",
    "def build_ple(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim = 4,\n",
    "              varlens_cols = [],varlens_max_len = [],dnn_hidden_units = (64,64),\n",
    "              n_task = 2,n_experts = [2,2],n_expert_share = 4,dnn_reg_l2 = 1e-6,\n",
    "              drop_rate = 0.0,embedding_reg_l2 = 1e-6,targets = []):\n",
    "\n",
    "   #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])    \n",
    "                                  \n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    #Ple网络层\n",
    "    towers = PleLayer(n_task,n_experts,expert_dim,n_expert_share)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid',kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                       name = f,use_bias = True)(_t) for f,_t in zip(targets,towers)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d355852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 64)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 64)           0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 64)           0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 327)          0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 64)           20992       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 64)           4160        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ple_layer_1 (PleLayer)          [(None, 16), (None,  5785        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            17          ple_layer_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "VR (Dense)                      (None, 1)            17          ple_layer_1[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "VB (Dense)                      (None, 1)            17          ple_layer_1[0][2]                \n",
      "==================================================================================================\n",
      "Total params: 32,204\n",
      "Trainable params: 32,204\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_ple(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 16,\n",
    "          varlens_cols = varlen_features,varlens_max_len = varlens_max_len,dnn_hidden_units = (64,64),\n",
    "          n_task = 3,n_experts = [1,1,1],n_expert_share = 2,dnn_reg_l2 = 0.001,\n",
    "          drop_rate = 0.1,embedding_reg_l2 = 0.001,targets = target)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"AUC\"],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc2b3cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_40004\\346764826.py:4 loss  *\n        loss = - y_true * (alpha * K.pow(1 - y_pred, gamma) * K.log(y_pred)) -                (1 - y_true) * ((1 - alpha) * K.pow(y_pred, gamma) * K.log(1 - y_pred))\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1383 binary_op_wrapper\n        raise e\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1710 _mul_dispatch\n        return multiply(x, y, name=name)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6244 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:555 _apply_op_helper\n        raise TypeError(\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_model_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_model_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:759\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    763\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3066\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 3066\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3460\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3463\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3464\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_40004\\346764826.py:4 loss  *\n        loss = - y_true * (alpha * K.pow(1 - y_pred, gamma) * K.log(y_pred)) -                (1 - y_true) * ((1 - alpha) * K.pow(y_pred, gamma) * K.log(1 - y_pred))\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1383 binary_op_wrapper\n        raise e\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1710 _mul_dispatch\n        return multiply(x, y, name=name)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6244 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:555 _apply_op_helper\n        raise TypeError(\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type int64 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8f770e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.70129216],\n",
       "        [0.70129216],\n",
       "        [0.70129216],\n",
       "        ...,\n",
       "        [0.70678955],\n",
       "        [0.70614773],\n",
       "        [0.7061447 ]], dtype=float32),\n",
       " array([[0.13284911],\n",
       "        [0.13284911],\n",
       "        [0.13284911],\n",
       "        ...,\n",
       "        [0.14583455],\n",
       "        [0.14618456],\n",
       "        [0.14618663]], dtype=float32),\n",
       " array([[0.02366647],\n",
       "        [0.02366647],\n",
       "        [0.02366647],\n",
       "        ...,\n",
       "        [0.04442582],\n",
       "        [0.07810827],\n",
       "        [0.00534914]], dtype=float32)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "093a9901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.9046673286991063\n",
      "0.974180734856008\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01c509d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5130123097607477\n",
      "0.5193731347763446\n",
      "0.5141180016466714\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37c47957",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fe9236c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VS</th>\n",
       "      <th>VR</th>\n",
       "      <th>VB</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40279 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  VS  VR  VB  dx_yr  \\\n",
       "0                591.000000                       2   0   0   0   2005   \n",
       "1               1018.000000                       3   0   0   0   2005   \n",
       "2               2072.250000                       6   1   0   0   2005   \n",
       "3               2495.333333                       7   1   0   0   2005   \n",
       "4               2793.333333                       8   1   0   0   2005   \n",
       "...                     ...                     ...  ..  ..  ..    ...   \n",
       "40274           2737.500000                       8   1   0   0   2009   \n",
       "40275           3193.000000                       9   1   0   0   2009   \n",
       "40276           3499.666667                      10   1   0   0   2009   \n",
       "40277           3884.000000                      11   1   0   0   2009   \n",
       "40278            755.000000                       2   0   1   0   2016   \n",
       "\n",
       "       dx_mth  age sex   race  ... msld.cum_1 metacanc.cum_1  aids.cum_1  \\\n",
       "0          12   39   F  Black  ...        0.0            0.0         0.0   \n",
       "1          12   39   F  Black  ...        0.0            0.0         0.0   \n",
       "2          12   39   F  Black  ...        0.0            0.0         0.0   \n",
       "3          12   39   F  Black  ...        0.0            0.0         0.0   \n",
       "4          12   39   F  Black  ...        0.0            0.0         0.0   \n",
       "...       ...  ...  ..    ...  ...        ...            ...         ...   \n",
       "40274       9   48   M  Black  ...        0.0            0.0         0.0   \n",
       "40275       9   48   M  Black  ...        0.0            0.0         0.0   \n",
       "40276       9   48   M  Black  ...        0.0            0.0         0.0   \n",
       "40277       9   48   M  Black  ...        0.0            0.0         0.0   \n",
       "40278      11   21   M  Black  ...        0.0            0.0         0.0   \n",
       "\n",
       "      Depression_1  Anxiety_1  Psychiatric_disorder_1  Alcohol_use_1  \\\n",
       "0                0          0                       0              0   \n",
       "1                0          1                       0              1   \n",
       "2                0          0                       0              0   \n",
       "3                0          0                       0              0   \n",
       "4                0          0                       0              0   \n",
       "...            ...        ...                     ...            ...   \n",
       "40274            0          0                       0              0   \n",
       "40275            0          0                       0              0   \n",
       "40276            0          0                       0              0   \n",
       "40277            0          0                       0              0   \n",
       "40278            0          0                       0              0   \n",
       "\n",
       "       Tobacco_use_1  Illicit_drug_use_1  visits_1  \n",
       "0                  0                   0         4  \n",
       "1                  1                   1         2  \n",
       "2                  0                   0         2  \n",
       "3                  0                   0         8  \n",
       "4                  0                   0         6  \n",
       "...              ...                 ...       ...  \n",
       "40274              0                   0         3  \n",
       "40275              0                   0         8  \n",
       "40276              0                   0         3  \n",
       "40277              0                   0         6  \n",
       "40278              0                   0         4  \n",
       "\n",
       "[40279 rows x 106 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = variables[variables['model2'] != 'delete']\n",
    "data = data_origin[temp['variables'].tolist()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4657e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = variables[variables['model2'] == 'outcome']['variables'].tolist()\n",
    "sparse_features = variables[variables['model2'] == 'cat']['variables'].tolist()\n",
    "dense_features = variables[variables['model2'] == 'num']['variables'].tolist()\n",
    "varlen_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a50cd513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VS', 'VR', 'VB']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81bfd152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_9212\\2408031544.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n"
     ]
    }
   ],
   "source": [
    "encoder = {}\n",
    "# 稀疏特征编码\n",
    "for featid in sparse_features:\n",
    "    # print(f\"编码ID字段：{featid}\")\n",
    "    encoder[featid] = {uid:ucode+1 for ucode,uid in enumerate(data[featid].unique())} \n",
    "    data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n",
    "    \n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b00dde6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(data.shape[0] * 0.6)\n",
    "n_val = round(data.shape[0] * 0.2)\n",
    "\n",
    "train = data[:n_train]\n",
    "val = data[n_train:(n_train+n_val)]\n",
    "test = data[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "12d772c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "test_labels = [test[y].values for y in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af594f4d",
   "metadata": {},
   "source": [
    "### Seperate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d99bea8",
   "metadata": {},
   "source": [
    "#### VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c509463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32223, 103)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VS\"]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30f9b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 64)                6656      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,297\n",
      "Trainable params: 23,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "942a78c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 1303.6934 - accuracy: 0.6224 - val_loss: 1098.1283 - val_accuracy: 0.2589\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 545.4844 - accuracy: 0.5970 - val_loss: 5057.5225 - val_accuracy: 0.7414\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 683.4459 - accuracy: 0.6165 - val_loss: 1147.1113 - val_accuracy: 0.3530\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 542.2349 - accuracy: 0.5190 - val_loss: 3097.2981 - val_accuracy: 0.7443\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 564.9619 - accuracy: 0.6095 - val_loss: 3137.7454 - val_accuracy: 0.7442\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 982.0530 - accuracy: 0.5561 - val_loss: 9666.7705 - val_accuracy: 0.7442\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1093.7834 - accuracy: 0.6027 - val_loss: 1135.7395 - val_accuracy: 0.3641\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 416.8147 - accuracy: 0.6592 - val_loss: 3462.6907 - val_accuracy: 0.7049\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 633.1074 - accuracy: 0.5585 - val_loss: 7220.8413 - val_accuracy: 0.7442\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 635.9726 - accuracy: 0.6189 - val_loss: 108.7574 - val_accuracy: 0.5745\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 659.9925 - accuracy: 0.5855 - val_loss: 2839.7966 - val_accuracy: 0.7442\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 854.6354 - accuracy: 0.5824 - val_loss: 5373.6592 - val_accuracy: 0.7418\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 760.2140 - accuracy: 0.5769 - val_loss: 3368.0420 - val_accuracy: 0.7164\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 192.3571 - accuracy: 0.6371 - val_loss: 29.3511 - val_accuracy: 0.5880\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 196.2463 - accuracy: 0.6268 - val_loss: 672.6975 - val_accuracy: 0.5722\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 163.2509 - accuracy: 0.5476 - val_loss: 255.7698 - val_accuracy: 0.7357\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 144.8421 - accuracy: 0.6032 - val_loss: 1057.5188 - val_accuracy: 0.7432\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 340.2108 - accuracy: 0.5736 - val_loss: 548.7397 - val_accuracy: 0.6985\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 180.7030 - accuracy: 0.6349 - val_loss: 786.7744 - val_accuracy: 0.6987\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 682.0627 - accuracy: 0.6009 - val_loss: 2164.1438 - val_accuracy: 0.6948\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b66916d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.08003461]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed6a7399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.660377358490566\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6230bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48872708783702357\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55400d",
   "metadata": {},
   "source": [
    "#### VB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0b3c63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38ac0f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 64)                6656      \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,297\n",
      "Trainable params: 23,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ceee4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 12ms/step - loss: 3718.6895 - accuracy: 0.8941 - val_loss: 407.7980 - val_accuracy: 0.9763\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1565.9006 - accuracy: 0.7082 - val_loss: 596.6691 - val_accuracy: 0.9763\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2209.9578 - accuracy: 0.9722 - val_loss: 1869.7743 - val_accuracy: 0.5070\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 733.8765 - accuracy: 0.8179 - val_loss: 68.1011 - val_accuracy: 0.9763\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 987.1768 - accuracy: 0.9736 - val_loss: 85.6758 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 823.5568 - accuracy: 0.8241 - val_loss: 663.7038 - val_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1854.5398 - accuracy: 0.9692 - val_loss: 1056.2395 - val_accuracy: 0.3539\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 230.4126 - accuracy: 0.8852 - val_loss: 9576.6670 - val_accuracy: 0.2537\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1585.9058 - accuracy: 0.8760 - val_loss: 288.6635 - val_accuracy: 0.9443\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1625.8920 - accuracy: 0.9276 - val_loss: 300.6555 - val_accuracy: 0.9755\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 654.7507 - accuracy: 0.8012 - val_loss: 65.3095 - val_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1183.0476 - accuracy: 0.9743 - val_loss: 147.8899 - val_accuracy: 0.9729\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 818.2527 - accuracy: 0.8675 - val_loss: 283.7793 - val_accuracy: 0.9561\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 695.7230 - accuracy: 0.8695 - val_loss: 139.8170 - val_accuracy: 0.9763\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 861.0510 - accuracy: 0.8794 - val_loss: 228.2239 - val_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 883.1745 - accuracy: 0.9072 - val_loss: 133.8732 - val_accuracy: 0.9763\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 799.5349 - accuracy: 0.9434 - val_loss: 164.5456 - val_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 607.2212 - accuracy: 0.8792 - val_loss: 489.9315 - val_accuracy: 0.9763\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1560.4144 - accuracy: 0.9769 - val_loss: 20.4336 - val_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 227.2930 - accuracy: 0.8616 - val_loss: 41.3663 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26d311d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.8997129e-11]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c09f8c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046673286991063\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "94d9512c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4995335154248994\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25869e72",
   "metadata": {},
   "source": [
    "#### VR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cbf4eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0916ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 64)                6656      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,297\n",
      "Trainable params: 23,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b6664cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 1s 12ms/step - loss: 4038.7146 - accuracy: 0.8352 - val_loss: 10635.8574 - val_accuracy: 0.8479\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 855.5363 - accuracy: 0.7286 - val_loss: 6369.5850 - val_accuracy: 0.8964\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2045.6101 - accuracy: 0.8511 - val_loss: 1365.4381 - val_accuracy: 0.6749\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 237.1105 - accuracy: 0.7216 - val_loss: 40.4630 - val_accuracy: 0.6930\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 342.6897 - accuracy: 0.7684 - val_loss: 844.3221 - val_accuracy: 0.8631\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 522.0289 - accuracy: 0.8194 - val_loss: 423.3529 - val_accuracy: 0.8847\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 614.6876 - accuracy: 0.7732 - val_loss: 9857.1631 - val_accuracy: 0.8964\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 3214.0093 - accuracy: 0.8749 - val_loss: 8118.3540 - val_accuracy: 0.8718\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 784.5656 - accuracy: 0.7135 - val_loss: 2306.4158 - val_accuracy: 0.8964\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 307.4129 - accuracy: 0.7525 - val_loss: 317.6185 - val_accuracy: 0.8085\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 229.4529 - accuracy: 0.7923 - val_loss: 2280.8418 - val_accuracy: 0.8964\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 188.0968 - accuracy: 0.7454 - val_loss: 147.6850 - val_accuracy: 0.8920\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 92.4308 - accuracy: 0.7972 - val_loss: 1024.0614 - val_accuracy: 0.8959\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 161.0268 - accuracy: 0.7956 - val_loss: 242.9106 - val_accuracy: 0.8837\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 313.8484 - accuracy: 0.7910 - val_loss: 951.9487 - val_accuracy: 0.2391\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 715.4328 - accuracy: 0.8142 - val_loss: 8795.7773 - val_accuracy: 0.8964\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1732.5167 - accuracy: 0.8485 - val_loss: 1625.9849 - val_accuracy: 0.7197\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1172.4180 - accuracy: 0.8109 - val_loss: 4834.3164 - val_accuracy: 0.8964\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 484.9515 - accuracy: 0.7613 - val_loss: 934.5347 - val_accuracy: 0.8964\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 96.0654 - accuracy: 0.7658 - val_loss: 434.6642 - val_accuracy: 0.8944\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37be6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.7517699e-38],\n",
       "       ...,\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.0360856e-06]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "996b802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9023088381330685\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c818ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5173960691662094\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f6aef",
   "metadata": {},
   "source": [
    "### MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cae76eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers\n",
    "\n",
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3e5bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_49 (Embedding)        (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_50 (Embedding)        (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_51 (Embedding)        (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_52 (Embedding)        (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_53 (Embedding)        (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_54 (Embedding)        (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_55 (Embedding)        (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_56 (Embedding)        (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_57 (Embedding)        (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_58 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_59 (Embedding)        (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 64)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 64)           0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 64)           0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 64)           0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 64)           0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 64)           0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 64)           0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 64)           0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 64)           0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 64)           0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 64)           0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 64)           0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 64)           0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 64)           0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 64)           0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 64)           0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 64)           0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 64)           0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 64)           0           embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 64)           0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 64)           0           embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 64)           0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 64)           0           embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 64)           0           embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 64)           0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 64)           0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 64)           0           embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 64)           0           embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 64)           0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 64)           0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 64)           0           embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 64)           0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 64)           0           embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 64)           0           embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 64)           0           embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 64)           0           embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 64)           0           embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_49 (Flatten)            (None, 64)           0           embedding_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_50 (Flatten)            (None, 64)           0           embedding_50[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_51 (Flatten)            (None, 64)           0           embedding_51[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_52 (Flatten)            (None, 64)           0           embedding_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 64)           0           embedding_53[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_54 (Flatten)            (None, 64)           0           embedding_54[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 64)           0           embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_56 (Flatten)            (None, 64)           0           embedding_56[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_57 (Flatten)            (None, 64)           0           embedding_57[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_58 (Flatten)            (None, 64)           0           embedding_58[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 64)           0           embedding_59[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_60 (Flatten)            (None, 64)           0           embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_61 (Flatten)            (None, 64)           0           embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3379)         0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "                                                                 flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "                                                                 flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "                                                                 flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "                                                                 flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "                                                                 flatten_49[0][0]                 \n",
      "                                                                 flatten_50[0][0]                 \n",
      "                                                                 flatten_51[0][0]                 \n",
      "                                                                 flatten_52[0][0]                 \n",
      "                                                                 flatten_53[0][0]                 \n",
      "                                                                 flatten_54[0][0]                 \n",
      "                                                                 flatten_55[0][0]                 \n",
      "                                                                 flatten_56[0][0]                 \n",
      "                                                                 flatten_57[0][0]                 \n",
      "                                                                 flatten_58[0][0]                 \n",
      "                                                                 flatten_59[0][0]                 \n",
      "                                                                 flatten_60[0][0]                 \n",
      "                                                                 flatten_61[0][0]                 \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 64)           216320      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 128)          8320        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer_1 (MmoeLayer)        [(None, 32), (None,  13650       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            33          mmoe_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "VR (Dense)                      (None, 1)            33          mmoe_layer_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "VB (Dense)                      (None, 1)            33          mmoe_layer_1[0][2]               \n",
      "==================================================================================================\n",
      "Total params: 259,701\n",
      "Trainable params: 259,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_mmoe(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 32,\n",
    "          n_task = 3,n_expert = 6,varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "          dnn_hidden_units = (64,128,64),target = target,dnn_reg_l2 = 0.001,drop_rate = 0.1)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6cfa318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 12s 169ms/step - loss: 2926.9907 - VS_loss: 1461.4592 - VR_loss: 956.3173 - VB_loss: 508.7933 - VS_accuracy: 0.5835 - VR_accuracy: 0.7574 - VB_accuracy: 0.9033 - val_loss: 555.9722 - val_VS_loss: 30.2149 - val_VR_loss: 357.6391 - val_VB_loss: 167.5892 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.4952\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 334.2800 - VS_loss: 118.9200 - VR_loss: 56.2917 - VB_loss: 158.6115 - VS_accuracy: 0.6012 - VR_accuracy: 0.7895 - VB_accuracy: 0.9280 - val_loss: 664.1569 - val_VS_loss: 80.6193 - val_VR_loss: 89.2008 - val_VB_loss: 493.9723 - val_VS_accuracy: 0.6168 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.2010\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 206.1549 - VS_loss: 51.7610 - VR_loss: 26.4522 - VB_loss: 127.6050 - VS_accuracy: 0.5467 - VR_accuracy: 0.7859 - VB_accuracy: 0.7953 - val_loss: 89.3995 - val_VS_loss: 36.9909 - val_VR_loss: 40.3040 - val_VB_loss: 11.8002 - val_VS_accuracy: 0.7109 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 38.5314 - VS_loss: 8.4102 - VR_loss: 7.5396 - VB_loss: 22.3206 - VS_accuracy: 0.5836 - VR_accuracy: 0.8078 - VB_accuracy: 0.9384 - val_loss: 39.2132 - val_VS_loss: 16.2866 - val_VR_loss: 1.0454 - val_VB_loss: 21.6453 - val_VS_accuracy: 0.7298 - val_VR_accuracy: 0.8965 - val_VB_accuracy: 0.5031\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 11.8133 - VS_loss: 2.9077 - VR_loss: 2.5053 - VB_loss: 6.1774 - VS_accuracy: 0.5974 - VR_accuracy: 0.8202 - VB_accuracy: 0.9404 - val_loss: 4.2611 - val_VS_loss: 0.9026 - val_VR_loss: 2.8519 - val_VB_loss: 0.2950 - val_VS_accuracy: 0.5752 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 82ms/step - loss: 14.6919 - VS_loss: 2.5266 - VR_loss: 2.0025 - VB_loss: 9.9538 - VS_accuracy: 0.6654 - VR_accuracy: 0.8577 - VB_accuracy: 0.9407 - val_loss: 3.5751 - val_VS_loss: 2.3356 - val_VR_loss: 0.7440 - val_VB_loss: 0.2875 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8757 - val_VB_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 80ms/step - loss: 6.0545 - VS_loss: 2.0020 - VR_loss: 1.0704 - VB_loss: 2.7766 - VS_accuracy: 0.6770 - VR_accuracy: 0.8621 - VB_accuracy: 0.9597 - val_loss: 8.2318 - val_VS_loss: 0.9528 - val_VR_loss: 6.6153 - val_VB_loss: 0.4610 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.6797 - val_VB_accuracy: 0.9763\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 5.6069 - VS_loss: 1.7717 - VR_loss: 2.2943 - VB_loss: 1.3396 - VS_accuracy: 0.6917 - VR_accuracy: 0.8532 - VB_accuracy: 0.9086 - val_loss: 11.8212 - val_VS_loss: 0.8142 - val_VR_loss: 10.5496 - val_VB_loss: 0.2572 - val_VS_accuracy: 0.6944 - val_VR_accuracy: 0.6691 - val_VB_accuracy: 0.9763\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 4.3824 - VS_loss: 2.2563 - VR_loss: 1.1141 - VB_loss: 0.8122 - VS_accuracy: 0.6791 - VR_accuracy: 0.8563 - VB_accuracy: 0.9664 - val_loss: 4.8850 - val_VS_loss: 1.3368 - val_VR_loss: 2.8542 - val_VB_loss: 0.4953 - val_VS_accuracy: 0.6239 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 74ms/step - loss: 2.9958 - VS_loss: 1.3903 - VR_loss: 0.8565 - VB_loss: 0.5510 - VS_accuracy: 0.6900 - VR_accuracy: 0.8688 - VB_accuracy: 0.9718 - val_loss: 1.2274 - val_VS_loss: 0.5762 - val_VR_loss: 0.3351 - val_VB_loss: 0.1189 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 2.0254 - VS_loss: 0.9953 - VR_loss: 0.6226 - VB_loss: 0.2104 - VS_accuracy: 0.6976 - VR_accuracy: 0.8727 - VB_accuracy: 0.9761 - val_loss: 1.2170 - val_VS_loss: 0.5740 - val_VR_loss: 0.3326 - val_VB_loss: 0.1138 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.3306 - VS_loss: 0.8336 - VR_loss: 0.5891 - VB_loss: 0.7122 - VS_accuracy: 0.7015 - VR_accuracy: 0.8730 - VB_accuracy: 0.9761 - val_loss: 1.2144 - val_VS_loss: 0.5731 - val_VR_loss: 0.3338 - val_VB_loss: 0.1129 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 1.7320 - VS_loss: 0.8761 - VR_loss: 0.4755 - VB_loss: 0.1864 - VS_accuracy: 0.7014 - VR_accuracy: 0.8737 - VB_accuracy: 0.9749 - val_loss: 1.2117 - val_VS_loss: 0.5732 - val_VR_loss: 0.3324 - val_VB_loss: 0.1127 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 2.0311 - VS_loss: 1.1605 - VR_loss: 0.5021 - VB_loss: 0.1757 - VS_accuracy: 0.7005 - VR_accuracy: 0.8730 - VB_accuracy: 0.9762 - val_loss: 1.2095 - val_VS_loss: 0.5725 - val_VR_loss: 0.3324 - val_VB_loss: 0.1124 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 1.5194 - VS_loss: 0.7107 - VR_loss: 0.4512 - VB_loss: 0.1660 - VS_accuracy: 0.7041 - VR_accuracy: 0.8728 - VB_accuracy: 0.9760 - val_loss: 1.2083 - val_VS_loss: 0.5722 - val_VR_loss: 0.3330 - val_VB_loss: 0.1123 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 66ms/step - loss: 1.4296 - VS_loss: 0.6606 - VR_loss: 0.4420 - VB_loss: 0.1369 - VS_accuracy: 0.7031 - VR_accuracy: 0.8730 - VB_accuracy: 0.9758 - val_loss: 1.2043 - val_VS_loss: 0.5717 - val_VR_loss: 0.3309 - val_VB_loss: 0.1122 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 1.5092 - VS_loss: 0.7173 - VR_loss: 0.4461 - VB_loss: 0.1567 - VS_accuracy: 0.7032 - VR_accuracy: 0.8737 - VB_accuracy: 0.9763 - val_loss: 1.2053 - val_VS_loss: 0.5719 - val_VR_loss: 0.3328 - val_VB_loss: 0.1123 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.4453 - VS_loss: 0.6573 - VR_loss: 0.4584 - VB_loss: 0.1415 - VS_accuracy: 0.7034 - VR_accuracy: 0.8736 - VB_accuracy: 0.9765 - val_loss: 1.2045 - val_VS_loss: 0.5715 - val_VR_loss: 0.3335 - val_VB_loss: 0.1120 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 1.8875 - VS_loss: 0.9837 - VR_loss: 0.4313 - VB_loss: 0.2855 - VS_accuracy: 0.7036 - VR_accuracy: 0.8738 - VB_accuracy: 0.9767 - val_loss: 1.2080 - val_VS_loss: 0.5726 - val_VR_loss: 0.3365 - val_VB_loss: 0.1125 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 2.5375 - VS_loss: 0.7745 - VR_loss: 0.5090 - VB_loss: 1.0671 - VS_accuracy: 0.6998 - VR_accuracy: 0.8731 - VB_accuracy: 0.9509 - val_loss: 1.2020 - val_VS_loss: 0.5708 - val_VR_loss: 0.3313 - val_VB_loss: 0.1128 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "403e548b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.71051854],\n",
       "        [0.71051854],\n",
       "        [0.71051854],\n",
       "        ...,\n",
       "        [0.7105179 ],\n",
       "        [0.7105179 ],\n",
       "        [0.7239818 ]], dtype=float32),\n",
       " array([[0.12581421],\n",
       "        [0.12581421],\n",
       "        [0.12581421],\n",
       "        ...,\n",
       "        [0.12581314],\n",
       "        [0.12581314],\n",
       "        [0.11457289]], dtype=float32),\n",
       " array([[0.01823806],\n",
       "        [0.01823806],\n",
       "        [0.01823806],\n",
       "        ...,\n",
       "        [0.01823815],\n",
       "        [0.01823815],\n",
       "        [0.01619718]], dtype=float32)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bdf5c1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.9046673286991063\n",
      "0.974180734856008\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6c18b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5288075756913242\n",
      "0.5140566220442279\n",
      "0.526198492511566\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7fc5e",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4a7fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class PleLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    n_experts:list,每个任务使用几个expert。[2,3]第一个任务使用2个expert，第二个任务使用3个expert。\n",
    "    n_expert_share:int,共享的部分设置的expert个数。\n",
    "    expert_dim:int,每个专家网络输出的向量维度。\n",
    "    n_task:int,任务个数。\n",
    "    '''\n",
    "    def __init__(self,n_task,n_experts,expert_dim,n_expert_share,dnn_reg_l2 = 1e-5):\n",
    "        super(PleLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        \n",
    "        # 生成多个任务特定网络和1个共享网络。\n",
    "        self.E_layer = []\n",
    "        for i in range(n_task):\n",
    "            sub_exp = [Dense(expert_dim,activation = 'relu') for j in range(n_experts[i])]\n",
    "            self.E_layer.append(sub_exp)\n",
    "            \n",
    "        self.share_layer = [Dense(expert_dim,activation = 'relu') for j in range(n_expert_share)]\n",
    "        #定义门控网络\n",
    "        self.gate_layers = [Dense(n_expert_share+n_experts[i],kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                                  activation = 'softmax') for i in range(n_task)]\n",
    "\n",
    "    def call(self,x):\n",
    "        #特定网络和共享网络\n",
    "        E_net = [[expert(x) for expert in sub_expert] for sub_expert in self.E_layer]\n",
    "        share_net = [expert(x) for expert in self.share_layer]\n",
    "        \n",
    "        #门的权重乘上，指定任务和共享任务的输出。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = self.gate_layers[i](x)\n",
    "            g = tf.expand_dims(g,axis = -1) #(bs,n_expert_share+n_experts[i],1)\n",
    "            _e = share_net+E_net[i]  \n",
    "            _e = Concatenate(axis = 1)([expert[:,tf.newaxis,:] for expert in _e]) #(bs,n_expert_share+n_experts[i],expert_dim)\n",
    "            _tower = tf.matmul(_e, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower)) #(bs,expert_dim)\n",
    "        return towers\n",
    "\n",
    "def build_ple(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim = 4,\n",
    "              varlens_cols = [],varlens_max_len = [],dnn_hidden_units = (64,64),\n",
    "              n_task = 2,n_experts = [2,2],n_expert_share = 4,dnn_reg_l2 = 1e-6,\n",
    "              drop_rate = 0.0,embedding_reg_l2 = 1e-6,targets = []):\n",
    "\n",
    "   #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])    \n",
    "                                  \n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    #Ple网络层\n",
    "    towers = PleLayer(n_task,n_experts,expert_dim,n_expert_share)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid',kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                       name = f,use_bias = True)(_t) for f,_t in zip(targets,towers)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4e0f5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_62 (Embedding)        (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_63 (Embedding)        (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_64 (Embedding)        (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_65 (Embedding)        (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_66 (Embedding)        (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_67 (Embedding)        (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_68 (Embedding)        (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_69 (Embedding)        (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_70 (Embedding)        (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_71 (Embedding)        (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_72 (Embedding)        (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_73 (Embedding)        (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_76 (Embedding)        (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_77 (Embedding)        (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_78 (Embedding)        (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_79 (Embedding)        (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_80 (Embedding)        (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_81 (Embedding)        (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_82 (Embedding)        (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_83 (Embedding)        (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_84 (Embedding)        (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_85 (Embedding)        (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_86 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_87 (Embedding)        (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_88 (Embedding)        (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_89 (Embedding)        (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_90 (Embedding)        (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_91 (Embedding)        (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_92 (Embedding)        (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_93 (Embedding)        (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_94 (Embedding)        (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_95 (Embedding)        (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_96 (Embedding)        (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_97 (Embedding)        (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_98 (Embedding)        (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_99 (Embedding)        (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_100 (Embedding)       (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_101 (Embedding)       (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_102 (Embedding)       (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_103 (Embedding)       (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_104 (Embedding)       (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_105 (Embedding)       (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_106 (Embedding)       (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_107 (Embedding)       (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_108 (Embedding)       (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_109 (Embedding)       (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_110 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_111 (Embedding)       (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_112 (Embedding)       (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_113 (Embedding)       (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_62 (Flatten)            (None, 64)           0           embedding_62[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_63 (Flatten)            (None, 64)           0           embedding_63[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_64 (Flatten)            (None, 64)           0           embedding_64[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_65 (Flatten)            (None, 64)           0           embedding_65[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_66 (Flatten)            (None, 64)           0           embedding_66[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 64)           0           embedding_67[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 64)           0           embedding_68[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 64)           0           embedding_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 64)           0           embedding_70[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 64)           0           embedding_71[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 64)           0           embedding_72[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 64)           0           embedding_73[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_74 (Flatten)            (None, 64)           0           embedding_74[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_75 (Flatten)            (None, 64)           0           embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_76 (Flatten)            (None, 64)           0           embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 64)           0           embedding_77[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_78 (Flatten)            (None, 64)           0           embedding_78[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_79 (Flatten)            (None, 64)           0           embedding_79[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_80 (Flatten)            (None, 64)           0           embedding_80[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_81 (Flatten)            (None, 64)           0           embedding_81[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_82 (Flatten)            (None, 64)           0           embedding_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_83 (Flatten)            (None, 64)           0           embedding_83[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_84 (Flatten)            (None, 64)           0           embedding_84[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_85 (Flatten)            (None, 64)           0           embedding_85[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_86 (Flatten)            (None, 64)           0           embedding_86[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_87 (Flatten)            (None, 64)           0           embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_88 (Flatten)            (None, 64)           0           embedding_88[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_89 (Flatten)            (None, 64)           0           embedding_89[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_90 (Flatten)            (None, 64)           0           embedding_90[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_91 (Flatten)            (None, 64)           0           embedding_91[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_92 (Flatten)            (None, 64)           0           embedding_92[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_93 (Flatten)            (None, 64)           0           embedding_93[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_94 (Flatten)            (None, 64)           0           embedding_94[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_95 (Flatten)            (None, 64)           0           embedding_95[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_96 (Flatten)            (None, 64)           0           embedding_96[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_97 (Flatten)            (None, 64)           0           embedding_97[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_98 (Flatten)            (None, 64)           0           embedding_98[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_99 (Flatten)            (None, 64)           0           embedding_99[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_100 (Flatten)           (None, 64)           0           embedding_100[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_101 (Flatten)           (None, 64)           0           embedding_101[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_102 (Flatten)           (None, 64)           0           embedding_102[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_103 (Flatten)           (None, 64)           0           embedding_103[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_104 (Flatten)           (None, 64)           0           embedding_104[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_105 (Flatten)           (None, 64)           0           embedding_105[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_106 (Flatten)           (None, 64)           0           embedding_106[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_107 (Flatten)           (None, 64)           0           embedding_107[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_108 (Flatten)           (None, 64)           0           embedding_108[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_109 (Flatten)           (None, 64)           0           embedding_109[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_110 (Flatten)           (None, 64)           0           embedding_110[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_111 (Flatten)           (None, 64)           0           embedding_111[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_112 (Flatten)           (None, 64)           0           embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)           (None, 64)           0           embedding_113[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3379)         0           flatten_62[0][0]                 \n",
      "                                                                 flatten_63[0][0]                 \n",
      "                                                                 flatten_64[0][0]                 \n",
      "                                                                 flatten_65[0][0]                 \n",
      "                                                                 flatten_66[0][0]                 \n",
      "                                                                 flatten_67[0][0]                 \n",
      "                                                                 flatten_68[0][0]                 \n",
      "                                                                 flatten_69[0][0]                 \n",
      "                                                                 flatten_70[0][0]                 \n",
      "                                                                 flatten_71[0][0]                 \n",
      "                                                                 flatten_72[0][0]                 \n",
      "                                                                 flatten_73[0][0]                 \n",
      "                                                                 flatten_74[0][0]                 \n",
      "                                                                 flatten_75[0][0]                 \n",
      "                                                                 flatten_76[0][0]                 \n",
      "                                                                 flatten_77[0][0]                 \n",
      "                                                                 flatten_78[0][0]                 \n",
      "                                                                 flatten_79[0][0]                 \n",
      "                                                                 flatten_80[0][0]                 \n",
      "                                                                 flatten_81[0][0]                 \n",
      "                                                                 flatten_82[0][0]                 \n",
      "                                                                 flatten_83[0][0]                 \n",
      "                                                                 flatten_84[0][0]                 \n",
      "                                                                 flatten_85[0][0]                 \n",
      "                                                                 flatten_86[0][0]                 \n",
      "                                                                 flatten_87[0][0]                 \n",
      "                                                                 flatten_88[0][0]                 \n",
      "                                                                 flatten_89[0][0]                 \n",
      "                                                                 flatten_90[0][0]                 \n",
      "                                                                 flatten_91[0][0]                 \n",
      "                                                                 flatten_92[0][0]                 \n",
      "                                                                 flatten_93[0][0]                 \n",
      "                                                                 flatten_94[0][0]                 \n",
      "                                                                 flatten_95[0][0]                 \n",
      "                                                                 flatten_96[0][0]                 \n",
      "                                                                 flatten_97[0][0]                 \n",
      "                                                                 flatten_98[0][0]                 \n",
      "                                                                 flatten_99[0][0]                 \n",
      "                                                                 flatten_100[0][0]                \n",
      "                                                                 flatten_101[0][0]                \n",
      "                                                                 flatten_102[0][0]                \n",
      "                                                                 flatten_103[0][0]                \n",
      "                                                                 flatten_104[0][0]                \n",
      "                                                                 flatten_105[0][0]                \n",
      "                                                                 flatten_106[0][0]                \n",
      "                                                                 flatten_107[0][0]                \n",
      "                                                                 flatten_108[0][0]                \n",
      "                                                                 flatten_109[0][0]                \n",
      "                                                                 flatten_110[0][0]                \n",
      "                                                                 flatten_111[0][0]                \n",
      "                                                                 flatten_112[0][0]                \n",
      "                                                                 flatten_113[0][0]                \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 64)           216320      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 64)           4160        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ple_layer_1 (PleLayer)          [(None, 16), (None,  5785        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            17          ple_layer_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "VR (Dense)                      (None, 1)            17          ple_layer_1[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "VB (Dense)                      (None, 1)            17          ple_layer_1[0][2]                \n",
      "==================================================================================================\n",
      "Total params: 239,372\n",
      "Trainable params: 239,372\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_ple(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 16,\n",
    "          varlens_cols = varlen_features,varlens_max_len = varlens_max_len,dnn_hidden_units = (64,64),\n",
    "          n_task = 3,n_experts = [1,1,1],n_expert_share = 2,dnn_reg_l2 = 0.001,\n",
    "          drop_rate = 0.1,embedding_reg_l2 = 0.001,targets = target)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "48e71b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 12s 153ms/step - loss: 960.9734 - VS_loss: 506.0392 - VR_loss: 332.3476 - VB_loss: 122.3302 - VS_accuracy: 0.5834 - VR_accuracy: 0.7837 - VB_accuracy: 0.9174 - val_loss: 646.0811 - val_VS_loss: 326.9859 - val_VR_loss: 278.9359 - val_VB_loss: 39.7975 - val_VS_accuracy: 0.2604 - val_VR_accuracy: 0.8950 - val_VB_accuracy: 0.9763\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 239.0318 - VS_loss: 140.8563 - VR_loss: 75.0958 - VB_loss: 22.6045 - VS_accuracy: 0.5840 - VR_accuracy: 0.6808 - VB_accuracy: 0.9688 - val_loss: 17.3397 - val_VS_loss: 0.7415 - val_VR_loss: 15.6464 - val_VB_loss: 0.4037 - val_VS_accuracy: 0.4323 - val_VR_accuracy: 0.8707 - val_VB_accuracy: 0.9763\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 86ms/step - loss: 18.4327 - VS_loss: 12.3381 - VR_loss: 4.2931 - VB_loss: 1.4057 - VS_accuracy: 0.6242 - VR_accuracy: 0.8320 - VB_accuracy: 0.9693 - val_loss: 1.8272 - val_VS_loss: 0.6454 - val_VR_loss: 0.5460 - val_VB_loss: 0.4009 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 54ms/step - loss: 9.0762 - VS_loss: 4.4883 - VR_loss: 1.0381 - VB_loss: 3.3804 - VS_accuracy: 0.6965 - VR_accuracy: 0.8720 - VB_accuracy: 0.9735 - val_loss: 1.5724 - val_VS_loss: 0.6273 - val_VR_loss: 0.4817 - val_VB_loss: 0.3428 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 3.1492 - VS_loss: 1.3423 - VR_loss: 0.8362 - VB_loss: 0.8692 - VS_accuracy: 0.7008 - VR_accuracy: 0.8731 - VB_accuracy: 0.9717 - val_loss: 1.4220 - val_VS_loss: 0.6072 - val_VR_loss: 0.4391 - val_VB_loss: 0.2903 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.8135 - VS_loss: 0.8267 - VR_loss: 0.5626 - VB_loss: 0.3467 - VS_accuracy: 0.7025 - VR_accuracy: 0.8744 - VB_accuracy: 0.9759 - val_loss: 1.3149 - val_VS_loss: 0.5924 - val_VR_loss: 0.4074 - val_VB_loss: 0.2447 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.3755 - VS_loss: 0.6558 - VR_loss: 0.4220 - VB_loss: 0.2306 - VS_accuracy: 0.7027 - VR_accuracy: 0.8745 - VB_accuracy: 0.9765 - val_loss: 1.2447 - val_VS_loss: 0.5843 - val_VR_loss: 0.3835 - val_VB_loss: 0.2126 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.3278 - VS_loss: 0.6363 - VR_loss: 0.4315 - VB_loss: 0.1971 - VS_accuracy: 0.7039 - VR_accuracy: 0.8745 - VB_accuracy: 0.9768 - val_loss: 1.1967 - val_VS_loss: 0.5779 - val_VR_loss: 0.3664 - val_VB_loss: 0.1908 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.3857 - VS_loss: 0.7018 - VR_loss: 0.4397 - VB_loss: 0.1833 - VS_accuracy: 0.7043 - VR_accuracy: 0.8745 - VB_accuracy: 0.9767 - val_loss: 1.1735 - val_VS_loss: 0.5762 - val_VR_loss: 0.3600 - val_VB_loss: 0.1771 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.2756 - VS_loss: 0.6190 - VR_loss: 0.4182 - VB_loss: 0.1786 - VS_accuracy: 0.7038 - VR_accuracy: 0.8746 - VB_accuracy: 0.9767 - val_loss: 1.1546 - val_VS_loss: 0.5750 - val_VR_loss: 0.3541 - val_VB_loss: 0.1662 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 1.2723 - VS_loss: 0.6254 - VR_loss: 0.4226 - VB_loss: 0.1651 - VS_accuracy: 0.7047 - VR_accuracy: 0.8747 - VB_accuracy: 0.9768 - val_loss: 1.1369 - val_VS_loss: 0.5746 - val_VR_loss: 0.3483 - val_VB_loss: 0.1552 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 56ms/step - loss: 1.3376 - VS_loss: 0.6984 - VR_loss: 0.4161 - VB_loss: 0.1647 - VS_accuracy: 0.7045 - VR_accuracy: 0.8748 - VB_accuracy: 0.9767 - val_loss: 1.1244 - val_VS_loss: 0.5746 - val_VR_loss: 0.3445 - val_VB_loss: 0.1472 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 72ms/step - loss: 1.2792 - VS_loss: 0.6156 - VR_loss: 0.4561 - VB_loss: 0.1496 - VS_accuracy: 0.7050 - VR_accuracy: 0.8748 - VB_accuracy: 0.9768 - val_loss: 1.1158 - val_VS_loss: 0.5743 - val_VR_loss: 0.3422 - val_VB_loss: 0.1416 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 1.3024 - VS_loss: 0.7222 - VR_loss: 0.3862 - VB_loss: 0.1365 - VS_accuracy: 0.7049 - VR_accuracy: 0.8748 - VB_accuracy: 0.9769 - val_loss: 1.1080 - val_VS_loss: 0.5735 - val_VR_loss: 0.3407 - val_VB_loss: 0.1367 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 83ms/step - loss: 1.1878 - VS_loss: 0.6142 - VR_loss: 0.3826 - VB_loss: 0.1341 - VS_accuracy: 0.7049 - VR_accuracy: 0.8750 - VB_accuracy: 0.9769 - val_loss: 1.1016 - val_VS_loss: 0.5729 - val_VR_loss: 0.3393 - val_VB_loss: 0.1328 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 1.1796 - VS_loss: 0.6114 - VR_loss: 0.3806 - VB_loss: 0.1312 - VS_accuracy: 0.7050 - VR_accuracy: 0.8749 - VB_accuracy: 0.9768 - val_loss: 1.0967 - val_VS_loss: 0.5728 - val_VR_loss: 0.3381 - val_VB_loss: 0.1296 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.1797 - VS_loss: 0.6153 - VR_loss: 0.3802 - VB_loss: 0.1283 - VS_accuracy: 0.7049 - VR_accuracy: 0.8750 - VB_accuracy: 0.9769 - val_loss: 1.0925 - val_VS_loss: 0.5728 - val_VR_loss: 0.3373 - val_VB_loss: 0.1266 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 2s 97ms/step - loss: 1.1934 - VS_loss: 0.6275 - VR_loss: 0.3856 - VB_loss: 0.1246 - VS_accuracy: 0.7051 - VR_accuracy: 0.8750 - VB_accuracy: 0.9768 - val_loss: 1.0893 - val_VS_loss: 0.5729 - val_VR_loss: 0.3369 - val_VB_loss: 0.1242 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 2s 89ms/step - loss: 1.1987 - VS_loss: 0.6378 - VR_loss: 0.3841 - VB_loss: 0.1215 - VS_accuracy: 0.7051 - VR_accuracy: 0.8749 - VB_accuracy: 0.9768 - val_loss: 1.0865 - val_VS_loss: 0.5727 - val_VR_loss: 0.3365 - val_VB_loss: 0.1222 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 90ms/step - loss: 1.2988 - VS_loss: 0.6655 - VR_loss: 0.4574 - VB_loss: 0.1210 - VS_accuracy: 0.7051 - VR_accuracy: 0.8749 - VB_accuracy: 0.9768 - val_loss: 1.0845 - val_VS_loss: 0.5728 - val_VR_loss: 0.3362 - val_VB_loss: 0.1207 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ae093c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.703185 ],\n",
       "        [0.703185 ],\n",
       "        [0.703185 ],\n",
       "        ...,\n",
       "        [0.703185 ],\n",
       "        [0.703185 ],\n",
       "        [0.6597895]], dtype=float32),\n",
       " array([[0.13506533],\n",
       "        [0.13506533],\n",
       "        [0.13506533],\n",
       "        ...,\n",
       "        [0.13506533],\n",
       "        [0.13506533],\n",
       "        [0.06071173]], dtype=float32),\n",
       " array([[0.05286883],\n",
       "        [0.05286883],\n",
       "        [0.05286883],\n",
       "        ...,\n",
       "        [0.05286883],\n",
       "        [0.05286883],\n",
       "        [0.00869927]], dtype=float32)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2cb45196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.9046673286991063\n",
      "0.974180734856008\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "597a5c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5095318703961043\n",
      "0.4911196415912001\n",
      "0.5350174958833216\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c6548",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a6188d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VL_interpretation</th>\n",
       "      <th>VL</th>\n",
       "      <th>VS</th>\n",
       "      <th>VR</th>\n",
       "      <th>VB</th>\n",
       "      <th>Months_to_ini_VS</th>\n",
       "      <th>VR_N</th>\n",
       "      <th>VR_size</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>=</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>=</td>\n",
       "      <td>4804.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>=</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>200-500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40279 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year VL_interpretation      VL  \\\n",
       "0                591.000000                       2                 =  2902.0   \n",
       "1               1018.000000                       3                 =  4804.0   \n",
       "2               2072.250000                       6                 <   200.0   \n",
       "3               2495.333333                       7                 <   200.0   \n",
       "4               2793.333333                       8                 <   200.0   \n",
       "...                     ...                     ...               ...     ...   \n",
       "40274           2737.500000                       8                 <   200.0   \n",
       "40275           3193.000000                       9                 <   200.0   \n",
       "40276           3499.666667                      10                 <   200.0   \n",
       "40277           3884.000000                      11                 <   200.0   \n",
       "40278            755.000000                       2                 =   200.0   \n",
       "\n",
       "       VS  VR  VB  Months_to_ini_VS  VR_N  VR_size  ...  msld.cum_1  \\\n",
       "0       0   0   0         69.075000     0     none  ...         0.0   \n",
       "1       0   0   0         69.075000     0     none  ...         0.0   \n",
       "2       1   0   0         69.075000     0     none  ...         0.0   \n",
       "3       1   0   0         69.075000     0     none  ...         0.0   \n",
       "4       1   0   0         69.075000     0     none  ...         0.0   \n",
       "...    ..  ..  ..               ...   ...      ...  ...         ...   \n",
       "40274   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40275   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40276   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40277   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40278   0   1   0          5.150000     1  200-500  ...         0.0   \n",
       "\n",
       "       metacanc.cum_1  aids.cum_1  Depression_1 Anxiety_1  \\\n",
       "0                 0.0         0.0             0         0   \n",
       "1                 0.0         0.0             0         1   \n",
       "2                 0.0         0.0             0         0   \n",
       "3                 0.0         0.0             0         0   \n",
       "4                 0.0         0.0             0         0   \n",
       "...               ...         ...           ...       ...   \n",
       "40274             0.0         0.0             0         0   \n",
       "40275             0.0         0.0             0         0   \n",
       "40276             0.0         0.0             0         0   \n",
       "40277             0.0         0.0             0         0   \n",
       "40278             0.0         0.0             0         0   \n",
       "\n",
       "      Psychiatric_disorder_1 Alcohol_use_1 Tobacco_use_1  Illicit_drug_use_1  \\\n",
       "0                          0             0             0                   0   \n",
       "1                          0             1             1                   1   \n",
       "2                          0             0             0                   0   \n",
       "3                          0             0             0                   0   \n",
       "4                          0             0             0                   0   \n",
       "...                      ...           ...           ...                 ...   \n",
       "40274                      0             0             0                   0   \n",
       "40275                      0             0             0                   0   \n",
       "40276                      0             0             0                   0   \n",
       "40277                      0             0             0                   0   \n",
       "40278                      0             0             0                   0   \n",
       "\n",
       "      visits_1  \n",
       "0            4  \n",
       "1            2  \n",
       "2            2  \n",
       "3            8  \n",
       "4            6  \n",
       "...        ...  \n",
       "40274        3  \n",
       "40275        8  \n",
       "40276        3  \n",
       "40277        6  \n",
       "40278        4  \n",
       "\n",
       "[40279 rows x 124 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = variables[variables['model3'] != 'delete']\n",
    "data = data_origin[temp['variables'].tolist()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "162c2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = variables[variables['model3'] == 'outcome']['variables'].tolist()\n",
    "sparse_features = variables[variables['model3'] == 'cat']['variables'].tolist()\n",
    "dense_features = variables[variables['model3'] == 'num']['variables'].tolist()\n",
    "varlen_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "436446c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VS', 'VR', 'VB']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "269bef2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_40004\\2408031544.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n"
     ]
    }
   ],
   "source": [
    "encoder = {}\n",
    "# 稀疏特征编码\n",
    "for featid in sparse_features:\n",
    "    # print(f\"编码ID字段：{featid}\")\n",
    "    encoder[featid] = {uid:ucode+1 for ucode,uid in enumerate(data[featid].unique())} \n",
    "    data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n",
    "    \n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d2fc1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(data.shape[0] * 0.6)\n",
    "n_val = round(data.shape[0] * 0.2)\n",
    "\n",
    "train = data[:n_train]\n",
    "val = data[n_train:(n_train+n_val)]\n",
    "test = data[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2ecc24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "test_labels = [test[y].values for y in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92412744",
   "metadata": {},
   "source": [
    "### Seperate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e028264",
   "metadata": {},
   "source": [
    "#### VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "11fecf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32223, 121)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VS\"]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604394d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a024898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 64)                7808      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 24,449\n",
      "Trainable params: 24,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "825a1a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 4483.3657 - accuracy: 0.6523 - val_loss: 15358.5508 - val_accuracy: 0.8273\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1679.2067 - accuracy: 0.7487 - val_loss: 1256.8468 - val_accuracy: 0.5124\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 947.3356 - accuracy: 0.7351 - val_loss: 1337.6721 - val_accuracy: 0.8412\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1297.2480 - accuracy: 0.6647 - val_loss: 832.4089 - val_accuracy: 0.6147\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1221.4532 - accuracy: 0.7453 - val_loss: 3937.1436 - val_accuracy: 0.8296\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1006.1104 - accuracy: 0.7902 - val_loss: 1690.5839 - val_accuracy: 0.3509\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1102.3544 - accuracy: 0.7111 - val_loss: 1428.2468 - val_accuracy: 0.8086\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1871.5396 - accuracy: 0.7010 - val_loss: 26406.4824 - val_accuracy: 0.8285\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3026.4360 - accuracy: 0.7478 - val_loss: 17223.8164 - val_accuracy: 0.8373\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 918.9487 - accuracy: 0.7641 - val_loss: 466.1006 - val_accuracy: 0.8517\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 148.6929 - accuracy: 0.8117 - val_loss: 2006.6808 - val_accuracy: 0.8626\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 857.6949 - accuracy: 0.6922 - val_loss: 8499.2793 - val_accuracy: 0.8406\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 2566.6208 - accuracy: 0.7725 - val_loss: 3055.7239 - val_accuracy: 0.3774\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1008.4370 - accuracy: 0.6695 - val_loss: 3108.2600 - val_accuracy: 0.8569\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 259.7147 - accuracy: 0.7887 - val_loss: 2516.2656 - val_accuracy: 0.3672\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 444.5696 - accuracy: 0.7516 - val_loss: 7901.6484 - val_accuracy: 0.8488\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 660.2606 - accuracy: 0.7946 - val_loss: 1707.2062 - val_accuracy: 0.8419\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 791.9255 - accuracy: 0.7175 - val_loss: 3681.0732 - val_accuracy: 0.8479\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 954.3571 - accuracy: 0.7142 - val_loss: 2397.0034 - val_accuracy: 0.8483\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1056.4316 - accuracy: 0.7611 - val_loss: 10348.7822 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c4f3e64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46b580aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8597318768619663\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b92faa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6922403839214837\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "16493301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9018\n",
      "Logistic Regression AUC: 0.8414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "log_reg = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train.to_numpy(), np.array(y_train))\n",
    "\n",
    "# 在测试集上进行预测\n",
    "log_pred_prob = log_reg.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
    "log_pred = (log_pred_prob > 0.5).astype(int)  # 转换为二分类预测\n",
    "\n",
    "# 计算 Accuracy 和 AUC\n",
    "log_accuracy = accuracy_score(test_labels[0], log_pred)\n",
    "log_auc = roc_auc_score(test_labels[0], log_pred_prob)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression AUC: {log_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86398656",
   "metadata": {},
   "source": [
    "#### VB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "feec06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cddfc5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 64)                7808      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 24,449\n",
      "Trainable params: 24,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8933927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 270.3208 - accuracy: 0.9591 - val_loss: 6188.3882 - val_accuracy: 0.6204\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1222.8949 - accuracy: 0.9040 - val_loss: 240.9587 - val_accuracy: 0.9763\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 979.9902 - accuracy: 0.8783 - val_loss: 259.2208 - val_accuracy: 0.9763\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 495.6732 - accuracy: 0.8934 - val_loss: 9.2358 - val_accuracy: 0.9763\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 581.2900 - accuracy: 0.9402 - val_loss: 158.5749 - val_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 772.0606 - accuracy: 0.9528 - val_loss: 1599.8464 - val_accuracy: 0.8697\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 393.6704 - accuracy: 0.9412 - val_loss: 948.9550 - val_accuracy: 0.9120\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 373.5401 - accuracy: 0.9709 - val_loss: 33.6921 - val_accuracy: 0.9763\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 283.6260 - accuracy: 0.9148 - val_loss: 27.8553 - val_accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 332.9833 - accuracy: 0.9611 - val_loss: 67.3366 - val_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 315.3478 - accuracy: 0.9291 - val_loss: 64.1218 - val_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 277.7210 - accuracy: 0.9371 - val_loss: 77.5138 - val_accuracy: 0.9763\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 337.2366 - accuracy: 0.9560 - val_loss: 33.0987 - val_accuracy: 0.9763\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 61.8464 - accuracy: 0.9678 - val_loss: 3061.3716 - val_accuracy: 0.6461\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 886.3679 - accuracy: 0.9246 - val_loss: 107.1796 - val_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 388.7515 - accuracy: 0.9246 - val_loss: 104.3244 - val_accuracy: 0.9763\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 329.7405 - accuracy: 0.9494 - val_loss: 41.8451 - val_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 343.3480 - accuracy: 0.9253 - val_loss: 196.9785 - val_accuracy: 0.9763\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 608.4809 - accuracy: 0.9713 - val_loss: 30.4299 - val_accuracy: 0.9496\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 204.0966 - accuracy: 0.9152 - val_loss: 334.3506 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8428436c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [1.6281023e-23]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ebf371a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046673286991063\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d2ff0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4832440741630077\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99b3d1",
   "metadata": {},
   "source": [
    "#### VR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "40083a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ca05166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 64)                7808      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 24,449\n",
      "Trainable params: 24,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d0ce9c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 32.0257 - accuracy: 0.8463 - val_loss: 210.4855 - val_accuracy: 0.9153\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 57.7751 - accuracy: 0.8495 - val_loss: 104.2802 - val_accuracy: 0.9158\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 32.8524 - accuracy: 0.8611 - val_loss: 109.4254 - val_accuracy: 0.9078\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 29.3086 - accuracy: 0.8566 - val_loss: 33.1597 - val_accuracy: 0.8733\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 444.9315 - accuracy: 0.8609 - val_loss: 2605.8269 - val_accuracy: 0.7961\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 210.5623 - accuracy: 0.7576 - val_loss: 1305.3279 - val_accuracy: 0.9042\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 270.7642 - accuracy: 0.8510 - val_loss: 2587.9141 - val_accuracy: 0.8946\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 251.1071 - accuracy: 0.8209 - val_loss: 500.5365 - val_accuracy: 0.9141\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 81.0832 - accuracy: 0.8345 - val_loss: 128.4338 - val_accuracy: 0.8923\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 49.0474 - accuracy: 0.8349 - val_loss: 125.9676 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 40.1110 - accuracy: 0.8653 - val_loss: 162.7949 - val_accuracy: 0.8621\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 29.2043 - accuracy: 0.8347 - val_loss: 168.2202 - val_accuracy: 0.8978\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 28.0170 - accuracy: 0.8555 - val_loss: 31.1059 - val_accuracy: 0.8964\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 70.8991 - accuracy: 0.8578 - val_loss: 1906.4048 - val_accuracy: 0.8966\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 393.9047 - accuracy: 0.7350 - val_loss: 609.1051 - val_accuracy: 0.8975\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 102.4193 - accuracy: 0.8371 - val_loss: 118.5688 - val_accuracy: 0.9158\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 31.3360 - accuracy: 0.8548 - val_loss: 110.4312 - val_accuracy: 0.8863\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 23.7517 - accuracy: 0.8587 - val_loss: 66.4628 - val_accuracy: 0.9086\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 235.9502 - accuracy: 0.8546 - val_loss: 2319.3132 - val_accuracy: 0.8576\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 242.8610 - accuracy: 0.7473 - val_loss: 313.1351 - val_accuracy: 0.8914\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5b9a6983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1128482e-30],\n",
       "       [7.7010084e-30],\n",
       "       [9.2051642e-30],\n",
       "       ...,\n",
       "       [1.9518611e-26],\n",
       "       [4.8199402e-30],\n",
       "       [2.0585395e-29]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "01ee4196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9018123138033763\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f4cdee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6819560514715971\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fab65f",
   "metadata": {},
   "source": [
    "### MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "563f2f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled VS: 0    55232\n",
      "1    27616\n",
      "dtype: int64\n",
      "Resampled VB: 0    55232\n",
      "1    27616\n",
      "dtype: int64\n",
      "Resampled VR: 0    55232\n",
      "1    27616\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 先将所有任务合并，创建一个多标签数据集\n",
    "y_train_combined = np.vstack([data[:(n_train+n_val)][\"VS\"], data[:(n_train+n_val)][\"VB\"], data[:(n_train+n_val)][\"VR\"]]).T  # 转换为 (样本数, 3)\n",
    "\n",
    "# 进行 SMOTE 采样（使用多标签策略）\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled_combined = smote.fit_resample(X_train, y_train_combined)\n",
    "\n",
    "# 拆分出三个任务的 y\n",
    "y_resampled_vs = y_resampled_combined[:, 0]\n",
    "y_resampled_vb = y_resampled_combined[:, 1]\n",
    "y_resampled_vr = y_resampled_combined[:, 2]\n",
    "\n",
    "# 打印新分布\n",
    "print(\"Resampled VS:\", pd.Series(y_resampled_vs).value_counts())\n",
    "print(\"Resampled VB:\", pd.Series(y_resampled_vb).value_counts())\n",
    "print(\"Resampled VR:\", pd.Series(y_resampled_vr).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c2f7f6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ec5c8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers\n",
    "\n",
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "934e5fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "VL_interpretation (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "linkage (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retention (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VS_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VB_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "linkage_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retention_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_263 (Embedding)       (None, 1, 32)        96          VL_interpretation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_264 (Embedding)       (None, 1, 32)        192         VR_size[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_265 (Embedding)       (None, 1, 32)        96          sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_266 (Embedding)       (None, 1, 32)        160         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_267 (Embedding)       (None, 1, 32)        160         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_268 (Embedding)       (None, 1, 32)        96          region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_269 (Embedding)       (None, 1, 32)        96          VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_270 (Embedding)       (None, 1, 32)        96          linkage[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_271 (Embedding)       (None, 1, 32)        96          retention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_272 (Embedding)       (None, 1, 32)        96          mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_273 (Embedding)       (None, 1, 32)        96          chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_274 (Embedding)       (None, 1, 32)        96          pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_275 (Embedding)       (None, 1, 32)        96          cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_276 (Embedding)       (None, 1, 32)        96          dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_277 (Embedding)       (None, 1, 32)        96          cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_278 (Embedding)       (None, 1, 32)        96          rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_279 (Embedding)       (None, 1, 32)        96          pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_280 (Embedding)       (None, 1, 32)        96          mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_281 (Embedding)       (None, 1, 32)        96          diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_282 (Embedding)       (None, 1, 32)        96          diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_283 (Embedding)       (None, 1, 32)        96          hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_284 (Embedding)       (None, 1, 32)        96          rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_285 (Embedding)       (None, 1, 32)        96          canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_286 (Embedding)       (None, 1, 32)        96          msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_287 (Embedding)       (None, 1, 32)        96          metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_288 (Embedding)       (None, 1, 32)        96          aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_289 (Embedding)       (None, 1, 32)        96          Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_290 (Embedding)       (None, 1, 32)        96          Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_291 (Embedding)       (None, 1, 32)        96          Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_292 (Embedding)       (None, 1, 32)        96          Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_293 (Embedding)       (None, 1, 32)        96          Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_294 (Embedding)       (None, 1, 32)        96          Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_295 (Embedding)       (None, 1, 32)        1504        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_296 (Embedding)       (None, 1, 32)        96          VS_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_297 (Embedding)       (None, 1, 32)        96          VR_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_298 (Embedding)       (None, 1, 32)        96          VB_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_299 (Embedding)       (None, 1, 32)        192         VR_size_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_300 (Embedding)       (None, 1, 32)        96          linkage_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_301 (Embedding)       (None, 1, 32)        96          retention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_302 (Embedding)       (None, 1, 32)        96          mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_303 (Embedding)       (None, 1, 32)        96          chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_304 (Embedding)       (None, 1, 32)        96          pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_305 (Embedding)       (None, 1, 32)        96          cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_306 (Embedding)       (None, 1, 32)        96          dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_307 (Embedding)       (None, 1, 32)        96          cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_308 (Embedding)       (None, 1, 32)        96          rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_309 (Embedding)       (None, 1, 32)        96          pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_310 (Embedding)       (None, 1, 32)        96          mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_311 (Embedding)       (None, 1, 32)        96          diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_312 (Embedding)       (None, 1, 32)        96          diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_313 (Embedding)       (None, 1, 32)        96          hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_314 (Embedding)       (None, 1, 32)        96          rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_315 (Embedding)       (None, 1, 32)        96          canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_316 (Embedding)       (None, 1, 32)        96          msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_317 (Embedding)       (None, 1, 32)        96          metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_318 (Embedding)       (None, 1, 32)        96          aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_319 (Embedding)       (None, 1, 32)        96          Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_320 (Embedding)       (None, 1, 32)        96          Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_321 (Embedding)       (None, 1, 32)        96          Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_322 (Embedding)       (None, 1, 32)        96          Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_323 (Embedding)       (None, 1, 32)        96          Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_324 (Embedding)       (None, 1, 32)        96          Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_263 (Flatten)           (None, 32)           0           embedding_263[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_264 (Flatten)           (None, 32)           0           embedding_264[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_265 (Flatten)           (None, 32)           0           embedding_265[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_266 (Flatten)           (None, 32)           0           embedding_266[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_267 (Flatten)           (None, 32)           0           embedding_267[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_268 (Flatten)           (None, 32)           0           embedding_268[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_269 (Flatten)           (None, 32)           0           embedding_269[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_270 (Flatten)           (None, 32)           0           embedding_270[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_271 (Flatten)           (None, 32)           0           embedding_271[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_272 (Flatten)           (None, 32)           0           embedding_272[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_273 (Flatten)           (None, 32)           0           embedding_273[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_274 (Flatten)           (None, 32)           0           embedding_274[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_275 (Flatten)           (None, 32)           0           embedding_275[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_276 (Flatten)           (None, 32)           0           embedding_276[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_277 (Flatten)           (None, 32)           0           embedding_277[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_278 (Flatten)           (None, 32)           0           embedding_278[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_279 (Flatten)           (None, 32)           0           embedding_279[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_280 (Flatten)           (None, 32)           0           embedding_280[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_281 (Flatten)           (None, 32)           0           embedding_281[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_282 (Flatten)           (None, 32)           0           embedding_282[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_283 (Flatten)           (None, 32)           0           embedding_283[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_284 (Flatten)           (None, 32)           0           embedding_284[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_285 (Flatten)           (None, 32)           0           embedding_285[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_286 (Flatten)           (None, 32)           0           embedding_286[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_287 (Flatten)           (None, 32)           0           embedding_287[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_288 (Flatten)           (None, 32)           0           embedding_288[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_289 (Flatten)           (None, 32)           0           embedding_289[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_290 (Flatten)           (None, 32)           0           embedding_290[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_291 (Flatten)           (None, 32)           0           embedding_291[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_292 (Flatten)           (None, 32)           0           embedding_292[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_293 (Flatten)           (None, 32)           0           embedding_293[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_294 (Flatten)           (None, 32)           0           embedding_294[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_295 (Flatten)           (None, 32)           0           embedding_295[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_296 (Flatten)           (None, 32)           0           embedding_296[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_297 (Flatten)           (None, 32)           0           embedding_297[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_298 (Flatten)           (None, 32)           0           embedding_298[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_299 (Flatten)           (None, 32)           0           embedding_299[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_300 (Flatten)           (None, 32)           0           embedding_300[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_301 (Flatten)           (None, 32)           0           embedding_301[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_302 (Flatten)           (None, 32)           0           embedding_302[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_303 (Flatten)           (None, 32)           0           embedding_303[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_304 (Flatten)           (None, 32)           0           embedding_304[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_305 (Flatten)           (None, 32)           0           embedding_305[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_306 (Flatten)           (None, 32)           0           embedding_306[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_307 (Flatten)           (None, 32)           0           embedding_307[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_308 (Flatten)           (None, 32)           0           embedding_308[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_309 (Flatten)           (None, 32)           0           embedding_309[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_310 (Flatten)           (None, 32)           0           embedding_310[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_311 (Flatten)           (None, 32)           0           embedding_311[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_312 (Flatten)           (None, 32)           0           embedding_312[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_313 (Flatten)           (None, 32)           0           embedding_313[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_314 (Flatten)           (None, 32)           0           embedding_314[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_315 (Flatten)           (None, 32)           0           embedding_315[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_316 (Flatten)           (None, 32)           0           embedding_316[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_317 (Flatten)           (None, 32)           0           embedding_317[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_318 (Flatten)           (None, 32)           0           embedding_318[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_319 (Flatten)           (None, 32)           0           embedding_319[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_320 (Flatten)           (None, 32)           0           embedding_320[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_321 (Flatten)           (None, 32)           0           embedding_321[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_322 (Flatten)           (None, 32)           0           embedding_322[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_323 (Flatten)           (None, 32)           0           embedding_323[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_324 (Flatten)           (None, 32)           0           embedding_324[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 2043)         0           flatten_263[0][0]                \n",
      "                                                                 flatten_264[0][0]                \n",
      "                                                                 flatten_265[0][0]                \n",
      "                                                                 flatten_266[0][0]                \n",
      "                                                                 flatten_267[0][0]                \n",
      "                                                                 flatten_268[0][0]                \n",
      "                                                                 flatten_269[0][0]                \n",
      "                                                                 flatten_270[0][0]                \n",
      "                                                                 flatten_271[0][0]                \n",
      "                                                                 flatten_272[0][0]                \n",
      "                                                                 flatten_273[0][0]                \n",
      "                                                                 flatten_274[0][0]                \n",
      "                                                                 flatten_275[0][0]                \n",
      "                                                                 flatten_276[0][0]                \n",
      "                                                                 flatten_277[0][0]                \n",
      "                                                                 flatten_278[0][0]                \n",
      "                                                                 flatten_279[0][0]                \n",
      "                                                                 flatten_280[0][0]                \n",
      "                                                                 flatten_281[0][0]                \n",
      "                                                                 flatten_282[0][0]                \n",
      "                                                                 flatten_283[0][0]                \n",
      "                                                                 flatten_284[0][0]                \n",
      "                                                                 flatten_285[0][0]                \n",
      "                                                                 flatten_286[0][0]                \n",
      "                                                                 flatten_287[0][0]                \n",
      "                                                                 flatten_288[0][0]                \n",
      "                                                                 flatten_289[0][0]                \n",
      "                                                                 flatten_290[0][0]                \n",
      "                                                                 flatten_291[0][0]                \n",
      "                                                                 flatten_292[0][0]                \n",
      "                                                                 flatten_293[0][0]                \n",
      "                                                                 flatten_294[0][0]                \n",
      "                                                                 flatten_295[0][0]                \n",
      "                                                                 flatten_296[0][0]                \n",
      "                                                                 flatten_297[0][0]                \n",
      "                                                                 flatten_298[0][0]                \n",
      "                                                                 flatten_299[0][0]                \n",
      "                                                                 flatten_300[0][0]                \n",
      "                                                                 flatten_301[0][0]                \n",
      "                                                                 flatten_302[0][0]                \n",
      "                                                                 flatten_303[0][0]                \n",
      "                                                                 flatten_304[0][0]                \n",
      "                                                                 flatten_305[0][0]                \n",
      "                                                                 flatten_306[0][0]                \n",
      "                                                                 flatten_307[0][0]                \n",
      "                                                                 flatten_308[0][0]                \n",
      "                                                                 flatten_309[0][0]                \n",
      "                                                                 flatten_310[0][0]                \n",
      "                                                                 flatten_311[0][0]                \n",
      "                                                                 flatten_312[0][0]                \n",
      "                                                                 flatten_313[0][0]                \n",
      "                                                                 flatten_314[0][0]                \n",
      "                                                                 flatten_315[0][0]                \n",
      "                                                                 flatten_316[0][0]                \n",
      "                                                                 flatten_317[0][0]                \n",
      "                                                                 flatten_318[0][0]                \n",
      "                                                                 flatten_319[0][0]                \n",
      "                                                                 flatten_320[0][0]                \n",
      "                                                                 flatten_321[0][0]                \n",
      "                                                                 flatten_322[0][0]                \n",
      "                                                                 flatten_323[0][0]                \n",
      "                                                                 flatten_324[0][0]                \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 VL[0][0]                         \n",
      "                                                                 Months_to_ini_VS[0][0]           \n",
      "                                                                 VR_N[0][0]                       \n",
      "                                                                 prop_time[0][0]                  \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 VL_1[0][0]                       \n",
      "                                                                 Months_to_ini_VS_1[0][0]         \n",
      "                                                                 VR_N_1[0][0]                     \n",
      "                                                                 prop_time_1[0][0]                \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 64)           130816      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 64)           0           dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 128)          8320        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128)          0           dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 64)           8256        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 64)           0           dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer_5 (MmoeLayer)        [(None, 32), (None,  9100        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            33          mmoe_layer_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "VR (Dense)                      (None, 1)            33          mmoe_layer_5[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "VB (Dense)                      (None, 1)            33          mmoe_layer_5[0][2]               \n",
      "==================================================================================================\n",
      "Total params: 164,271\n",
      "Trainable params: 164,271\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_mmoe(sparse_features,dense_features,sparse_max_len,embed_dim = 32,expert_dim = 32,\n",
    "          n_task = 3,n_expert = 4,varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "          dnn_hidden_units = (64,128,64),target = target,dnn_reg_l2 = 0.001,drop_rate = 0.1)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"AUC\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d8c49fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 7s 101ms/step - loss: 1043.8833 - VS_loss: 371.9657 - VR_loss: 270.5643 - VB_loss: 401.2181 - VS_auc: 0.5406 - VR_auc_1: 0.5039 - VB_auc_2: 0.5028 - val_loss: 773.5620 - val_VS_loss: 555.6420 - val_VR_loss: 172.2690 - val_VB_loss: 45.5011 - val_VS_auc: 0.5497 - val_VR_auc_1: 0.4864 - val_VB_auc_2: 0.5027\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 49ms/step - loss: 600.5771 - VS_loss: 182.3253 - VR_loss: 120.0762 - VB_loss: 298.0437 - VS_auc: 0.5355 - VR_auc_1: 0.4984 - VB_auc_2: 0.4935 - val_loss: 185.1437 - val_VS_loss: 159.2955 - val_VR_loss: 21.5622 - val_VB_loss: 4.1774 - val_VS_auc: 0.5871 - val_VR_auc_1: 0.4779 - val_VB_auc_2: 0.5048\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 136.1038 - VS_loss: 67.1707 - VR_loss: 24.4879 - VB_loss: 44.3511 - VS_auc: 0.5247 - VR_auc_1: 0.4697 - VB_auc_2: 0.5211 - val_loss: 89.7435 - val_VS_loss: 10.2485 - val_VR_loss: 61.2486 - val_VB_loss: 18.1728 - val_VS_auc: 0.6480 - val_VR_auc_1: 0.4682 - val_VB_auc_2: 0.6370\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 33.4055 - VS_loss: 12.9145 - VR_loss: 15.2231 - VB_loss: 5.2044 - VS_auc: 0.5266 - VR_auc_1: 0.4816 - VB_auc_2: 0.5489 - val_loss: 2.1665 - val_VS_loss: 0.9192 - val_VR_loss: 0.9645 - val_VB_loss: 0.2257 - val_VS_auc: 0.4039 - val_VR_auc_1: 0.4862 - val_VB_auc_2: 0.5690\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.6627 - VS_loss: 3.7690 - VR_loss: 6.2058 - VB_loss: 1.6323 - VS_auc: 0.5356 - VR_auc_1: 0.5237 - VB_auc_2: 0.5424 - val_loss: 1.3085 - val_VS_loss: 0.5728 - val_VR_loss: 0.5241 - val_VB_loss: 0.1607 - val_VS_auc: 0.6453 - val_VR_auc_1: 0.5138 - val_VB_auc_2: 0.5594\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 6.5979 - VS_loss: 3.1495 - VR_loss: 2.5132 - VB_loss: 0.8874 - VS_auc: 0.5153 - VR_auc_1: 0.4989 - VB_auc_2: 0.5222 - val_loss: 1.3002 - val_VS_loss: 0.6518 - val_VR_loss: 0.4622 - val_VB_loss: 0.1413 - val_VS_auc: 0.5628 - val_VR_auc_1: 0.4872 - val_VB_auc_2: 0.5353\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 4.7737 - VS_loss: 2.4368 - VR_loss: 1.7508 - VB_loss: 0.5426 - VS_auc: 0.5140 - VR_auc_1: 0.4920 - VB_auc_2: 0.5436 - val_loss: 1.3710 - val_VS_loss: 0.6462 - val_VR_loss: 0.5602 - val_VB_loss: 0.1223 - val_VS_auc: 0.5711 - val_VR_auc_1: 0.4945 - val_VB_auc_2: 0.5425\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 11.0707 - VS_loss: 8.6079 - VR_loss: 1.9910 - VB_loss: 0.4300 - VS_auc: 0.5194 - VR_auc_1: 0.5095 - VB_auc_2: 0.5482 - val_loss: 1.3953 - val_VS_loss: 0.7021 - val_VR_loss: 0.5312 - val_VB_loss: 0.1204 - val_VS_auc: 0.5731 - val_VR_auc_1: 0.4998 - val_VB_auc_2: 0.5411\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 9.4243 - VS_loss: 6.4574 - VR_loss: 2.3241 - VB_loss: 0.6008 - VS_auc: 0.5221 - VR_auc_1: 0.5068 - VB_auc_2: 0.5297 - val_loss: 1.6166 - val_VS_loss: 1.0660 - val_VR_loss: 0.3948 - val_VB_loss: 0.1129 - val_VS_auc: 0.4757 - val_VR_auc_1: 0.5028 - val_VB_auc_2: 0.5864\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 5.5361 - VS_loss: 3.8601 - VR_loss: 1.4472 - VB_loss: 0.1860 - VS_auc: 0.5393 - VR_auc_1: 0.5132 - VB_auc_2: 0.5580 - val_loss: 1.2565 - val_VS_loss: 0.6366 - val_VR_loss: 0.4669 - val_VB_loss: 0.1108 - val_VS_auc: 0.5784 - val_VR_auc_1: 0.5135 - val_VB_auc_2: 0.5841\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 4.7333 - VS_loss: 3.1589 - VR_loss: 1.2747 - VB_loss: 0.2579 - VS_auc: 0.5222 - VR_auc_1: 0.5215 - VB_auc_2: 0.5448 - val_loss: 1.3934 - val_VS_loss: 0.7287 - val_VR_loss: 0.5129 - val_VB_loss: 0.1107 - val_VS_auc: 0.5577 - val_VR_auc_1: 0.5033 - val_VB_auc_2: 0.5730\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 48ms/step - loss: 4.9787 - VS_loss: 2.3945 - VR_loss: 1.5289 - VB_loss: 1.0146 - VS_auc: 0.5159 - VR_auc_1: 0.5067 - VB_auc_2: 0.5403 - val_loss: 1.2422 - val_VS_loss: 0.6041 - val_VR_loss: 0.4871 - val_VB_loss: 0.1106 - val_VS_auc: 0.4703 - val_VR_auc_1: 0.5168 - val_VB_auc_2: 0.5653\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 3.6311 - VS_loss: 2.4571 - VR_loss: 0.8796 - VB_loss: 0.2541 - VS_auc: 0.5158 - VR_auc_1: 0.5095 - VB_auc_2: 0.5370 - val_loss: 1.4422 - val_VS_loss: 0.8380 - val_VR_loss: 0.4515 - val_VB_loss: 0.1124 - val_VS_auc: 0.4912 - val_VR_auc_1: 0.4695 - val_VB_auc_2: 0.5268\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 46ms/step - loss: 2.5444 - VS_loss: 1.2551 - VR_loss: 0.8033 - VB_loss: 0.4459 - VS_auc: 0.5319 - VR_auc_1: 0.5035 - VB_auc_2: 0.5335 - val_loss: 1.0956 - val_VS_loss: 0.5807 - val_VR_loss: 0.3631 - val_VB_loss: 0.1119 - val_VS_auc: 0.5388 - val_VR_auc_1: 0.4958 - val_VB_auc_2: 0.5374\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 2.2620 - VS_loss: 1.0973 - VR_loss: 0.8503 - VB_loss: 0.2746 - VS_auc: 0.5337 - VR_auc_1: 0.4999 - VB_auc_2: 0.5328 - val_loss: 1.0897 - val_VS_loss: 0.5767 - val_VR_loss: 0.3615 - val_VB_loss: 0.1119 - val_VS_auc: 0.5332 - val_VR_auc_1: 0.5066 - val_VB_auc_2: 0.5183\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 1.9151 - VS_loss: 0.8381 - VR_loss: 0.6863 - VB_loss: 0.3512 - VS_auc: 0.5342 - VR_auc_1: 0.4862 - VB_auc_2: 0.4980 - val_loss: 1.1865 - val_VS_loss: 0.6581 - val_VR_loss: 0.3778 - val_VB_loss: 0.1111 - val_VS_auc: 0.5089 - val_VR_auc_1: 0.5377 - val_VB_auc_2: 0.5429\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 2.1481 - VS_loss: 1.0921 - VR_loss: 0.7006 - VB_loss: 0.3162 - VS_auc: 0.5322 - VR_auc_1: 0.4965 - VB_auc_2: 0.5255 - val_loss: 1.2120 - val_VS_loss: 0.6907 - val_VR_loss: 0.3712 - val_VB_loss: 0.1110 - val_VS_auc: 0.5123 - val_VR_auc_1: 0.5064 - val_VB_auc_2: 0.5440\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 2.2630 - VS_loss: 0.9549 - VR_loss: 0.9685 - VB_loss: 0.3006 - VS_auc: 0.5352 - VR_auc_1: 0.5157 - VB_auc_2: 0.5241 - val_loss: 1.4752 - val_VS_loss: 0.5959 - val_VR_loss: 0.7291 - val_VB_loss: 0.1113 - val_VS_auc: 0.5494 - val_VR_auc_1: 0.5379 - val_VB_auc_2: 0.5344\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 47ms/step - loss: 2.8556 - VS_loss: 0.8980 - VR_loss: 1.6589 - VB_loss: 0.2597 - VS_auc: 0.5379 - VR_auc_1: 0.5246 - VB_auc_2: 0.5179 - val_loss: 1.4116 - val_VS_loss: 0.6532 - val_VR_loss: 0.6079 - val_VB_loss: 0.1116 - val_VS_auc: 0.5252 - val_VR_auc_1: 0.5246 - val_VB_auc_2: 0.5246\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 44ms/step - loss: 2.4819 - VS_loss: 0.9933 - VR_loss: 1.2395 - VB_loss: 0.2103 - VS_auc: 0.5391 - VR_auc_1: 0.5275 - VB_auc_2: 0.5243 - val_loss: 1.1450 - val_VS_loss: 0.5729 - val_VR_loss: 0.4218 - val_VB_loss: 0.1117 - val_VS_auc: 0.5404 - val_VR_auc_1: 0.5194 - val_VB_auc_2: 0.5194\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a4d3e46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.69262433],\n",
       "        [0.69262433],\n",
       "        [0.69262433],\n",
       "        ...,\n",
       "        [0.69262433],\n",
       "        [0.69262433],\n",
       "        [0.739012  ]], dtype=float32),\n",
       " array([[0.14249949],\n",
       "        [0.14249949],\n",
       "        [0.14249949],\n",
       "        ...,\n",
       "        [0.14249949],\n",
       "        [0.14249949],\n",
       "        [0.13933715]], dtype=float32),\n",
       " array([[0.02694018],\n",
       "        [0.02694018],\n",
       "        [0.02694018],\n",
       "        ...,\n",
       "        [0.02694018],\n",
       "        [0.02694018],\n",
       "        [0.03007615]], dtype=float32)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb763821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775695134061569\n",
      "0.9046673286991063\n",
      "0.974180734856008\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "030d1dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5594468446350852\n",
      "0.5284342090594127\n",
      "0.5317590713949658\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a59bfcd",
   "metadata": {},
   "source": [
    "### New MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "88bc2e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled VS Distribution: 0    41172\n",
      "1    20586\n",
      "dtype: int64\n",
      "Resampled VB Distribution: 0    41172\n",
      "1    20586\n",
      "dtype: int64\n",
      "Resampled VR Distribution: 0    41172\n",
      "1    20586\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# 先将所有任务合并，创建一个多标签数据集\n",
    "y_train_combined = np.vstack([train_labels[0], train_labels[1], train_labels[2]]).T  # (样本数, 3)\n",
    "\n",
    "# # 进行 SMOTE 采样（使用多标签策略）\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# X_resampled, y_resampled_combined = smote.fit_resample(pd.DataFrame(train_model_input), y_train_combined)\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled_combined = ros.fit_resample(pd.DataFrame(train_model_input), y_train_combined)\n",
    "\n",
    "# 拆分出三个任务的 y\n",
    "y_resampled_vs = y_resampled_combined[:, 0]\n",
    "y_resampled_vb = y_resampled_combined[:, 1]\n",
    "y_resampled_vr = y_resampled_combined[:, 2]\n",
    "\n",
    "# 生成新的训练标签\n",
    "train_labels_resampled = [y_resampled_vs, y_resampled_vb, y_resampled_vr]\n",
    "\n",
    "# 打印新数据分布\n",
    "print(\"Resampled VS Distribution:\", pd.Series(y_resampled_vs).value_counts())\n",
    "print(\"Resampled VB Distribution:\", pd.Series(y_resampled_vb).value_counts())\n",
    "print(\"Resampled VR Distribution:\", pd.Series(y_resampled_vr).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "02fb6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新构建 train_model_input\n",
    "train_model_input_resampled = {name: X_resampled[name] if name not in varlen_features \n",
    "                               else np.stack(X_resampled[name]) for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "840fb685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "62/62 [==============================] - 8s 66ms/step - loss: 2274.6465 - VS_loss: 626.8201 - VR_loss: 466.1612 - VB_loss: 1181.4010 - VS_auc: 0.5286 - VR_auc_1: 0.5633 - VB_auc_2: 0.5649 - val_loss: 7607.1597 - val_VS_loss: 833.5277 - val_VR_loss: 475.1587 - val_VB_loss: 6298.2188 - val_VS_auc: 0.5224 - val_VR_auc_1: 0.5760 - val_VB_auc_2: 0.5957\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 1456.5278 - VS_loss: 373.4844 - VR_loss: 273.5056 - VB_loss: 809.2694 - VS_auc: 0.5315 - VR_auc_1: 0.5466 - VB_auc_2: 0.5719 - val_loss: 1964.5417 - val_VS_loss: 142.4765 - val_VR_loss: 276.6937 - val_VB_loss: 1545.0955 - val_VS_auc: 0.5789 - val_VR_auc_1: 0.4976 - val_VB_auc_2: 0.6182\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 3s 41ms/step - loss: 1072.9261 - VS_loss: 249.2328 - VR_loss: 181.6318 - VB_loss: 641.7686 - VS_auc: 0.5447 - VR_auc_1: 0.5482 - VB_auc_2: 0.5779 - val_loss: 1021.9758 - val_VS_loss: 307.2560 - val_VR_loss: 23.4378 - val_VB_loss: 690.9647 - val_VS_auc: 0.4961 - val_VR_auc_1: 0.5468 - val_VB_auc_2: 0.6347\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 637.1471 - VS_loss: 137.4062 - VR_loss: 139.7608 - VB_loss: 359.6417 - VS_auc: 0.5430 - VR_auc_1: 0.5618 - VB_auc_2: 0.5848 - val_loss: 1542.8796 - val_VS_loss: 69.0504 - val_VR_loss: 191.4782 - val_VB_loss: 1281.9918 - val_VS_auc: 0.5645 - val_VR_auc_1: 0.5789 - val_VB_auc_2: 0.5843\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 281.4706 - VS_loss: 74.1482 - VR_loss: 62.7083 - VB_loss: 144.2499 - VS_auc: 0.5283 - VR_auc_1: 0.5453 - VB_auc_2: 0.5923 - val_loss: 304.6646 - val_VS_loss: 31.0498 - val_VR_loss: 60.2570 - val_VB_loss: 212.9928 - val_VS_auc: 0.4368 - val_VR_auc_1: 0.4864 - val_VB_auc_2: 0.6567\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 143.9022 - VS_loss: 36.5412 - VR_loss: 31.6082 - VB_loss: 75.3916 - VS_auc: 0.5210 - VR_auc_1: 0.5285 - VB_auc_2: 0.5846 - val_loss: 3.3069 - val_VS_loss: 1.1595 - val_VR_loss: 1.3040 - val_VB_loss: 0.4995 - val_VS_auc: 0.5319 - val_VR_auc_1: 0.5063 - val_VB_auc_2: 0.5459\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 45.9953 - VS_loss: 16.4194 - VR_loss: 7.8494 - VB_loss: 21.4010 - VS_auc: 0.5091 - VR_auc_1: 0.5371 - VB_auc_2: 0.5665 - val_loss: 2.2649 - val_VS_loss: 0.7131 - val_VR_loss: 0.7579 - val_VB_loss: 0.4844 - val_VS_auc: 0.5764 - val_VR_auc_1: 0.4778 - val_VB_auc_2: 0.5362\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 21.9267 - VS_loss: 2.7203 - VR_loss: 7.5054 - VB_loss: 11.4057 - VS_auc: 0.5007 - VR_auc_1: 0.5208 - VB_auc_2: 0.5462 - val_loss: 2.1458 - val_VS_loss: 0.7406 - val_VR_loss: 0.6447 - val_VB_loss: 0.4793 - val_VS_auc: 0.5273 - val_VR_auc_1: 0.5086 - val_VB_auc_2: 0.5120\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 6.4276 - VS_loss: 1.6072 - VR_loss: 2.2161 - VB_loss: 2.3354 - VS_auc: 0.5030 - VR_auc_1: 0.4991 - VB_auc_2: 0.5263 - val_loss: 2.0947 - val_VS_loss: 0.7757 - val_VR_loss: 0.5952 - val_VB_loss: 0.4669 - val_VS_auc: 0.5044 - val_VR_auc_1: 0.5028 - val_VB_auc_2: 0.5011\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 3s 45ms/step - loss: 3.5695 - VS_loss: 1.0696 - VR_loss: 1.1140 - VB_loss: 1.1386 - VS_auc: 0.5014 - VR_auc_1: 0.5129 - VB_auc_2: 0.5187 - val_loss: 2.0597 - val_VS_loss: 0.8048 - val_VR_loss: 0.5644 - val_VB_loss: 0.4524 - val_VS_auc: 0.5012 - val_VR_auc_1: 0.5003 - val_VB_auc_2: 0.5003\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.4900 - VS_loss: 0.7898 - VR_loss: 1.1904 - VB_loss: 1.2789 - VS_auc: 0.5050 - VR_auc_1: 0.5091 - VB_auc_2: 0.5112 - val_loss: 2.0365 - val_VS_loss: 0.8288 - val_VR_loss: 0.5426 - val_VB_loss: 0.4412 - val_VS_auc: 0.5012 - val_VR_auc_1: 0.5003 - val_VB_auc_2: 0.5003\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 2s 40ms/step - loss: 3.2854 - VS_loss: 0.9097 - VR_loss: 0.9456 - VB_loss: 1.2118 - VS_auc: 0.5005 - VR_auc_1: 0.5112 - VB_auc_2: 0.5132 - val_loss: 2.0220 - val_VS_loss: 0.8488 - val_VR_loss: 0.5258 - val_VB_loss: 0.4345 - val_VS_auc: 0.5005 - val_VR_auc_1: 0.5004 - val_VB_auc_2: 0.5003\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 4.3029 - VS_loss: 1.6680 - VR_loss: 0.9880 - VB_loss: 1.4381 - VS_auc: 0.4988 - VR_auc_1: 0.5051 - VB_auc_2: 0.5088 - val_loss: 2.0135 - val_VS_loss: 0.8656 - val_VR_loss: 0.5132 - val_VB_loss: 0.4299 - val_VS_auc: 0.5007 - val_VR_auc_1: 0.5005 - val_VB_auc_2: 0.5002\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 6.9145 - VS_loss: 0.8166 - VR_loss: 1.7043 - VB_loss: 4.1921 - VS_auc: 0.5005 - VR_auc_1: 0.4988 - VB_auc_2: 0.5068 - val_loss: 2.0082 - val_VS_loss: 0.8794 - val_VR_loss: 0.5036 - val_VB_loss: 0.4268 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 3.1344 - VS_loss: 0.8400 - VR_loss: 0.9432 - VB_loss: 1.1553 - VS_auc: 0.4993 - VR_auc_1: 0.5029 - VB_auc_2: 0.5079 - val_loss: 2.0051 - val_VS_loss: 0.8902 - val_VR_loss: 0.4967 - val_VB_loss: 0.4249 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 3s 42ms/step - loss: 2.8793 - VS_loss: 0.7771 - VR_loss: 0.7854 - VB_loss: 1.1254 - VS_auc: 0.4982 - VR_auc_1: 0.5068 - VB_auc_2: 0.5053 - val_loss: 2.0027 - val_VS_loss: 0.8984 - val_VR_loss: 0.4908 - val_VB_loss: 0.4240 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 2s 38ms/step - loss: 2.5974 - VS_loss: 0.7853 - VR_loss: 0.8163 - VB_loss: 0.8078 - VS_auc: 0.4997 - VR_auc_1: 0.5064 - VB_auc_2: 0.5064 - val_loss: 2.0006 - val_VS_loss: 0.9042 - val_VR_loss: 0.4865 - val_VB_loss: 0.4235 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 2s 37ms/step - loss: 3.2977 - VS_loss: 1.1745 - VR_loss: 0.7996 - VB_loss: 1.1384 - VS_auc: 0.5021 - VR_auc_1: 0.5043 - VB_auc_2: 0.5065 - val_loss: 2.0001 - val_VS_loss: 0.9090 - val_VR_loss: 0.4836 - val_VB_loss: 0.4234 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 3s 44ms/step - loss: 2.8272 - VS_loss: 0.7779 - VR_loss: 0.7422 - VB_loss: 1.1239 - VS_auc: 0.5002 - VR_auc_1: 0.5047 - VB_auc_2: 0.5055 - val_loss: 1.9994 - val_VS_loss: 0.9129 - val_VR_loss: 0.4813 - val_VB_loss: 0.4231 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 2s 39ms/step - loss: 2.4565 - VS_loss: 0.7616 - VR_loss: 0.7638 - VB_loss: 0.7498 - VS_auc: 0.4991 - VR_auc_1: 0.5049 - VB_auc_2: 0.5056 - val_loss: 1.9981 - val_VS_loss: 0.9154 - val_VR_loss: 0.4799 - val_VB_loss: 0.4223 - val_VS_auc: 0.5000 - val_VR_auc_1: 0.5000 - val_VB_auc_2: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 重新编译模型\n",
    "adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss='binary_crossentropy', metrics=[\"AUC\"])\n",
    "\n",
    "# 使用 Oversampled 训练数据训练模型\n",
    "history = model.fit(train_model_input_resampled, train_labels_resampled,\n",
    "                    validation_data=(val_model_input, val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e60f28a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VS - Accuracy: 0.2232, AUC: 0.5000\n",
      "VR - Accuracy: 0.9047, AUC: 0.5000\n",
      "VB - Accuracy: 0.9742, AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# 预测测试集\n",
    "preds = model.predict(test_model_input)\n",
    "\n",
    "# 计算评估指标\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 计算每个任务的 AUC 和 Accuracy\n",
    "for i, task in enumerate(target):\n",
    "    auc = roc_auc_score(test_labels[i], preds[i])\n",
    "    acc = accuracy_score(test_labels[i], (preds[i] > 0.5).astype(int))\n",
    "    print(f\"{task} - Accuracy: {acc:.4f}, AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbafef",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "787fd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class PleLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    n_experts:list,每个任务使用几个expert。[2,3]第一个任务使用2个expert，第二个任务使用3个expert。\n",
    "    n_expert_share:int,共享的部分设置的expert个数。\n",
    "    expert_dim:int,每个专家网络输出的向量维度。\n",
    "    n_task:int,任务个数。\n",
    "    '''\n",
    "    def __init__(self,n_task,n_experts,expert_dim,n_expert_share,dnn_reg_l2 = 1e-5):\n",
    "        super(PleLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        \n",
    "        # 生成多个任务特定网络和1个共享网络。\n",
    "        self.E_layer = []\n",
    "        for i in range(n_task):\n",
    "            sub_exp = [Dense(expert_dim,activation = 'relu') for j in range(n_experts[i])]\n",
    "            self.E_layer.append(sub_exp)\n",
    "            \n",
    "        self.share_layer = [Dense(expert_dim,activation = 'relu') for j in range(n_expert_share)]\n",
    "        #定义门控网络\n",
    "        self.gate_layers = [Dense(n_expert_share+n_experts[i],kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                                  activation = 'softmax') for i in range(n_task)]\n",
    "\n",
    "    def call(self,x):\n",
    "        #特定网络和共享网络\n",
    "        E_net = [[expert(x) for expert in sub_expert] for sub_expert in self.E_layer]\n",
    "        share_net = [expert(x) for expert in self.share_layer]\n",
    "        \n",
    "        #门的权重乘上，指定任务和共享任务的输出。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = self.gate_layers[i](x)\n",
    "            g = tf.expand_dims(g,axis = -1) #(bs,n_expert_share+n_experts[i],1)\n",
    "            _e = share_net+E_net[i]  \n",
    "            _e = Concatenate(axis = 1)([expert[:,tf.newaxis,:] for expert in _e]) #(bs,n_expert_share+n_experts[i],expert_dim)\n",
    "            _tower = tf.matmul(_e, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower)) #(bs,expert_dim)\n",
    "        return towers\n",
    "\n",
    "def build_ple(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim = 4,\n",
    "              varlens_cols = [],varlens_max_len = [],dnn_hidden_units = (64,64),\n",
    "              n_task = 2,n_experts = [2,2],n_expert_share = 4,dnn_reg_l2 = 1e-6,\n",
    "              drop_rate = 0.0,embedding_reg_l2 = 1e-6,targets = []):\n",
    "\n",
    "   #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])    \n",
    "                                  \n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    #Ple网络层\n",
    "    towers = PleLayer(n_task,n_experts,expert_dim,n_expert_share)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid',kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                       name = f,use_bias = True)(_t) for f,_t in zip(targets,towers)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bf75d5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "VL_interpretation (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "linkage (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retention (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VS_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VB_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "linkage_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retention_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_176 (Embedding)       (None, 1, 64)        192         VL_interpretation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_177 (Embedding)       (None, 1, 64)        384         VR_size[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_178 (Embedding)       (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_179 (Embedding)       (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_180 (Embedding)       (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_181 (Embedding)       (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_182 (Embedding)       (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_183 (Embedding)       (None, 1, 64)        192         linkage[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_184 (Embedding)       (None, 1, 64)        192         retention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_185 (Embedding)       (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_186 (Embedding)       (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_187 (Embedding)       (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_188 (Embedding)       (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_189 (Embedding)       (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_190 (Embedding)       (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_191 (Embedding)       (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_192 (Embedding)       (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_193 (Embedding)       (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_194 (Embedding)       (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_195 (Embedding)       (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_196 (Embedding)       (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_197 (Embedding)       (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_198 (Embedding)       (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_199 (Embedding)       (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_200 (Embedding)       (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_201 (Embedding)       (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_202 (Embedding)       (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_203 (Embedding)       (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_204 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_205 (Embedding)       (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_206 (Embedding)       (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_207 (Embedding)       (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_208 (Embedding)       (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_209 (Embedding)       (None, 1, 64)        192         VS_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_210 (Embedding)       (None, 1, 64)        192         VR_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_211 (Embedding)       (None, 1, 64)        192         VB_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_212 (Embedding)       (None, 1, 64)        384         VR_size_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_213 (Embedding)       (None, 1, 64)        192         linkage_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_214 (Embedding)       (None, 1, 64)        192         retention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_215 (Embedding)       (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_216 (Embedding)       (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_217 (Embedding)       (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_218 (Embedding)       (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_219 (Embedding)       (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_220 (Embedding)       (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_221 (Embedding)       (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_222 (Embedding)       (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_223 (Embedding)       (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_224 (Embedding)       (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_225 (Embedding)       (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_226 (Embedding)       (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_227 (Embedding)       (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_228 (Embedding)       (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_229 (Embedding)       (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_230 (Embedding)       (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_231 (Embedding)       (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_232 (Embedding)       (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_233 (Embedding)       (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_234 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_235 (Embedding)       (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_236 (Embedding)       (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_237 (Embedding)       (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_176 (Flatten)           (None, 64)           0           embedding_176[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_177 (Flatten)           (None, 64)           0           embedding_177[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_178 (Flatten)           (None, 64)           0           embedding_178[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_179 (Flatten)           (None, 64)           0           embedding_179[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_180 (Flatten)           (None, 64)           0           embedding_180[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_181 (Flatten)           (None, 64)           0           embedding_181[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_182 (Flatten)           (None, 64)           0           embedding_182[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_183 (Flatten)           (None, 64)           0           embedding_183[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_184 (Flatten)           (None, 64)           0           embedding_184[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_185 (Flatten)           (None, 64)           0           embedding_185[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_186 (Flatten)           (None, 64)           0           embedding_186[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_187 (Flatten)           (None, 64)           0           embedding_187[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_188 (Flatten)           (None, 64)           0           embedding_188[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_189 (Flatten)           (None, 64)           0           embedding_189[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_190 (Flatten)           (None, 64)           0           embedding_190[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_191 (Flatten)           (None, 64)           0           embedding_191[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_192 (Flatten)           (None, 64)           0           embedding_192[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_193 (Flatten)           (None, 64)           0           embedding_193[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_194 (Flatten)           (None, 64)           0           embedding_194[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_195 (Flatten)           (None, 64)           0           embedding_195[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_196 (Flatten)           (None, 64)           0           embedding_196[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_197 (Flatten)           (None, 64)           0           embedding_197[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_198 (Flatten)           (None, 64)           0           embedding_198[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_199 (Flatten)           (None, 64)           0           embedding_199[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_200 (Flatten)           (None, 64)           0           embedding_200[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_201 (Flatten)           (None, 64)           0           embedding_201[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_202 (Flatten)           (None, 64)           0           embedding_202[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_203 (Flatten)           (None, 64)           0           embedding_203[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_204 (Flatten)           (None, 64)           0           embedding_204[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_205 (Flatten)           (None, 64)           0           embedding_205[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_206 (Flatten)           (None, 64)           0           embedding_206[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_207 (Flatten)           (None, 64)           0           embedding_207[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_208 (Flatten)           (None, 64)           0           embedding_208[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_209 (Flatten)           (None, 64)           0           embedding_209[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_210 (Flatten)           (None, 64)           0           embedding_210[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_211 (Flatten)           (None, 64)           0           embedding_211[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_212 (Flatten)           (None, 64)           0           embedding_212[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_213 (Flatten)           (None, 64)           0           embedding_213[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_214 (Flatten)           (None, 64)           0           embedding_214[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_215 (Flatten)           (None, 64)           0           embedding_215[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_216 (Flatten)           (None, 64)           0           embedding_216[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_217 (Flatten)           (None, 64)           0           embedding_217[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_218 (Flatten)           (None, 64)           0           embedding_218[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_219 (Flatten)           (None, 64)           0           embedding_219[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_220 (Flatten)           (None, 64)           0           embedding_220[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_221 (Flatten)           (None, 64)           0           embedding_221[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_222 (Flatten)           (None, 64)           0           embedding_222[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_223 (Flatten)           (None, 64)           0           embedding_223[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_224 (Flatten)           (None, 64)           0           embedding_224[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_225 (Flatten)           (None, 64)           0           embedding_225[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_226 (Flatten)           (None, 64)           0           embedding_226[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_227 (Flatten)           (None, 64)           0           embedding_227[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_228 (Flatten)           (None, 64)           0           embedding_228[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_229 (Flatten)           (None, 64)           0           embedding_229[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_230 (Flatten)           (None, 64)           0           embedding_230[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_231 (Flatten)           (None, 64)           0           embedding_231[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_232 (Flatten)           (None, 64)           0           embedding_232[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_233 (Flatten)           (None, 64)           0           embedding_233[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_234 (Flatten)           (None, 64)           0           embedding_234[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_235 (Flatten)           (None, 64)           0           embedding_235[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_236 (Flatten)           (None, 64)           0           embedding_236[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_237 (Flatten)           (None, 64)           0           embedding_237[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4027)         0           flatten_176[0][0]                \n",
      "                                                                 flatten_177[0][0]                \n",
      "                                                                 flatten_178[0][0]                \n",
      "                                                                 flatten_179[0][0]                \n",
      "                                                                 flatten_180[0][0]                \n",
      "                                                                 flatten_181[0][0]                \n",
      "                                                                 flatten_182[0][0]                \n",
      "                                                                 flatten_183[0][0]                \n",
      "                                                                 flatten_184[0][0]                \n",
      "                                                                 flatten_185[0][0]                \n",
      "                                                                 flatten_186[0][0]                \n",
      "                                                                 flatten_187[0][0]                \n",
      "                                                                 flatten_188[0][0]                \n",
      "                                                                 flatten_189[0][0]                \n",
      "                                                                 flatten_190[0][0]                \n",
      "                                                                 flatten_191[0][0]                \n",
      "                                                                 flatten_192[0][0]                \n",
      "                                                                 flatten_193[0][0]                \n",
      "                                                                 flatten_194[0][0]                \n",
      "                                                                 flatten_195[0][0]                \n",
      "                                                                 flatten_196[0][0]                \n",
      "                                                                 flatten_197[0][0]                \n",
      "                                                                 flatten_198[0][0]                \n",
      "                                                                 flatten_199[0][0]                \n",
      "                                                                 flatten_200[0][0]                \n",
      "                                                                 flatten_201[0][0]                \n",
      "                                                                 flatten_202[0][0]                \n",
      "                                                                 flatten_203[0][0]                \n",
      "                                                                 flatten_204[0][0]                \n",
      "                                                                 flatten_205[0][0]                \n",
      "                                                                 flatten_206[0][0]                \n",
      "                                                                 flatten_207[0][0]                \n",
      "                                                                 flatten_208[0][0]                \n",
      "                                                                 flatten_209[0][0]                \n",
      "                                                                 flatten_210[0][0]                \n",
      "                                                                 flatten_211[0][0]                \n",
      "                                                                 flatten_212[0][0]                \n",
      "                                                                 flatten_213[0][0]                \n",
      "                                                                 flatten_214[0][0]                \n",
      "                                                                 flatten_215[0][0]                \n",
      "                                                                 flatten_216[0][0]                \n",
      "                                                                 flatten_217[0][0]                \n",
      "                                                                 flatten_218[0][0]                \n",
      "                                                                 flatten_219[0][0]                \n",
      "                                                                 flatten_220[0][0]                \n",
      "                                                                 flatten_221[0][0]                \n",
      "                                                                 flatten_222[0][0]                \n",
      "                                                                 flatten_223[0][0]                \n",
      "                                                                 flatten_224[0][0]                \n",
      "                                                                 flatten_225[0][0]                \n",
      "                                                                 flatten_226[0][0]                \n",
      "                                                                 flatten_227[0][0]                \n",
      "                                                                 flatten_228[0][0]                \n",
      "                                                                 flatten_229[0][0]                \n",
      "                                                                 flatten_230[0][0]                \n",
      "                                                                 flatten_231[0][0]                \n",
      "                                                                 flatten_232[0][0]                \n",
      "                                                                 flatten_233[0][0]                \n",
      "                                                                 flatten_234[0][0]                \n",
      "                                                                 flatten_235[0][0]                \n",
      "                                                                 flatten_236[0][0]                \n",
      "                                                                 flatten_237[0][0]                \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 VL[0][0]                         \n",
      "                                                                 Months_to_ini_VS[0][0]           \n",
      "                                                                 VR_N[0][0]                       \n",
      "                                                                 prop_time[0][0]                  \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 VL_1[0][0]                       \n",
      "                                                                 Months_to_ini_VS_1[0][0]         \n",
      "                                                                 VR_N_1[0][0]                     \n",
      "                                                                 prop_time_1[0][0]                \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 64)           257792      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64)           0           dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 64)           4160        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ple_layer_2 (PleLayer)          [(None, 16), (None,  5785        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            17          ple_layer_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "VR (Dense)                      (None, 1)            17          ple_layer_2[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "VB (Dense)                      (None, 1)            17          ple_layer_2[0][2]                \n",
      "==================================================================================================\n",
      "Total params: 283,148\n",
      "Trainable params: 283,148\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_ple(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 16,\n",
    "          varlens_cols = varlen_features,varlens_max_len = varlens_max_len,dnn_hidden_units = (64,64),\n",
    "          n_task = 3,n_experts = [1,1,1],n_expert_share = 2,dnn_reg_l2 = 0.001,\n",
    "          drop_rate = 0.1,embedding_reg_l2 = 0.001,targets = target)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f74b20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "242/242 [==============================] - 18s 74ms/step - loss: 1.0490 - VS_loss: 0.4621 - VR_loss: 0.4000 - VB_loss: 0.1132 - VS_accuracy: 0.8153 - VR_accuracy: 0.8750 - VB_accuracy: 0.9768 - val_loss: 0.9382 - val_VS_loss: 0.4203 - val_VR_loss: 0.3359 - val_VB_loss: 0.1093 - val_VS_accuracy: 0.8429 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 2/20\n",
      "242/242 [==============================] - 21s 88ms/step - loss: 1.1823 - VS_loss: 0.5790 - VR_loss: 0.4067 - VB_loss: 0.1216 - VS_accuracy: 0.7884 - VR_accuracy: 0.8748 - VB_accuracy: 0.9768 - val_loss: 0.9960 - val_VS_loss: 0.4721 - val_VR_loss: 0.3355 - val_VB_loss: 0.1110 - val_VS_accuracy: 0.8123 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 3/20\n",
      "242/242 [==============================] - 17s 72ms/step - loss: 1.0712 - VS_loss: 0.5016 - VR_loss: 0.3809 - VB_loss: 0.1130 - VS_accuracy: 0.7958 - VR_accuracy: 0.8748 - VB_accuracy: 0.9768 - val_loss: 0.9664 - val_VS_loss: 0.4456 - val_VR_loss: 0.3355 - val_VB_loss: 0.1101 - val_VS_accuracy: 0.8276 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 4/20\n",
      "242/242 [==============================] - 16s 67ms/step - loss: 1.0509 - VS_loss: 0.4745 - VR_loss: 0.3945 - VB_loss: 0.1080 - VS_accuracy: 0.8096 - VR_accuracy: 0.8750 - VB_accuracy: 0.9768 - val_loss: 0.9458 - val_VS_loss: 0.4268 - val_VR_loss: 0.3357 - val_VB_loss: 0.1103 - val_VS_accuracy: 0.8381 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 5/20\n",
      "242/242 [==============================] - 18s 73ms/step - loss: 1.0191 - VS_loss: 0.4623 - VR_loss: 0.3770 - VB_loss: 0.1081 - VS_accuracy: 0.8223 - VR_accuracy: 0.8749 - VB_accuracy: 0.9769 - val_loss: 0.9379 - val_VS_loss: 0.4216 - val_VR_loss: 0.3351 - val_VB_loss: 0.1100 - val_VS_accuracy: 0.8401 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 6/20\n",
      "242/242 [==============================] - 16s 67ms/step - loss: 1.0027 - VS_loss: 0.4475 - VR_loss: 0.3769 - VB_loss: 0.1080 - VS_accuracy: 0.8212 - VR_accuracy: 0.8750 - VB_accuracy: 0.9769 - val_loss: 0.9392 - val_VS_loss: 0.4249 - val_VR_loss: 0.3357 - val_VB_loss: 0.1099 - val_VS_accuracy: 0.8404 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 7/20\n",
      "242/242 [==============================] - 18s 73ms/step - loss: 0.9977 - VS_loss: 0.4456 - VR_loss: 0.3773 - VB_loss: 0.1071 - VS_accuracy: 0.8236 - VR_accuracy: 0.8749 - VB_accuracy: 0.9769 - val_loss: 0.9288 - val_VS_loss: 0.4167 - val_VR_loss: 0.3360 - val_VB_loss: 0.1096 - val_VS_accuracy: 0.8441 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 8/20\n",
      "242/242 [==============================] - 17s 69ms/step - loss: 0.9831 - VS_loss: 0.4340 - VR_loss: 0.3769 - VB_loss: 0.1065 - VS_accuracy: 0.8299 - VR_accuracy: 0.8749 - VB_accuracy: 0.9769 - val_loss: 0.9197 - val_VS_loss: 0.4126 - val_VR_loss: 0.3343 - val_VB_loss: 0.1078 - val_VS_accuracy: 0.8457 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 9/20\n",
      "242/242 [==============================] - 17s 69ms/step - loss: 1.0148 - VS_loss: 0.4493 - VR_loss: 0.3811 - VB_loss: 0.1192 - VS_accuracy: 0.8339 - VR_accuracy: 0.8749 - VB_accuracy: 0.9768 - val_loss: 0.9175 - val_VS_loss: 0.4087 - val_VR_loss: 0.3343 - val_VB_loss: 0.1098 - val_VS_accuracy: 0.8481 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "242/242 [==============================] - 17s 69ms/step - loss: 5.9244 - VS_loss: 0.5446 - VR_loss: 5.1678 - VB_loss: 0.1429 - VS_accuracy: 0.7822 - VR_accuracy: 0.8749 - VB_accuracy: 0.9767 - val_loss: 1.1009 - val_VS_loss: 0.5752 - val_VR_loss: 0.3362 - val_VB_loss: 0.1101 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "242/242 [==============================] - 17s 71ms/step - loss: 1.1728 - VS_loss: 0.6069 - VR_loss: 0.3779 - VB_loss: 0.1098 - VS_accuracy: 0.7051 - VR_accuracy: 0.8749 - VB_accuracy: 0.9769 - val_loss: 1.0932 - val_VS_loss: 0.5709 - val_VR_loss: 0.3351 - val_VB_loss: 0.1115 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "242/242 [==============================] - 17s 70ms/step - loss: 1.1669 - VS_loss: 0.6064 - VR_loss: 0.3769 - VB_loss: 0.1095 - VS_accuracy: 0.7052 - VR_accuracy: 0.8750 - VB_accuracy: 0.9769 - val_loss: 1.0911 - val_VS_loss: 0.5736 - val_VR_loss: 0.3364 - val_VB_loss: 0.1088 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 13/20\n",
      "242/242 [==============================] - 17s 71ms/step - loss: 1.5964 - VS_loss: 0.6063 - VR_loss: 0.3770 - VB_loss: 0.5424 - VS_accuracy: 0.7052 - VR_accuracy: 0.8750 - VB_accuracy: 0.9768 - val_loss: 1.0848 - val_VS_loss: 0.5714 - val_VR_loss: 0.3346 - val_VB_loss: 0.1094 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 14/20\n",
      "242/242 [==============================] - 17s 69ms/step - loss: 1.1751 - VS_loss: 0.6101 - VR_loss: 0.3766 - VB_loss: 0.1203 - VS_accuracy: 0.7053 - VR_accuracy: 0.8750 - VB_accuracy: 0.9768 - val_loss: 1.0799 - val_VS_loss: 0.5675 - val_VR_loss: 0.3346 - val_VB_loss: 0.1104 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 15/20\n",
      "242/242 [==============================] - 18s 73ms/step - loss: 1.2229 - VS_loss: 0.6055 - VR_loss: 0.3759 - VB_loss: 0.1729 - VS_accuracy: 0.7138 - VR_accuracy: 0.8750 - VB_accuracy: 0.9769 - val_loss: 1.0849 - val_VS_loss: 0.5718 - val_VR_loss: 0.3346 - val_VB_loss: 0.1091 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 16/20\n",
      "242/242 [==============================] - 17s 71ms/step - loss: 1.1600 - VS_loss: 0.6083 - VR_loss: 0.3770 - VB_loss: 0.1067 - VS_accuracy: 0.7050 - VR_accuracy: 0.8750 - VB_accuracy: 0.9768 - val_loss: 1.0806 - val_VS_loss: 0.5718 - val_VR_loss: 0.3352 - val_VB_loss: 0.1072 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 17/20\n",
      "242/242 [==============================] - 17s 71ms/step - loss: 1.1583 - VS_loss: 0.6079 - VR_loss: 0.3787 - VB_loss: 0.1070 - VS_accuracy: 0.7051 - VR_accuracy: 0.8749 - VB_accuracy: 0.9769 - val_loss: 1.0770 - val_VS_loss: 0.5709 - val_VR_loss: 0.3350 - val_VB_loss: 0.1081 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "242/242 [==============================] - 17s 70ms/step - loss: 1.1695 - VS_loss: 0.6063 - VR_loss: 0.3768 - VB_loss: 0.1249 - VS_accuracy: 0.7051 - VR_accuracy: 0.8750 - VB_accuracy: 0.9767 - val_loss: 1.0732 - val_VS_loss: 0.5713 - val_VR_loss: 0.3351 - val_VB_loss: 0.1070 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 19/20\n",
      "242/242 [==============================] - 21s 86ms/step - loss: 1.1488 - VS_loss: 0.6066 - VR_loss: 0.3776 - VB_loss: 0.1062 - VS_accuracy: 0.7052 - VR_accuracy: 0.8749 - VB_accuracy: 0.9769 - val_loss: 1.0725 - val_VS_loss: 0.5736 - val_VR_loss: 0.3358 - val_VB_loss: 0.1063 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n",
      "Epoch 20/20\n",
      "242/242 [==============================] - 17s 70ms/step - loss: 1.1613 - VS_loss: 0.6097 - VR_loss: 0.3785 - VB_loss: 0.1175 - VS_accuracy: 0.7051 - VR_accuracy: 0.8748 - VB_accuracy: 0.9768 - val_loss: 1.0721 - val_VS_loss: 0.5744 - val_VR_loss: 0.3366 - val_VB_loss: 0.1070 - val_VS_accuracy: 0.7442 - val_VR_accuracy: 0.8964 - val_VB_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "411c7933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6958191],\n",
       "        [0.6958191],\n",
       "        [0.6958191],\n",
       "        ...,\n",
       "        [0.6958191],\n",
       "        [0.6958191],\n",
       "        [0.6958191]], dtype=float32),\n",
       " array([[0.13125898],\n",
       "        [0.13125898],\n",
       "        [0.13125898],\n",
       "        ...,\n",
       "        [0.13125898],\n",
       "        [0.13125898],\n",
       "        [0.13125898]], dtype=float32),\n",
       " array([[0.03083998],\n",
       "        [0.03083998],\n",
       "        [0.03083998],\n",
       "        ...,\n",
       "        [0.03083998],\n",
       "        [0.03083998],\n",
       "        [0.03083998]], dtype=float32)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5adaa826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.9046673286991063\n",
      "0.974180734856008\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3beae12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5903414882772681\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9218eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tfgpu] *",
   "language": "python",
   "name": "conda-env-.conda-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
