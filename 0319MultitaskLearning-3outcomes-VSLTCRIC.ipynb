{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c792c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "from tensorflow.keras import optimizers,initializers\n",
    "from tensorflow.python.keras.initializers import glorot_normal\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c1da42",
   "metadata": {},
   "source": [
    "https://github.com/ShowMeAI-Hub/multi-task-learning/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3eecdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_origin = pd.read_excel('D:/OneDrive - University of South Carolina/Research/multitasking learning/data cleaning/DHEC_tests_final_lag1.xlsx', sheet_name='Sheet1', engine='openpyxl')\n",
    "variables = pd.read_excel(\"D:/OneDrive - University of South Carolina/Research/multitasking learning/data cleaning/0130variables-VSLTCRIC.xlsx\", sheet_name='Sheet1', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3db2f6",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1596b04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VS</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "      <th>region</th>\n",
       "      <th>CD4_baseline</th>\n",
       "      <th>VL_baseline_interpretation</th>\n",
       "      <th>VL_baseline</th>\n",
       "      <th>linkage</th>\n",
       "      <th>retention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>401.0</td>\n",
       "      <td>=</td>\n",
       "      <td>160288.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>414.0</td>\n",
       "      <td>=</td>\n",
       "      <td>15127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>=</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40279 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  VS  dx_yr  dx_mth  age  \\\n",
       "0                591.000000                       2   0   2005      12   39   \n",
       "1               1018.000000                       3   0   2005      12   39   \n",
       "2               2072.250000                       6   1   2005      12   39   \n",
       "3               2495.333333                       7   1   2005      12   39   \n",
       "4               2793.333333                       8   1   2005      12   39   \n",
       "...                     ...                     ...  ..    ...     ...  ...   \n",
       "40274           2737.500000                       8   1   2009       9   48   \n",
       "40275           3193.000000                       9   1   2009       9   48   \n",
       "40276           3499.666667                      10   1   2009       9   48   \n",
       "40277           3884.000000                      11   1   2009       9   48   \n",
       "40278            755.000000                       2   0   2016      11   21   \n",
       "\n",
       "      sex   race    risk region  CD4_baseline VL_baseline_interpretation  \\\n",
       "0       F  Black  Others  Urban         401.0                          =   \n",
       "1       F  Black  Others  Urban         401.0                          =   \n",
       "2       F  Black  Others  Urban         401.0                          =   \n",
       "3       F  Black  Others  Urban         401.0                          =   \n",
       "4       F  Black  Others  Urban         401.0                          =   \n",
       "...    ..    ...     ...    ...           ...                        ...   \n",
       "40274   M  Black     MSM  Urban         414.0                          =   \n",
       "40275   M  Black     MSM  Urban         414.0                          =   \n",
       "40276   M  Black     MSM  Urban         414.0                          =   \n",
       "40277   M  Black     MSM  Urban         414.0                          =   \n",
       "40278   M  Black     MSM  Urban        1012.0                          =   \n",
       "\n",
       "       VL_baseline  linkage  retention  \n",
       "0         160288.0        0          0  \n",
       "1         160288.0        0          0  \n",
       "2         160288.0        0          1  \n",
       "3         160288.0        0          1  \n",
       "4         160288.0        0          1  \n",
       "...            ...      ...        ...  \n",
       "40274      15127.0        1          1  \n",
       "40275      15127.0        1          1  \n",
       "40276      15127.0        1          1  \n",
       "40277      15127.0        1          1  \n",
       "40278        200.0        0          0  \n",
       "\n",
       "[40279 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = variables[variables['model1'] != 'delete']\n",
    "data = data_origin[temp['variables'].tolist()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7bfc2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = variables[variables['model1'] == 'outcome']['variables'].tolist()\n",
    "sparse_features = variables[variables['model1'] == 'cat']['variables'].tolist()\n",
    "dense_features = variables[variables['model1'] == 'num']['variables'].tolist()\n",
    "varlen_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25637d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'race', 'risk', 'region', 'VL_baseline_interpretation']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b174052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_46932\\2408031544.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n"
     ]
    }
   ],
   "source": [
    "encoder = {}\n",
    "# 稀疏特征编码\n",
    "for featid in sparse_features:\n",
    "    # print(f\"编码ID字段：{featid}\")\n",
    "    encoder[featid] = {uid:ucode+1 for ucode,uid in enumerate(data[featid].unique())} \n",
    "    data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n",
    "    \n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfd1dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(data.shape[0] * 0.6)\n",
    "n_val = round(data.shape[0] * 0.2)\n",
    "\n",
    "train = data[:n_train]\n",
    "val = data[n_train:(n_train+n_val)]\n",
    "test = data[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f218a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "test_labels = [test[y].values for y in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba174a2d",
   "metadata": {},
   "source": [
    "### Seperate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dba16a",
   "metadata": {},
   "source": [
    "#### VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "617d0be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "      <th>region</th>\n",
       "      <th>CD4_baseline</th>\n",
       "      <th>VL_baseline_interpretation</th>\n",
       "      <th>VL_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32218</th>\n",
       "      <td>1693.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32219</th>\n",
       "      <td>1964.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32220</th>\n",
       "      <td>2392.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32221</th>\n",
       "      <td>2771.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32222</th>\n",
       "      <td>3022.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "      <td>41899.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32223 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  dx_yr  dx_mth  age  sex  \\\n",
       "0                591.000000                       2   2005      12   39    1   \n",
       "1               1018.000000                       3   2005      12   39    1   \n",
       "2               2072.250000                       6   2005      12   39    1   \n",
       "3               2495.333333                       7   2005      12   39    1   \n",
       "4               2793.333333                       8   2005      12   39    1   \n",
       "...                     ...                     ...    ...     ...  ...  ...   \n",
       "32218           1693.000000                       5   2009       4   47    2   \n",
       "32219           1964.000000                       6   2009       4   47    2   \n",
       "32220           2392.500000                       7   2009       4   47    2   \n",
       "32221           2771.000000                       8   2009       4   47    2   \n",
       "32222           3022.000000                       9   2009       4   47    2   \n",
       "\n",
       "       race  risk  region  CD4_baseline  VL_baseline_interpretation  \\\n",
       "0         1     1       1         401.0                           1   \n",
       "1         1     1       1         401.0                           1   \n",
       "2         1     1       1         401.0                           1   \n",
       "3         1     1       1         401.0                           1   \n",
       "4         1     1       1         401.0                           1   \n",
       "...     ...   ...     ...           ...                         ...   \n",
       "32218     1     3       1          94.0                           1   \n",
       "32219     1     3       1          94.0                           1   \n",
       "32220     1     3       1          94.0                           1   \n",
       "32221     1     3       1          94.0                           1   \n",
       "32222     1     3       1          94.0                           1   \n",
       "\n",
       "       VL_baseline  \n",
       "0         160288.0  \n",
       "1         160288.0  \n",
       "2         160288.0  \n",
       "3         160288.0  \n",
       "4         160288.0  \n",
       "...            ...  \n",
       "32218      41899.0  \n",
       "32219      41899.0  \n",
       "32220      41899.0  \n",
       "32221      41899.0  \n",
       "32222      41899.0  \n",
       "\n",
       "[32223 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VS\"]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d36c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_distribution(y):\n",
    "    class_counts = pd.Series(y).value_counts(normalize=True)  # 计算比例\n",
    "    print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d43087fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.714893\n",
      "0    0.285107\n",
      "Name: VS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "check_class_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db144e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,473\n",
      "Trainable params: 17,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e0cb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 2s 14ms/step - loss: 3643.7812 - accuracy: 0.6196 - val_loss: 32801.3086 - val_accuracy: 0.6580\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1526.8846 - accuracy: 0.5564 - val_loss: 1408.1959 - val_accuracy: 0.6687\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1555.8414 - accuracy: 0.5334 - val_loss: 7261.9946 - val_accuracy: 0.7544\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 2713.4912 - accuracy: 0.6066 - val_loss: 7016.7007 - val_accuracy: 0.3170\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1990.4755 - accuracy: 0.5710 - val_loss: 4346.1470 - val_accuracy: 0.7465\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1016.3265 - accuracy: 0.5709 - val_loss: 22773.2168 - val_accuracy: 0.7131\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1399.0951 - accuracy: 0.5642 - val_loss: 2271.7632 - val_accuracy: 0.3344\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 934.8597 - accuracy: 0.6049 - val_loss: 1721.3470 - val_accuracy: 0.3133\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1455.0531 - accuracy: 0.5149 - val_loss: 34912.5156 - val_accuracy: 0.7544\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 3500.1130 - accuracy: 0.5745 - val_loss: 3359.8223 - val_accuracy: 0.7243\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 644.8812 - accuracy: 0.5945 - val_loss: 262.6024 - val_accuracy: 0.4549\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 627.0239 - accuracy: 0.5897 - val_loss: 2730.0667 - val_accuracy: 0.7545\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 234.6991 - accuracy: 0.5848 - val_loss: 245.7803 - val_accuracy: 0.4759\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 719.6947 - accuracy: 0.5590 - val_loss: 639.3220 - val_accuracy: 0.3454\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3050.4448 - accuracy: 0.6652 - val_loss: 3393.3909 - val_accuracy: 0.6726\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 593.5443 - accuracy: 0.5742 - val_loss: 4146.8281 - val_accuracy: 0.7358\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 186.2774 - accuracy: 0.6021 - val_loss: 533.9479 - val_accuracy: 0.3297\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 555.2385 - accuracy: 0.5561 - val_loss: 2276.0225 - val_accuracy: 0.7255\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 174.6180 - accuracy: 0.6178 - val_loss: 2700.7122 - val_accuracy: 0.7130\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 121.3234 - accuracy: 0.5653 - val_loss: 736.4471 - val_accuracy: 0.2979\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c22cac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       ...,\n",
       "       [1.9143881e-05],\n",
       "       [1.3354896e-02],\n",
       "       [1.2945627e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13586709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.304369414101291\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7602228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517228936949581\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9adec",
   "metadata": {},
   "source": [
    "#### RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c242d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"retention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a301b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5675\n",
      "Logistic Regression AUC: 0.4912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\.conda\\envs\\tfgpu\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "log_reg = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "log_reg.fit(X_train.to_numpy(), np.array(y_train))\n",
    "\n",
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "log_pred_prob = log_reg.predict_proba(X_test)[:, 1]  # 获取正类的概率\n",
    "log_pred = (log_pred_prob > 0.5).astype(int)  # 转换为二分类预测\n",
    "\n",
    "# 计算 Accuracy 和 AUC\n",
    "log_accuracy = accuracy_score(test_labels[0], log_pred)\n",
    "log_auc = roc_auc_score(test_labels[0], log_pred_prob)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression AUC: {log_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b1b0289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,473\n",
      "Trainable params: 17,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['AUC'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d023f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 12ms/step - loss: 4003.1680 - auc: 0.4969 - val_loss: 7143.0132 - val_auc: 0.4965\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1667.6602 - auc: 0.5013 - val_loss: 628.0534 - val_auc: 0.4999\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 979.9077 - auc: 0.4947 - val_loss: 941.4921 - val_auc: 0.5001\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1054.4846 - auc: 0.5006 - val_loss: 12659.6709 - val_auc: 0.4879\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1024.0724 - auc: 0.4903 - val_loss: 20.3225 - val_auc: 0.5088\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 694.7341 - auc: 0.5003 - val_loss: 240.8504 - val_auc: 0.4999\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1112.4059 - auc: 0.5065 - val_loss: 11549.0703 - val_auc: 0.4934\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 908.5849 - auc: 0.5004 - val_loss: 107.1047 - val_auc: 0.5088\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 753.2424 - auc: 0.4944 - val_loss: 323.5843 - val_auc: 0.5004\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 670.7362 - auc: 0.4950 - val_loss: 70.2165 - val_auc: 0.5037\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 407.1056 - auc: 0.5053 - val_loss: 25.1319 - val_auc: 0.5141\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 631.8674 - auc: 0.5062 - val_loss: 814.8871 - val_auc: 0.5000\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1968.8680 - auc: 0.4962 - val_loss: 222.3811 - val_auc: 0.5000\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 769.5914 - auc: 0.4951 - val_loss: 21.1661 - val_auc: 0.5144\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 473.4202 - auc: 0.4971 - val_loss: 126.4677 - val_auc: 0.4989\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 473.2910 - auc: 0.4990 - val_loss: 252.2659 - val_auc: 0.5103\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 522.5218 - auc: 0.5004 - val_loss: 45.5100 - val_auc: 0.5107\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 330.5102 - auc: 0.5077 - val_loss: 389.6074 - val_auc: 0.5125\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 591.6690 - auc: 0.4995 - val_loss: 1120.8969 - val_auc: 0.4724\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 296.4201 - auc: 0.5122 - val_loss: 129.8391 - val_auc: 0.5097\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d64e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.88537973]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0246d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620407149950348\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac445d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5068592974793162\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000aed24",
   "metadata": {},
   "source": [
    "#### LTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9ff5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"linkage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b00dc1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,473\n",
      "Trainable params: 17,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41fda4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 3892.3950 - accuracy: 0.6252 - val_loss: 81453.9844 - val_accuracy: 0.6925\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 2405.5322 - accuracy: 0.5951 - val_loss: 16388.8887 - val_accuracy: 0.6276\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 327.0363 - accuracy: 0.5823 - val_loss: 534.7205 - val_accuracy: 0.5452\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 444.3952 - accuracy: 0.5949 - val_loss: 32937.6523 - val_accuracy: 0.6925\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 808.4762 - accuracy: 0.5801 - val_loss: 2747.5989 - val_accuracy: 0.6441\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 547.1274 - accuracy: 0.6132 - val_loss: 4451.8521 - val_accuracy: 0.5893\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 403.2219 - accuracy: 0.6127 - val_loss: 20222.7344 - val_accuracy: 0.6829\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 2568.1729 - accuracy: 0.6530 - val_loss: 50403.6250 - val_accuracy: 0.6844\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 954.7145 - accuracy: 0.5725 - val_loss: 583.1340 - val_accuracy: 0.3497\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 257.2090 - accuracy: 0.5389 - val_loss: 3619.5784 - val_accuracy: 0.6433\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 163.9397 - accuracy: 0.5712 - val_loss: 500.2530 - val_accuracy: 0.4455\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 107.6422 - accuracy: 0.5690 - val_loss: 197.4644 - val_accuracy: 0.4284\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 168.4837 - accuracy: 0.5933 - val_loss: 6310.2241 - val_accuracy: 0.6790\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 224.3051 - accuracy: 0.6006 - val_loss: 494.0748 - val_accuracy: 0.3092\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1343.9803 - accuracy: 0.6168 - val_loss: 70838.7812 - val_accuracy: 0.6925\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1525.7825 - accuracy: 0.5942 - val_loss: 5438.8208 - val_accuracy: 0.6450\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 190.4954 - accuracy: 0.5905 - val_loss: 2941.7661 - val_accuracy: 0.5294\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1531.7957 - accuracy: 0.6427 - val_loss: 10664.1602 - val_accuracy: 0.6008\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 271.6489 - accuracy: 0.5757 - val_loss: 101.8887 - val_accuracy: 0.3718\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 193.0960 - accuracy: 0.5881 - val_loss: 1137.8934 - val_accuracy: 0.5538\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84b95fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       [0.0000000e+00],\n",
       "       ...,\n",
       "       [4.7233419e-12],\n",
       "       [2.0811015e-14],\n",
       "       [1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3831d012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a09328e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5579107755259762\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8333b",
   "metadata": {},
   "source": [
    "### MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c3b041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers\n",
    "\n",
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc8e3317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 32)        96          sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 32)        160         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 32)        160         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 32)        96          region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 32)        96          VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 32)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 32)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 167)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           5376        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           2112        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer (MmoeLayer)          [(None, 8), (None, 8 1452        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            9           mmoe_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "linkage (Dense)                 (None, 1)            9           mmoe_layer[0][1]                 \n",
      "__________________________________________________________________________________________________\n",
      "retention (Dense)               (None, 1)            9           mmoe_layer[0][2]                 \n",
      "==================================================================================================\n",
      "Total params: 11,655\n",
      "Trainable params: 11,655\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_mmoe(sparse_features,dense_features,sparse_max_len,embed_dim = 32,expert_dim = 8,\n",
    "          n_task = 3,n_expert = 4,varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "          dnn_hidden_units = (32,64,32),target = target,dnn_reg_l2 = 0.001,drop_rate = 0.1)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6cd34b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 2s 30ms/step - loss: 3860.0076 - VS_loss: 1748.6101 - linkage_loss: 694.0479 - retention_loss: 1417.2137 - VS_accuracy: 0.5471 - linkage_accuracy: 0.5303 - retention_accuracy: 0.7132 - val_loss: 1408.4767 - val_VS_loss: 276.5470 - val_linkage_loss: 1004.9866 - val_retention_loss: 126.8167 - val_VS_accuracy: 0.7430 - val_linkage_accuracy: 0.6939 - val_retention_accuracy: 0.7663\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 0s 19ms/step - loss: 2257.4983 - VS_loss: 827.0262 - linkage_loss: 333.1529 - retention_loss: 1097.1987 - VS_accuracy: 0.5704 - linkage_accuracy: 0.5988 - retention_accuracy: 0.7310 - val_loss: 2746.1060 - val_VS_loss: 2134.8218 - val_linkage_loss: 568.9769 - val_retention_loss: 42.1928 - val_VS_accuracy: 0.7439 - val_linkage_accuracy: 0.6970 - val_retention_accuracy: 0.7612\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 1915.1398 - VS_loss: 1081.3909 - linkage_loss: 198.5350 - retention_loss: 635.1031 - VS_accuracy: 0.5623 - linkage_accuracy: 0.5929 - retention_accuracy: 0.7113 - val_loss: 327.0262 - val_VS_loss: 281.7905 - val_linkage_loss: 1.4379 - val_retention_loss: 43.6920 - val_VS_accuracy: 0.6106 - val_linkage_accuracy: 0.6512 - val_retention_accuracy: 0.6976\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 1523.8451 - VS_loss: 582.2078 - linkage_loss: 361.1712 - retention_loss: 580.3628 - VS_accuracy: 0.5048 - linkage_accuracy: 0.6043 - retention_accuracy: 0.7167 - val_loss: 1190.7253 - val_VS_loss: 337.2821 - val_linkage_loss: 815.3107 - val_retention_loss: 38.0325 - val_VS_accuracy: 0.4320 - val_linkage_accuracy: 0.6853 - val_retention_accuracy: 0.6595\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 883.7812 - VS_loss: 438.1151 - linkage_loss: 283.6031 - retention_loss: 161.9648 - VS_accuracy: 0.5793 - linkage_accuracy: 0.6281 - retention_accuracy: 0.7032 - val_loss: 1321.5802 - val_VS_loss: 173.5101 - val_linkage_loss: 1051.6738 - val_retention_loss: 96.2998 - val_VS_accuracy: 0.4148 - val_linkage_accuracy: 0.6928 - val_retention_accuracy: 0.7342\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 927.0296 - VS_loss: 333.4961 - linkage_loss: 154.2042 - retention_loss: 439.2344 - VS_accuracy: 0.5908 - linkage_accuracy: 0.6347 - retention_accuracy: 0.6843 - val_loss: 2115.7219 - val_VS_loss: 517.0283 - val_linkage_loss: 101.8620 - val_retention_loss: 1496.7382 - val_VS_accuracy: 0.7345 - val_linkage_accuracy: 0.6905 - val_retention_accuracy: 0.2969\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 697.1741 - VS_loss: 354.8851 - linkage_loss: 100.7576 - retention_loss: 241.4389 - VS_accuracy: 0.5961 - linkage_accuracy: 0.5745 - retention_accuracy: 0.6176 - val_loss: 388.3563 - val_VS_loss: 140.6856 - val_linkage_loss: 0.7328 - val_retention_loss: 246.8464 - val_VS_accuracy: 0.5777 - val_linkage_accuracy: 0.3565 - val_retention_accuracy: 0.4024\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 653.2959 - VS_loss: 374.4104 - linkage_loss: 122.4984 - retention_loss: 156.2962 - VS_accuracy: 0.5977 - linkage_accuracy: 0.5299 - retention_accuracy: 0.5793 - val_loss: 3.2119 - val_VS_loss: 0.8692 - val_linkage_loss: 0.7591 - val_retention_loss: 1.4932 - val_VS_accuracy: 0.7145 - val_linkage_accuracy: 0.3460 - val_retention_accuracy: 0.7546\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 409.8811 - VS_loss: 235.2366 - linkage_loss: 109.5898 - retention_loss: 64.9648 - VS_accuracy: 0.5957 - linkage_accuracy: 0.4911 - retention_accuracy: 0.6439 - val_loss: 3.1206 - val_VS_loss: 0.7422 - val_linkage_loss: 0.7029 - val_retention_loss: 1.5860 - val_VS_accuracy: 0.6918 - val_linkage_accuracy: 0.3461 - val_retention_accuracy: 0.7363\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 236.9857 - VS_loss: 122.8700 - linkage_loss: 65.6467 - retention_loss: 48.3799 - VS_accuracy: 0.5957 - linkage_accuracy: 0.5813 - retention_accuracy: 0.6819 - val_loss: 2.2856 - val_VS_loss: 0.6632 - val_linkage_loss: 0.6943 - val_retention_loss: 0.8395 - val_VS_accuracy: 0.7236 - val_linkage_accuracy: 0.6967 - val_retention_accuracy: 0.8076\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 188.6329 - VS_loss: 84.8557 - linkage_loss: 61.3938 - retention_loss: 42.2951 - VS_accuracy: 0.6361 - linkage_accuracy: 0.6395 - retention_accuracy: 0.7139 - val_loss: 2.1000 - val_VS_loss: 0.6493 - val_linkage_loss: 0.6817 - val_retention_loss: 0.6812 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8049\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 294.2873 - VS_loss: 209.1522 - linkage_loss: 46.8499 - retention_loss: 38.1976 - VS_accuracy: 0.6545 - linkage_accuracy: 0.6466 - retention_accuracy: 0.7189 - val_loss: 2.0978 - val_VS_loss: 0.6450 - val_linkage_loss: 0.6777 - val_retention_loss: 0.6879 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6965 - val_retention_accuracy: 0.8150\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 266.6479 - VS_loss: 144.6335 - linkage_loss: 51.9575 - retention_loss: 69.9698 - VS_accuracy: 0.6770 - linkage_accuracy: 0.6340 - retention_accuracy: 0.7478 - val_loss: 36.1744 - val_VS_loss: 0.6409 - val_linkage_loss: 34.8527 - val_retention_loss: 0.5940 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8407\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 85.4431 - VS_loss: 38.4100 - linkage_loss: 29.6951 - retention_loss: 17.2513 - VS_accuracy: 0.6814 - linkage_accuracy: 0.6425 - retention_accuracy: 0.7922 - val_loss: 1.9814 - val_VS_loss: 0.6364 - val_linkage_loss: 0.6734 - val_retention_loss: 0.5853 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6965 - val_retention_accuracy: 0.8419\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 99.2877 - VS_loss: 69.1448 - linkage_loss: 15.1278 - retention_loss: 14.9290 - VS_accuracy: 0.6851 - linkage_accuracy: 0.6500 - retention_accuracy: 0.7975 - val_loss: 1.9656 - val_VS_loss: 0.6317 - val_linkage_loss: 0.6705 - val_retention_loss: 0.5777 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 85.3406 - VS_loss: 34.3333 - linkage_loss: 30.3242 - retention_loss: 20.5975 - VS_accuracy: 0.6920 - linkage_accuracy: 0.6382 - retention_accuracy: 0.7979 - val_loss: 1.9482 - val_VS_loss: 0.6272 - val_linkage_loss: 0.6649 - val_retention_loss: 0.5707 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 36.6620 - VS_loss: 20.2641 - linkage_loss: 8.2812 - retention_loss: 8.0315 - VS_accuracy: 0.6933 - linkage_accuracy: 0.6688 - retention_accuracy: 0.8106 - val_loss: 1.9315 - val_VS_loss: 0.6231 - val_linkage_loss: 0.6593 - val_retention_loss: 0.5641 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 35.1551 - VS_loss: 14.7609 - linkage_loss: 6.2674 - retention_loss: 14.0419 - VS_accuracy: 0.6948 - linkage_accuracy: 0.6962 - retention_accuracy: 0.8154 - val_loss: 1.9166 - val_VS_loss: 0.6191 - val_linkage_loss: 0.6552 - val_retention_loss: 0.5577 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 30.9578 - VS_loss: 10.5580 - linkage_loss: 4.5687 - retention_loss: 15.7467 - VS_accuracy: 0.6957 - linkage_accuracy: 0.6961 - retention_accuracy: 0.8165 - val_loss: 1.9025 - val_VS_loss: 0.6155 - val_linkage_loss: 0.6511 - val_retention_loss: 0.5516 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 15ms/step - loss: 18.5258 - VS_loss: 6.8651 - linkage_loss: 4.5576 - retention_loss: 7.0188 - VS_accuracy: 0.7004 - linkage_accuracy: 0.6960 - retention_accuracy: 0.8208 - val_loss: 1.8911 - val_VS_loss: 0.6121 - val_linkage_loss: 0.6490 - val_retention_loss: 0.5458 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3dd99e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6041793],\n",
       "        [0.6041793],\n",
       "        [0.6041793],\n",
       "        ...,\n",
       "        [0.6041793],\n",
       "        [0.6041793],\n",
       "        [0.6041793]], dtype=float32),\n",
       " array([[0.5675649 ],\n",
       "        [0.5675649 ],\n",
       "        [0.5675649 ],\n",
       "        ...,\n",
       "        [0.5675649 ],\n",
       "        [0.5675649 ],\n",
       "        [0.65216166]], dtype=float32),\n",
       " array([[0.63046795],\n",
       "        [0.63046795],\n",
       "        [0.63046795],\n",
       "        ...,\n",
       "        [0.63046795],\n",
       "        [0.63046795],\n",
       "        [0.63046795]], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42ea4a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.7671300893743793\n",
      "0.8259682224428997\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc0af1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5052839995583801\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b08b7bf",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1132e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class PleLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    n_experts:list,每个任务使用几个expert。[2,3]第一个任务使用2个expert，第二个任务使用3个expert。\n",
    "    n_expert_share:int,共享的部分设置的expert个数。\n",
    "    expert_dim:int,每个专家网络输出的向量维度。\n",
    "    n_task:int,任务个数。\n",
    "    '''\n",
    "    def __init__(self,n_task,n_experts,expert_dim,n_expert_share,dnn_reg_l2 = 1e-5):\n",
    "        super(PleLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        \n",
    "        # 生成多个任务特定网络和1个共享网络。\n",
    "        self.E_layer = []\n",
    "        for i in range(n_task):\n",
    "            sub_exp = [Dense(expert_dim,activation = 'relu') for j in range(n_experts[i])]\n",
    "            self.E_layer.append(sub_exp)\n",
    "            \n",
    "        self.share_layer = [Dense(expert_dim,activation = 'relu') for j in range(n_expert_share)]\n",
    "        #定义门控网络\n",
    "        self.gate_layers = [Dense(n_expert_share+n_experts[i],kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                                  activation = 'softmax') for i in range(n_task)]\n",
    "\n",
    "    def call(self,x):\n",
    "        #特定网络和共享网络\n",
    "        E_net = [[expert(x) for expert in sub_expert] for sub_expert in self.E_layer]\n",
    "        share_net = [expert(x) for expert in self.share_layer]\n",
    "        \n",
    "        #门的权重乘上，指定任务和共享任务的输出。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = self.gate_layers[i](x)\n",
    "            g = tf.expand_dims(g,axis = -1) #(bs,n_expert_share+n_experts[i],1)\n",
    "            _e = share_net+E_net[i]  \n",
    "            _e = Concatenate(axis = 1)([expert[:,tf.newaxis,:] for expert in _e]) #(bs,n_expert_share+n_experts[i],expert_dim)\n",
    "            _tower = tf.matmul(_e, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower)) #(bs,expert_dim)\n",
    "        return towers\n",
    "\n",
    "def build_ple(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim = 4,\n",
    "              varlens_cols = [],varlens_max_len = [],dnn_hidden_units = (64,64),\n",
    "              n_task = 2,n_experts = [2,2],n_expert_share = 4,dnn_reg_l2 = 1e-6,\n",
    "              drop_rate = 0.0,embedding_reg_l2 = 1e-6,targets = []):\n",
    "\n",
    "   #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])    \n",
    "                                  \n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    #Ple网络层\n",
    "    towers = PleLayer(n_task,n_experts,expert_dim,n_expert_share)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid',kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                       name = f,use_bias = True)(_t) for f,_t in zip(targets,towers)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d355852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 64)           0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 64)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 64)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 64)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 327)          0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           20992       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64)           4160        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ple_layer (PleLayer)            [(None, 16), (None,  5785        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            17          ple_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "linkage (Dense)                 (None, 1)            17          ple_layer[0][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "retention (Dense)               (None, 1)            17          ple_layer[0][2]                  \n",
      "==================================================================================================\n",
      "Total params: 32,204\n",
      "Trainable params: 32,204\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_ple(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 16,\n",
    "          varlens_cols = varlen_features,varlens_max_len = varlens_max_len,dnn_hidden_units = (64,64),\n",
    "          n_task = 3,n_experts = [1,1,1],n_expert_share = 2,dnn_reg_l2 = 0.001,\n",
    "          drop_rate = 0.1,embedding_reg_l2 = 0.001,targets = target)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc2b3cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 4s 48ms/step - loss: 5585.0957 - VS_loss: 3462.7629 - linkage_loss: 1191.8312 - retention_loss: 930.3781 - VS_accuracy: 0.5959 - linkage_accuracy: 0.5954 - retention_accuracy: 0.6851 - val_loss: 2412.0095 - val_VS_loss: 301.5742 - val_linkage_loss: 343.3718 - val_retention_loss: 1766.9329 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.3592 - val_retention_accuracy: 0.3292\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 538.9778 - VS_loss: 255.0327 - linkage_loss: 74.0181 - retention_loss: 209.7876 - VS_accuracy: 0.5895 - linkage_accuracy: 0.5744 - retention_accuracy: 0.7627 - val_loss: 748.1414 - val_VS_loss: 746.7322 - val_linkage_loss: 0.6776 - val_retention_loss: 0.6059 - val_VS_accuracy: 0.7447 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 360.5919 - VS_loss: 353.9021 - linkage_loss: 2.6620 - retention_loss: 3.9235 - VS_accuracy: 0.6033 - linkage_accuracy: 0.6968 - retention_accuracy: 0.8268 - val_loss: 524.8415 - val_VS_loss: 523.5698 - val_linkage_loss: 0.6410 - val_retention_loss: 0.5422 - val_VS_accuracy: 0.3078 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 457.5434 - VS_loss: 438.9709 - linkage_loss: 11.1530 - retention_loss: 7.3347 - VS_accuracy: 0.4339 - linkage_accuracy: 0.6903 - retention_accuracy: 0.8282 - val_loss: 1.9071 - val_VS_loss: 0.7018 - val_linkage_loss: 0.6229 - val_retention_loss: 0.5013 - val_VS_accuracy: 0.2558 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 8.3292 - VS_loss: 4.6710 - linkage_loss: 1.4715 - retention_loss: 2.1093 - VS_accuracy: 0.6047 - linkage_accuracy: 0.6960 - retention_accuracy: 0.8289 - val_loss: 1.8197 - val_VS_loss: 0.6529 - val_linkage_loss: 0.6161 - val_retention_loss: 0.4769 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 4.3321 - VS_loss: 2.8408 - linkage_loss: 0.7890 - retention_loss: 0.6301 - VS_accuracy: 0.7021 - linkage_accuracy: 0.6987 - retention_accuracy: 0.8285 - val_loss: 1.7687 - val_VS_loss: 0.6222 - val_linkage_loss: 0.6144 - val_retention_loss: 0.4614 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.4865 - VS_loss: 0.9130 - linkage_loss: 0.7480 - retention_loss: 0.7556 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6990 - retention_accuracy: 0.8304 - val_loss: 1.7373 - val_VS_loss: 0.6027 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4517 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.5740 - VS_loss: 1.2360 - linkage_loss: 0.6945 - retention_loss: 0.5751 - VS_accuracy: 0.7039 - linkage_accuracy: 0.6989 - retention_accuracy: 0.8308 - val_loss: 1.7178 - val_VS_loss: 0.5904 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4458 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 2.2045 - VS_loss: 0.9878 - linkage_loss: 0.6410 - retention_loss: 0.5086 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8311 - val_loss: 1.7062 - val_VS_loss: 0.5832 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4425 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.9103 - VS_loss: 1.2828 - linkage_loss: 0.8179 - retention_loss: 0.7434 - VS_accuracy: 0.7049 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8308 - val_loss: 1.6986 - val_VS_loss: 0.5787 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4403 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.9708 - VS_loss: 0.7140 - linkage_loss: 0.6234 - retention_loss: 0.5680 - VS_accuracy: 0.7046 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8311 - val_loss: 1.6942 - val_VS_loss: 0.5762 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4391 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8985 - VS_loss: 0.6353 - linkage_loss: 0.6269 - retention_loss: 0.5716 - VS_accuracy: 0.7049 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.6912 - val_VS_loss: 0.5746 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4383 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.9255 - VS_loss: 0.6553 - linkage_loss: 0.6195 - retention_loss: 0.5867 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.6890 - val_VS_loss: 0.5735 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4378 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 1.8064 - VS_loss: 0.6357 - linkage_loss: 0.6327 - retention_loss: 0.4746 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6878 - val_VS_loss: 0.5732 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4376 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 2.0697 - VS_loss: 0.7365 - linkage_loss: 0.6337 - retention_loss: 0.6367 - VS_accuracy: 0.7049 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6867 - val_VS_loss: 0.5729 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4374 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.9218 - VS_loss: 0.7749 - linkage_loss: 0.6173 - retention_loss: 0.4674 - VS_accuracy: 0.7045 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.6856 - val_VS_loss: 0.5726 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4373 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8826 - VS_loss: 0.7357 - linkage_loss: 0.6289 - retention_loss: 0.4564 - VS_accuracy: 0.7034 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6847 - val_VS_loss: 0.5723 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4371 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 2.0218 - VS_loss: 0.8089 - linkage_loss: 0.6591 - retention_loss: 0.4925 - VS_accuracy: 0.7036 - linkage_accuracy: 0.6994 - retention_accuracy: 0.8313 - val_loss: 1.6844 - val_VS_loss: 0.5723 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 1.9835 - VS_loss: 0.8293 - linkage_loss: 0.6367 - retention_loss: 0.4565 - VS_accuracy: 0.7033 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6838 - val_VS_loss: 0.5720 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4371 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 1.8844 - VS_loss: 0.7285 - linkage_loss: 0.6128 - retention_loss: 0.4826 - VS_accuracy: 0.7041 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.6835 - val_VS_loss: 0.5723 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8f770e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.70601195],\n",
       "        [0.70601195],\n",
       "        [0.70601195],\n",
       "        ...,\n",
       "        [0.70601195],\n",
       "        [0.70601195],\n",
       "        [0.70601195]], dtype=float32),\n",
       " array([[0.6990726],\n",
       "        [0.6990726],\n",
       "        [0.6990726],\n",
       "        ...,\n",
       "        [0.6990726],\n",
       "        [0.6990726],\n",
       "        [0.6990726]], dtype=float32),\n",
       " array([[0.8311868],\n",
       "        [0.8311868],\n",
       "        [0.8311868],\n",
       "        ...,\n",
       "        [0.8311868],\n",
       "        [0.8311868],\n",
       "        [0.8311868]], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "093a9901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.7671300893743793\n",
      "0.8259682224428997\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01c509d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f42e512e",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab66c35d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VS</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>Black</td>\n",
       "      <td>Others</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>MSM</td>\n",
       "      <td>Urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40279 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  VS  dx_yr  dx_mth  age  \\\n",
       "0                591.000000                       2   0   2005      12   39   \n",
       "1               1018.000000                       3   0   2005      12   39   \n",
       "2               2072.250000                       6   1   2005      12   39   \n",
       "3               2495.333333                       7   1   2005      12   39   \n",
       "4               2793.333333                       8   1   2005      12   39   \n",
       "...                     ...                     ...  ..    ...     ...  ...   \n",
       "40274           2737.500000                       8   1   2009       9   48   \n",
       "40275           3193.000000                       9   1   2009       9   48   \n",
       "40276           3499.666667                      10   1   2009       9   48   \n",
       "40277           3884.000000                      11   1   2009       9   48   \n",
       "40278            755.000000                       2   0   2016      11   21   \n",
       "\n",
       "      sex   race    risk region  ...  msld.cum_1 metacanc.cum_1  aids.cum_1  \\\n",
       "0       F  Black  Others  Urban  ...         0.0            0.0         0.0   \n",
       "1       F  Black  Others  Urban  ...         0.0            0.0         0.0   \n",
       "2       F  Black  Others  Urban  ...         0.0            0.0         0.0   \n",
       "3       F  Black  Others  Urban  ...         0.0            0.0         0.0   \n",
       "4       F  Black  Others  Urban  ...         0.0            0.0         0.0   \n",
       "...    ..    ...     ...    ...  ...         ...            ...         ...   \n",
       "40274   M  Black     MSM  Urban  ...         0.0            0.0         0.0   \n",
       "40275   M  Black     MSM  Urban  ...         0.0            0.0         0.0   \n",
       "40276   M  Black     MSM  Urban  ...         0.0            0.0         0.0   \n",
       "40277   M  Black     MSM  Urban  ...         0.0            0.0         0.0   \n",
       "40278   M  Black     MSM  Urban  ...         0.0            0.0         0.0   \n",
       "\n",
       "       Depression_1  Anxiety_1  Psychiatric_disorder_1  Alcohol_use_1  \\\n",
       "0                 0          0                       0              0   \n",
       "1                 0          1                       0              1   \n",
       "2                 0          0                       0              0   \n",
       "3                 0          0                       0              0   \n",
       "4                 0          0                       0              0   \n",
       "...             ...        ...                     ...            ...   \n",
       "40274             0          0                       0              0   \n",
       "40275             0          0                       0              0   \n",
       "40276             0          0                       0              0   \n",
       "40277             0          0                       0              0   \n",
       "40278             0          0                       0              0   \n",
       "\n",
       "       Tobacco_use_1  Illicit_drug_use_1  visits_1  \n",
       "0                  0                   0         4  \n",
       "1                  1                   1         2  \n",
       "2                  0                   0         2  \n",
       "3                  0                   0         8  \n",
       "4                  0                   0         6  \n",
       "...              ...                 ...       ...  \n",
       "40274              0                   0         3  \n",
       "40275              0                   0         8  \n",
       "40276              0                   0         3  \n",
       "40277              0                   0         6  \n",
       "40278              0                   0         4  \n",
       "\n",
       "[40279 rows x 106 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = variables[variables['model2'] != 'delete']\n",
    "data = data_origin[temp['variables'].tolist()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "98d6d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = variables[variables['model2'] == 'outcome']['variables'].tolist()\n",
    "sparse_features = variables[variables['model2'] == 'cat']['variables'].tolist()\n",
    "dense_features = variables[variables['model2'] == 'num']['variables'].tolist()\n",
    "varlen_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf407d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'race',\n",
       " 'risk',\n",
       " 'region',\n",
       " 'VL_baseline_interpretation',\n",
       " 'mi',\n",
       " 'chf',\n",
       " 'pvd',\n",
       " 'cevd',\n",
       " 'dementia',\n",
       " 'cpd',\n",
       " 'rheumd',\n",
       " 'pud',\n",
       " 'mld',\n",
       " 'diab',\n",
       " 'diabwc',\n",
       " 'hp',\n",
       " 'rend',\n",
       " 'canc',\n",
       " 'msld',\n",
       " 'metacanc',\n",
       " 'aids',\n",
       " 'Depression',\n",
       " 'Anxiety',\n",
       " 'Psychiatric_disorder',\n",
       " 'Alcohol_use',\n",
       " 'Tobacco_use',\n",
       " 'Illicit_drug_use',\n",
       " 'county',\n",
       " 'mi_1',\n",
       " 'chf_1',\n",
       " 'pvd_1',\n",
       " 'cevd_1',\n",
       " 'dementia_1',\n",
       " 'cpd_1',\n",
       " 'rheumd_1',\n",
       " 'pud_1',\n",
       " 'mld_1',\n",
       " 'diab_1',\n",
       " 'diabwc_1',\n",
       " 'hp_1',\n",
       " 'rend_1',\n",
       " 'canc_1',\n",
       " 'msld_1',\n",
       " 'metacanc_1',\n",
       " 'aids_1',\n",
       " 'Depression_1',\n",
       " 'Anxiety_1',\n",
       " 'Psychiatric_disorder_1',\n",
       " 'Alcohol_use_1',\n",
       " 'Tobacco_use_1',\n",
       " 'Illicit_drug_use_1']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66bd9790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_20536\\2408031544.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n"
     ]
    }
   ],
   "source": [
    "encoder = {}\n",
    "# 稀疏特征编码\n",
    "for featid in sparse_features:\n",
    "    # print(f\"编码ID字段：{featid}\")\n",
    "    encoder[featid] = {uid:ucode+1 for ucode,uid in enumerate(data[featid].unique())} \n",
    "    data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n",
    "    \n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c032b59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(data.shape[0] * 0.6)\n",
    "n_val = round(data.shape[0] * 0.2)\n",
    "\n",
    "train = data[:n_train]\n",
    "val = data[n_train:(n_train+n_val)]\n",
    "test = data[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89d07977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "test_labels = [test[y].values for y in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e07b9",
   "metadata": {},
   "source": [
    "### Seperate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcd945",
   "metadata": {},
   "source": [
    "#### VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "996ef623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>dx_yr</th>\n",
       "      <th>dx_mth</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>risk</th>\n",
       "      <th>region</th>\n",
       "      <th>CD4_baseline</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>401.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32218</th>\n",
       "      <td>1693.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32219</th>\n",
       "      <td>1964.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32220</th>\n",
       "      <td>2392.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32221</th>\n",
       "      <td>2771.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32222</th>\n",
       "      <td>3022.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2009</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32223 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  dx_yr  dx_mth  age  sex  \\\n",
       "0                591.000000                       2   2005      12   39    1   \n",
       "1               1018.000000                       3   2005      12   39    1   \n",
       "2               2072.250000                       6   2005      12   39    1   \n",
       "3               2495.333333                       7   2005      12   39    1   \n",
       "4               2793.333333                       8   2005      12   39    1   \n",
       "...                     ...                     ...    ...     ...  ...  ...   \n",
       "32218           1693.000000                       5   2009       4   47    2   \n",
       "32219           1964.000000                       6   2009       4   47    2   \n",
       "32220           2392.500000                       7   2009       4   47    2   \n",
       "32221           2771.000000                       8   2009       4   47    2   \n",
       "32222           3022.000000                       9   2009       4   47    2   \n",
       "\n",
       "       race  risk  region  CD4_baseline  ...  msld.cum_1  metacanc.cum_1  \\\n",
       "0         1     1       1         401.0  ...         0.0             0.0   \n",
       "1         1     1       1         401.0  ...         0.0             0.0   \n",
       "2         1     1       1         401.0  ...         0.0             0.0   \n",
       "3         1     1       1         401.0  ...         0.0             0.0   \n",
       "4         1     1       1         401.0  ...         0.0             0.0   \n",
       "...     ...   ...     ...           ...  ...         ...             ...   \n",
       "32218     1     3       1          94.0  ...         0.0             0.0   \n",
       "32219     1     3       1          94.0  ...         0.0             0.0   \n",
       "32220     1     3       1          94.0  ...         0.0             0.0   \n",
       "32221     1     3       1          94.0  ...         0.0             0.0   \n",
       "32222     1     3       1          94.0  ...         0.0             0.0   \n",
       "\n",
       "       aids.cum_1  Depression_1  Anxiety_1  Psychiatric_disorder_1  \\\n",
       "0             0.0             1          1                       1   \n",
       "1             0.0             1          2                       1   \n",
       "2             0.0             1          1                       1   \n",
       "3             0.0             1          1                       1   \n",
       "4             0.0             1          1                       1   \n",
       "...           ...           ...        ...                     ...   \n",
       "32218         0.0             1          1                       1   \n",
       "32219         0.0             1          1                       1   \n",
       "32220         0.0             1          1                       1   \n",
       "32221         0.0             1          1                       1   \n",
       "32222         0.0             1          1                       1   \n",
       "\n",
       "       Alcohol_use_1  Tobacco_use_1  Illicit_drug_use_1  visits_1  \n",
       "0                  1              1                   1         4  \n",
       "1                  2              2                   2         2  \n",
       "2                  1              1                   1         2  \n",
       "3                  1              1                   1         8  \n",
       "4                  1              1                   1         6  \n",
       "...              ...            ...                 ...       ...  \n",
       "32218              1              1                   1         4  \n",
       "32219              1              1                   1         2  \n",
       "32220              1              1                   1         6  \n",
       "32221              1              1                   1         5  \n",
       "32222              1              1                   1         4  \n",
       "\n",
       "[32223 rows x 103 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VS\"]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58bc4a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 64)                6656      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,297\n",
      "Trainable params: 23,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4792c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 2015.4648 - accuracy: 0.5978 - val_loss: 2137.0535 - val_accuracy: 0.7528\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1129.7391 - accuracy: 0.5566 - val_loss: 2220.9998 - val_accuracy: 0.3466\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5029.7529 - accuracy: 0.5708 - val_loss: 3951.7371 - val_accuracy: 0.7544\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 314.7221 - accuracy: 0.6536 - val_loss: 18052.6738 - val_accuracy: 0.7544\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 2341.8276 - accuracy: 0.6059 - val_loss: 15401.9697 - val_accuracy: 0.7544\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 756.3921 - accuracy: 0.6129 - val_loss: 450.1421 - val_accuracy: 0.2911\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1414.1932 - accuracy: 0.5719 - val_loss: 4207.1484 - val_accuracy: 0.7517\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 2411.6238 - accuracy: 0.6339 - val_loss: 6842.3267 - val_accuracy: 0.2459\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 3724.5840 - accuracy: 0.5946 - val_loss: 2894.5396 - val_accuracy: 0.2785\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 2982.5088 - accuracy: 0.5645 - val_loss: 6292.0781 - val_accuracy: 0.3049\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 3253.6421 - accuracy: 0.5677 - val_loss: 3536.7761 - val_accuracy: 0.7541\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1115.8926 - accuracy: 0.6182 - val_loss: 613.1660 - val_accuracy: 0.2874\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 775.6370 - accuracy: 0.5671 - val_loss: 5330.9653 - val_accuracy: 0.7099\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1079.4645 - accuracy: 0.5852 - val_loss: 3268.5244 - val_accuracy: 0.3126\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1036.3167 - accuracy: 0.5699 - val_loss: 2369.0764 - val_accuracy: 0.6610\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 66.2257 - accuracy: 0.5770 - val_loss: 4064.8599 - val_accuracy: 0.7204\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1416.2654 - accuracy: 0.6130 - val_loss: 3728.2908 - val_accuracy: 0.3199\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 747.5820 - accuracy: 0.5494 - val_loss: 456.4830 - val_accuracy: 0.3469\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 579.6580 - accuracy: 0.5717 - val_loss: 8203.1562 - val_accuracy: 0.7542\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 940.2343 - accuracy: 0.6364 - val_loss: 11.7904 - val_accuracy: 0.6248\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51447bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [0.6683879 ],\n",
       "       [0.16565925],\n",
       "       [0.7555089 ]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acd3f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631454816285998\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72aeee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5060499201733684\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c431c",
   "metadata": {},
   "source": [
    "#### RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "850b5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"retention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3255633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 64)                6656      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,297\n",
      "Trainable params: 23,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5dee7dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 14ms/step - loss: 4378.0781 - accuracy: 0.5598 - val_loss: 453.6558 - val_accuracy: 0.8295\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1236.2568 - accuracy: 0.7796 - val_loss: 47.4220 - val_accuracy: 0.6971\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 251.5029 - accuracy: 0.7025 - val_loss: 26.1400 - val_accuracy: 0.7682\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 326.8781 - accuracy: 0.7193 - val_loss: 236.3590 - val_accuracy: 0.8377\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1315.9252 - accuracy: 0.6128 - val_loss: 779.9474 - val_accuracy: 0.8379\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1658.0767 - accuracy: 0.6215 - val_loss: 828.1443 - val_accuracy: 0.8284\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1702.4854 - accuracy: 0.6828 - val_loss: 1283.3475 - val_accuracy: 0.8335\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1921.6447 - accuracy: 0.6187 - val_loss: 364.3391 - val_accuracy: 0.8379\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 561.0107 - accuracy: 0.7304 - val_loss: 116.7491 - val_accuracy: 0.8374\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 609.9827 - accuracy: 0.7105 - val_loss: 360.1770 - val_accuracy: 0.8379\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 552.9449 - accuracy: 0.7214 - val_loss: 25.7500 - val_accuracy: 0.7566\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 878.0617 - accuracy: 0.5897 - val_loss: 132.4632 - val_accuracy: 0.8379\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 426.9267 - accuracy: 0.7704 - val_loss: 115.1205 - val_accuracy: 0.8375\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 314.8349 - accuracy: 0.7130 - val_loss: 290.9330 - val_accuracy: 0.7801\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 447.5442 - accuracy: 0.6865 - val_loss: 341.0447 - val_accuracy: 0.7893\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 370.4225 - accuracy: 0.7139 - val_loss: 213.0032 - val_accuracy: 0.7679\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 349.9308 - accuracy: 0.6379 - val_loss: 353.2963 - val_accuracy: 0.8379\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 908.4377 - accuracy: 0.7626 - val_loss: 115.2194 - val_accuracy: 0.7969\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 376.1004 - accuracy: 0.6552 - val_loss: 2962.5771 - val_accuracy: 0.3957\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 157.1160 - accuracy: 0.7766 - val_loss: 49.9758 - val_accuracy: 0.8362\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebd92621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       ...,\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [0.9999392]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e92eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7637785501489573\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba557e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49640890554163997\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac8938",
   "metadata": {},
   "source": [
    "#### LTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33988b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"linkage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67ca16fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 64)                6656      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,297\n",
      "Trainable params: 23,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64661bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 14ms/step - loss: 1354.9604 - accuracy: 0.6412 - val_loss: 25574.6777 - val_accuracy: 0.6340\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 504.2840 - accuracy: 0.5647 - val_loss: 5545.3232 - val_accuracy: 0.6735\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 287.9030 - accuracy: 0.6101 - val_loss: 5596.7671 - val_accuracy: 0.6940\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 124.4110 - accuracy: 0.6001 - val_loss: 6061.0967 - val_accuracy: 0.6925\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 183.7287 - accuracy: 0.6203 - val_loss: 5747.1182 - val_accuracy: 0.6506\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 611.6110 - accuracy: 0.5752 - val_loss: 3852.7368 - val_accuracy: 0.6425\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 200.5870 - accuracy: 0.6203 - val_loss: 95.4889 - val_accuracy: 0.4036\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 152.1798 - accuracy: 0.5969 - val_loss: 5386.2773 - val_accuracy: 0.6939\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 240.4752 - accuracy: 0.6132 - val_loss: 1888.0586 - val_accuracy: 0.6600\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 144.8645 - accuracy: 0.6075 - val_loss: 4497.6543 - val_accuracy: 0.6732\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1327.2188 - accuracy: 0.6159 - val_loss: 724.1094 - val_accuracy: 0.3075\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 451.4277 - accuracy: 0.5897 - val_loss: 389.8292 - val_accuracy: 0.4981\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 905.7864 - accuracy: 0.6316 - val_loss: 4491.1455 - val_accuracy: 0.5590\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 955.1837 - accuracy: 0.5852 - val_loss: 7122.2100 - val_accuracy: 0.6132\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 386.8448 - accuracy: 0.6214 - val_loss: 848.2773 - val_accuracy: 0.4366\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1114.0742 - accuracy: 0.6514 - val_loss: 11324.4980 - val_accuracy: 0.6214\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 676.5142 - accuracy: 0.6153 - val_loss: 8344.1738 - val_accuracy: 0.6109\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 218.8052 - accuracy: 0.5743 - val_loss: 14882.4082 - val_accuracy: 0.6965\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 566.8461 - accuracy: 0.5992 - val_loss: 17016.5820 - val_accuracy: 0.6925\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 872.0154 - accuracy: 0.6584 - val_loss: 5135.8955 - val_accuracy: 0.5609\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "772e1e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       ],\n",
       "       [0.       ],\n",
       "       [0.       ],\n",
       "       ...,\n",
       "       [0.       ],\n",
       "       [0.       ],\n",
       "       [0.9427753]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b5a0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5763406156901688\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba0897f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5547145945032121\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ed2fcb",
   "metadata": {},
   "source": [
    "### MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5794a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers\n",
    "\n",
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48f5e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)        (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)        (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_30 (Embedding)        (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_31 (Embedding)        (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_34 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_35 (Embedding)        (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_40 (Embedding)        (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_41 (Embedding)        (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_49 (Embedding)        (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_50 (Embedding)        (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_51 (Embedding)        (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_52 (Embedding)        (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_53 (Embedding)        (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_54 (Embedding)        (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_55 (Embedding)        (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_56 (Embedding)        (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_57 (Embedding)        (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_58 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_59 (Embedding)        (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_60 (Embedding)        (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_61 (Embedding)        (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 64)           0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 64)           0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 64)           0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 64)           0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 64)           0           embedding_14[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 64)           0           embedding_15[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 64)           0           embedding_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 64)           0           embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 64)           0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 64)           0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 64)           0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 64)           0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 64)           0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 64)           0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 64)           0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 64)           0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)            (None, 64)           0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)            (None, 64)           0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 64)           0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 64)           0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 64)           0           embedding_30[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 64)           0           embedding_31[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 64)           0           embedding_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 64)           0           embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 64)           0           embedding_34[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 64)           0           embedding_35[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 64)           0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 64)           0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 64)           0           embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_39 (Flatten)            (None, 64)           0           embedding_39[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 64)           0           embedding_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 64)           0           embedding_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_42 (Flatten)            (None, 64)           0           embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_43 (Flatten)            (None, 64)           0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 64)           0           embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 64)           0           embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 64)           0           embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 64)           0           embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 64)           0           embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_49 (Flatten)            (None, 64)           0           embedding_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_50 (Flatten)            (None, 64)           0           embedding_50[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_51 (Flatten)            (None, 64)           0           embedding_51[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_52 (Flatten)            (None, 64)           0           embedding_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 64)           0           embedding_53[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_54 (Flatten)            (None, 64)           0           embedding_54[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 64)           0           embedding_55[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_56 (Flatten)            (None, 64)           0           embedding_56[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_57 (Flatten)            (None, 64)           0           embedding_57[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_58 (Flatten)            (None, 64)           0           embedding_58[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 64)           0           embedding_59[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_60 (Flatten)            (None, 64)           0           embedding_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_61 (Flatten)            (None, 64)           0           embedding_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3379)         0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 flatten_16[0][0]                 \n",
      "                                                                 flatten_17[0][0]                 \n",
      "                                                                 flatten_18[0][0]                 \n",
      "                                                                 flatten_19[0][0]                 \n",
      "                                                                 flatten_20[0][0]                 \n",
      "                                                                 flatten_21[0][0]                 \n",
      "                                                                 flatten_22[0][0]                 \n",
      "                                                                 flatten_23[0][0]                 \n",
      "                                                                 flatten_24[0][0]                 \n",
      "                                                                 flatten_25[0][0]                 \n",
      "                                                                 flatten_26[0][0]                 \n",
      "                                                                 flatten_27[0][0]                 \n",
      "                                                                 flatten_28[0][0]                 \n",
      "                                                                 flatten_29[0][0]                 \n",
      "                                                                 flatten_30[0][0]                 \n",
      "                                                                 flatten_31[0][0]                 \n",
      "                                                                 flatten_32[0][0]                 \n",
      "                                                                 flatten_33[0][0]                 \n",
      "                                                                 flatten_34[0][0]                 \n",
      "                                                                 flatten_35[0][0]                 \n",
      "                                                                 flatten_36[0][0]                 \n",
      "                                                                 flatten_37[0][0]                 \n",
      "                                                                 flatten_38[0][0]                 \n",
      "                                                                 flatten_39[0][0]                 \n",
      "                                                                 flatten_40[0][0]                 \n",
      "                                                                 flatten_41[0][0]                 \n",
      "                                                                 flatten_42[0][0]                 \n",
      "                                                                 flatten_43[0][0]                 \n",
      "                                                                 flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "                                                                 flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "                                                                 flatten_48[0][0]                 \n",
      "                                                                 flatten_49[0][0]                 \n",
      "                                                                 flatten_50[0][0]                 \n",
      "                                                                 flatten_51[0][0]                 \n",
      "                                                                 flatten_52[0][0]                 \n",
      "                                                                 flatten_53[0][0]                 \n",
      "                                                                 flatten_54[0][0]                 \n",
      "                                                                 flatten_55[0][0]                 \n",
      "                                                                 flatten_56[0][0]                 \n",
      "                                                                 flatten_57[0][0]                 \n",
      "                                                                 flatten_58[0][0]                 \n",
      "                                                                 flatten_59[0][0]                 \n",
      "                                                                 flatten_60[0][0]                 \n",
      "                                                                 flatten_61[0][0]                 \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 64)           216320      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          8320        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 64)           8256        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer_1 (MmoeLayer)        [(None, 32), (None,  13650       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            33          mmoe_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "linkage (Dense)                 (None, 1)            33          mmoe_layer_1[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "retention (Dense)               (None, 1)            33          mmoe_layer_1[0][2]               \n",
      "==================================================================================================\n",
      "Total params: 259,701\n",
      "Trainable params: 259,701\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_mmoe(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 32,\n",
    "          n_task = 3,n_expert = 6,varlens_cols = varlen_features,varlens_max_len = varlens_max_len,\n",
    "          dnn_hidden_units = (64,128,64),target = target,dnn_reg_l2 = 0.001,drop_rate = 0.1)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "64a848ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 11s 142ms/step - loss: 1869.4530 - VS_loss: 1081.5596 - linkage_loss: 227.5801 - retention_loss: 559.9071 - VS_accuracy: 0.5763 - linkage_accuracy: 0.6121 - retention_accuracy: 0.6503 - val_loss: 1751.6058 - val_VS_loss: 527.7377 - val_linkage_loss: 1061.1282 - val_retention_loss: 162.2075 - val_VS_accuracy: 0.3025 - val_linkage_accuracy: 0.6956 - val_retention_accuracy: 0.8419\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 877.5034 - VS_loss: 397.8058 - linkage_loss: 127.1546 - retention_loss: 351.8724 - VS_accuracy: 0.5484 - linkage_accuracy: 0.5948 - retention_accuracy: 0.6381 - val_loss: 678.3790 - val_VS_loss: 332.4725 - val_linkage_loss: 317.8212 - val_retention_loss: 27.1996 - val_VS_accuracy: 0.6019 - val_linkage_accuracy: 0.5757 - val_retention_accuracy: 0.8381\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 3s 114ms/step - loss: 220.2439 - VS_loss: 162.8289 - linkage_loss: 25.5215 - retention_loss: 30.9615 - VS_accuracy: 0.6491 - linkage_accuracy: 0.5395 - retention_accuracy: 0.7540 - val_loss: 408.3427 - val_VS_loss: 356.4158 - val_linkage_loss: 22.1976 - val_retention_loss: 28.8602 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.3648 - val_retention_accuracy: 0.3787\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 4s 180ms/step - loss: 18.4441 - VS_loss: 8.1718 - linkage_loss: 4.4026 - retention_loss: 5.1682 - VS_accuracy: 0.6904 - linkage_accuracy: 0.6773 - retention_accuracy: 0.7917 - val_loss: 2.2169 - val_VS_loss: 0.5998 - val_linkage_loss: 0.6388 - val_retention_loss: 0.4659 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 2.3042 - VS_loss: 0.7555 - linkage_loss: 0.6596 - retention_loss: 0.4790 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8308 - val_loss: 1.9599 - val_VS_loss: 0.5793 - val_linkage_loss: 0.6151 - val_retention_loss: 0.4414 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 2.0123 - VS_loss: 0.6241 - linkage_loss: 0.6184 - retention_loss: 0.4851 - VS_accuracy: 0.7049 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8310 - val_loss: 1.8758 - val_VS_loss: 0.5731 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4374 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.9114 - VS_loss: 0.6070 - linkage_loss: 0.6126 - retention_loss: 0.4559 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8311 - val_loss: 1.8455 - val_VS_loss: 0.5722 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4369 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 1.8914 - VS_loss: 0.6067 - linkage_loss: 0.6146 - retention_loss: 0.4542 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8311 - val_loss: 1.8336 - val_VS_loss: 0.5725 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 2s 84ms/step - loss: 1.8821 - VS_loss: 0.6072 - linkage_loss: 0.6118 - retention_loss: 0.4559 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.8276 - val_VS_loss: 0.5724 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4369 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 75ms/step - loss: 1.8753 - VS_loss: 0.6065 - linkage_loss: 0.6115 - retention_loss: 0.4546 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8312 - val_loss: 1.8243 - val_VS_loss: 0.5723 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 1.8746 - VS_loss: 0.6073 - linkage_loss: 0.6123 - retention_loss: 0.4552 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8312 - val_loss: 1.8218 - val_VS_loss: 0.5722 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4369 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.8754 - VS_loss: 0.6081 - linkage_loss: 0.6150 - retention_loss: 0.4544 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.8201 - val_VS_loss: 0.5723 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 1.8687 - VS_loss: 0.6067 - linkage_loss: 0.6120 - retention_loss: 0.4540 - VS_accuracy: 0.7049 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8312 - val_loss: 1.8183 - val_VS_loss: 0.5725 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4369 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 2s 78ms/step - loss: 1.8667 - VS_loss: 0.6072 - linkage_loss: 0.6115 - retention_loss: 0.4538 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8314 - val_loss: 1.8170 - val_VS_loss: 0.5726 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 2s 81ms/step - loss: 1.8652 - VS_loss: 0.6067 - linkage_loss: 0.6119 - retention_loss: 0.4540 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.8150 - val_VS_loss: 0.5723 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.8633 - VS_loss: 0.6067 - linkage_loss: 0.6115 - retention_loss: 0.4540 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8312 - val_loss: 1.8137 - val_VS_loss: 0.5726 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4369 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 1s 61ms/step - loss: 1.8622 - VS_loss: 0.6072 - linkage_loss: 0.6114 - retention_loss: 0.4540 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.8124 - val_VS_loss: 0.5725 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.8615 - VS_loss: 0.6073 - linkage_loss: 0.6121 - retention_loss: 0.4538 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6994 - retention_accuracy: 0.8313 - val_loss: 1.8109 - val_VS_loss: 0.5724 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 1.8588 - VS_loss: 0.6067 - linkage_loss: 0.6115 - retention_loss: 0.4538 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.8095 - val_VS_loss: 0.5722 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4371 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.8604 - VS_loss: 0.6075 - linkage_loss: 0.6132 - retention_loss: 0.4541 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.8085 - val_VS_loss: 0.5726 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5927ddd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.70397633],\n",
       "        [0.70397633],\n",
       "        [0.70397633],\n",
       "        ...,\n",
       "        [0.70397633],\n",
       "        [0.70397633],\n",
       "        [0.70397633]], dtype=float32),\n",
       " array([[0.6985665],\n",
       "        [0.6985665],\n",
       "        [0.6985665],\n",
       "        ...,\n",
       "        [0.6985665],\n",
       "        [0.6985665],\n",
       "        [0.6985665]], dtype=float32),\n",
       " array([[0.83109313],\n",
       "        [0.83109313],\n",
       "        [0.83109313],\n",
       "        ...,\n",
       "        [0.83109313],\n",
       "        [0.83109313],\n",
       "        [0.83109313]], dtype=float32)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01716d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.7671300893743793\n",
      "0.8259682224428997\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08b3370d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54099ce",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21f7c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class PleLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    n_experts:list,每个任务使用几个expert。[2,3]第一个任务使用2个expert，第二个任务使用3个expert。\n",
    "    n_expert_share:int,共享的部分设置的expert个数。\n",
    "    expert_dim:int,每个专家网络输出的向量维度。\n",
    "    n_task:int,任务个数。\n",
    "    '''\n",
    "    def __init__(self,n_task,n_experts,expert_dim,n_expert_share,dnn_reg_l2 = 1e-5):\n",
    "        super(PleLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        \n",
    "        # 生成多个任务特定网络和1个共享网络。\n",
    "        self.E_layer = []\n",
    "        for i in range(n_task):\n",
    "            sub_exp = [Dense(expert_dim,activation = 'relu') for j in range(n_experts[i])]\n",
    "            self.E_layer.append(sub_exp)\n",
    "            \n",
    "        self.share_layer = [Dense(expert_dim,activation = 'relu') for j in range(n_expert_share)]\n",
    "        #定义门控网络\n",
    "        self.gate_layers = [Dense(n_expert_share+n_experts[i],kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                                  activation = 'softmax') for i in range(n_task)]\n",
    "\n",
    "    def call(self,x):\n",
    "        #特定网络和共享网络\n",
    "        E_net = [[expert(x) for expert in sub_expert] for sub_expert in self.E_layer]\n",
    "        share_net = [expert(x) for expert in self.share_layer]\n",
    "        \n",
    "        #门的权重乘上，指定任务和共享任务的输出。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = self.gate_layers[i](x)\n",
    "            g = tf.expand_dims(g,axis = -1) #(bs,n_expert_share+n_experts[i],1)\n",
    "            _e = share_net+E_net[i]  \n",
    "            _e = Concatenate(axis = 1)([expert[:,tf.newaxis,:] for expert in _e]) #(bs,n_expert_share+n_experts[i],expert_dim)\n",
    "            _tower = tf.matmul(_e, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower)) #(bs,expert_dim)\n",
    "        return towers\n",
    "\n",
    "def build_ple(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim = 4,\n",
    "              varlens_cols = [],varlens_max_len = [],dnn_hidden_units = (64,64),\n",
    "              n_task = 2,n_experts = [2,2],n_expert_share = 4,dnn_reg_l2 = 1e-6,\n",
    "              drop_rate = 0.0,embedding_reg_l2 = 1e-6,targets = []):\n",
    "\n",
    "   #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])    \n",
    "                                  \n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    #Ple网络层\n",
    "    towers = PleLayer(n_task,n_experts,expert_dim,n_expert_share)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid',kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                       name = f,use_bias = True)(_t) for f,_t in zip(targets,towers)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d539a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_62 (Embedding)        (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_63 (Embedding)        (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_64 (Embedding)        (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_65 (Embedding)        (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_66 (Embedding)        (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_67 (Embedding)        (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_68 (Embedding)        (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_69 (Embedding)        (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_70 (Embedding)        (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_71 (Embedding)        (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_72 (Embedding)        (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_73 (Embedding)        (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_76 (Embedding)        (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_77 (Embedding)        (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_78 (Embedding)        (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_79 (Embedding)        (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_80 (Embedding)        (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_81 (Embedding)        (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_82 (Embedding)        (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_83 (Embedding)        (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_84 (Embedding)        (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_85 (Embedding)        (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_86 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_87 (Embedding)        (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_88 (Embedding)        (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_89 (Embedding)        (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_90 (Embedding)        (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_91 (Embedding)        (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_92 (Embedding)        (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_93 (Embedding)        (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_94 (Embedding)        (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_95 (Embedding)        (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_96 (Embedding)        (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_97 (Embedding)        (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_98 (Embedding)        (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_99 (Embedding)        (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_100 (Embedding)       (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_101 (Embedding)       (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_102 (Embedding)       (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_103 (Embedding)       (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_104 (Embedding)       (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_105 (Embedding)       (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_106 (Embedding)       (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_107 (Embedding)       (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_108 (Embedding)       (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_109 (Embedding)       (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_110 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_111 (Embedding)       (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_112 (Embedding)       (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_113 (Embedding)       (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_62 (Flatten)            (None, 64)           0           embedding_62[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_63 (Flatten)            (None, 64)           0           embedding_63[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_64 (Flatten)            (None, 64)           0           embedding_64[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_65 (Flatten)            (None, 64)           0           embedding_65[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_66 (Flatten)            (None, 64)           0           embedding_66[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 64)           0           embedding_67[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 64)           0           embedding_68[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 64)           0           embedding_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 64)           0           embedding_70[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 64)           0           embedding_71[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 64)           0           embedding_72[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 64)           0           embedding_73[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_74 (Flatten)            (None, 64)           0           embedding_74[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_75 (Flatten)            (None, 64)           0           embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_76 (Flatten)            (None, 64)           0           embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 64)           0           embedding_77[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_78 (Flatten)            (None, 64)           0           embedding_78[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_79 (Flatten)            (None, 64)           0           embedding_79[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_80 (Flatten)            (None, 64)           0           embedding_80[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_81 (Flatten)            (None, 64)           0           embedding_81[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_82 (Flatten)            (None, 64)           0           embedding_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_83 (Flatten)            (None, 64)           0           embedding_83[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_84 (Flatten)            (None, 64)           0           embedding_84[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_85 (Flatten)            (None, 64)           0           embedding_85[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_86 (Flatten)            (None, 64)           0           embedding_86[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_87 (Flatten)            (None, 64)           0           embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_88 (Flatten)            (None, 64)           0           embedding_88[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_89 (Flatten)            (None, 64)           0           embedding_89[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_90 (Flatten)            (None, 64)           0           embedding_90[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_91 (Flatten)            (None, 64)           0           embedding_91[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_92 (Flatten)            (None, 64)           0           embedding_92[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_93 (Flatten)            (None, 64)           0           embedding_93[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_94 (Flatten)            (None, 64)           0           embedding_94[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_95 (Flatten)            (None, 64)           0           embedding_95[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_96 (Flatten)            (None, 64)           0           embedding_96[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_97 (Flatten)            (None, 64)           0           embedding_97[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_98 (Flatten)            (None, 64)           0           embedding_98[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_99 (Flatten)            (None, 64)           0           embedding_99[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_100 (Flatten)           (None, 64)           0           embedding_100[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_101 (Flatten)           (None, 64)           0           embedding_101[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_102 (Flatten)           (None, 64)           0           embedding_102[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_103 (Flatten)           (None, 64)           0           embedding_103[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_104 (Flatten)           (None, 64)           0           embedding_104[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_105 (Flatten)           (None, 64)           0           embedding_105[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_106 (Flatten)           (None, 64)           0           embedding_106[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_107 (Flatten)           (None, 64)           0           embedding_107[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_108 (Flatten)           (None, 64)           0           embedding_108[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_109 (Flatten)           (None, 64)           0           embedding_109[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_110 (Flatten)           (None, 64)           0           embedding_110[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_111 (Flatten)           (None, 64)           0           embedding_111[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_112 (Flatten)           (None, 64)           0           embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)           (None, 64)           0           embedding_113[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3379)         0           flatten_62[0][0]                 \n",
      "                                                                 flatten_63[0][0]                 \n",
      "                                                                 flatten_64[0][0]                 \n",
      "                                                                 flatten_65[0][0]                 \n",
      "                                                                 flatten_66[0][0]                 \n",
      "                                                                 flatten_67[0][0]                 \n",
      "                                                                 flatten_68[0][0]                 \n",
      "                                                                 flatten_69[0][0]                 \n",
      "                                                                 flatten_70[0][0]                 \n",
      "                                                                 flatten_71[0][0]                 \n",
      "                                                                 flatten_72[0][0]                 \n",
      "                                                                 flatten_73[0][0]                 \n",
      "                                                                 flatten_74[0][0]                 \n",
      "                                                                 flatten_75[0][0]                 \n",
      "                                                                 flatten_76[0][0]                 \n",
      "                                                                 flatten_77[0][0]                 \n",
      "                                                                 flatten_78[0][0]                 \n",
      "                                                                 flatten_79[0][0]                 \n",
      "                                                                 flatten_80[0][0]                 \n",
      "                                                                 flatten_81[0][0]                 \n",
      "                                                                 flatten_82[0][0]                 \n",
      "                                                                 flatten_83[0][0]                 \n",
      "                                                                 flatten_84[0][0]                 \n",
      "                                                                 flatten_85[0][0]                 \n",
      "                                                                 flatten_86[0][0]                 \n",
      "                                                                 flatten_87[0][0]                 \n",
      "                                                                 flatten_88[0][0]                 \n",
      "                                                                 flatten_89[0][0]                 \n",
      "                                                                 flatten_90[0][0]                 \n",
      "                                                                 flatten_91[0][0]                 \n",
      "                                                                 flatten_92[0][0]                 \n",
      "                                                                 flatten_93[0][0]                 \n",
      "                                                                 flatten_94[0][0]                 \n",
      "                                                                 flatten_95[0][0]                 \n",
      "                                                                 flatten_96[0][0]                 \n",
      "                                                                 flatten_97[0][0]                 \n",
      "                                                                 flatten_98[0][0]                 \n",
      "                                                                 flatten_99[0][0]                 \n",
      "                                                                 flatten_100[0][0]                \n",
      "                                                                 flatten_101[0][0]                \n",
      "                                                                 flatten_102[0][0]                \n",
      "                                                                 flatten_103[0][0]                \n",
      "                                                                 flatten_104[0][0]                \n",
      "                                                                 flatten_105[0][0]                \n",
      "                                                                 flatten_106[0][0]                \n",
      "                                                                 flatten_107[0][0]                \n",
      "                                                                 flatten_108[0][0]                \n",
      "                                                                 flatten_109[0][0]                \n",
      "                                                                 flatten_110[0][0]                \n",
      "                                                                 flatten_111[0][0]                \n",
      "                                                                 flatten_112[0][0]                \n",
      "                                                                 flatten_113[0][0]                \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 64)           216320      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 64)           4160        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 64)           0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ple_layer_1 (PleLayer)          [(None, 16), (None,  5785        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            17          ple_layer_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "linkage (Dense)                 (None, 1)            17          ple_layer_1[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "retention (Dense)               (None, 1)            17          ple_layer_1[0][2]                \n",
      "==================================================================================================\n",
      "Total params: 239,372\n",
      "Trainable params: 239,372\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_ple(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 16,\n",
    "          varlens_cols = varlen_features,varlens_max_len = varlens_max_len,dnn_hidden_units = (64,64),\n",
    "          n_task = 3,n_experts = [1,1,1],n_expert_share = 2,dnn_reg_l2 = 0.001,\n",
    "          drop_rate = 0.1,embedding_reg_l2 = 0.001,targets = target)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "378587eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 13s 163ms/step - loss: 2412.5435 - VS_loss: 744.0338 - linkage_loss: 781.3936 - retention_loss: 886.7078 - VS_accuracy: 0.5605 - linkage_accuracy: 0.6244 - retention_accuracy: 0.6687 - val_loss: 11565.8672 - val_VS_loss: 317.7469 - val_linkage_loss: 11246.2090 - val_retention_loss: 1.2507 - val_VS_accuracy: 0.3086 - val_linkage_accuracy: 0.6864 - val_retention_accuracy: 0.8419\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 574.3810 - VS_loss: 217.2601 - linkage_loss: 353.6669 - retention_loss: 2.3894 - VS_accuracy: 0.5381 - linkage_accuracy: 0.5647 - retention_accuracy: 0.8091 - val_loss: 1132.9025 - val_VS_loss: 1130.0895 - val_linkage_loss: 0.7963 - val_retention_loss: 0.5989 - val_VS_accuracy: 0.7367 - val_linkage_accuracy: 0.3306 - val_retention_accuracy: 0.8419\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 32.0332 - VS_loss: 27.0306 - linkage_loss: 2.9339 - retention_loss: 0.7459 - VS_accuracy: 0.6776 - linkage_accuracy: 0.3445 - retention_accuracy: 0.8278 - val_loss: 2.9472 - val_VS_loss: 0.6401 - val_linkage_loss: 0.7062 - val_retention_loss: 0.5420 - val_VS_accuracy: 0.7443 - val_linkage_accuracy: 0.3036 - val_retention_accuracy: 0.8419\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 1s 55ms/step - loss: 3.9970 - VS_loss: 1.4538 - linkage_loss: 1.1781 - retention_loss: 0.5720 - VS_accuracy: 0.6946 - linkage_accuracy: 0.6000 - retention_accuracy: 0.8305 - val_loss: 2.3281 - val_VS_loss: 0.6225 - val_linkage_loss: 0.6588 - val_retention_loss: 0.5038 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 3.2687 - VS_loss: 1.1806 - linkage_loss: 1.0575 - retention_loss: 0.6166 - VS_accuracy: 0.7019 - linkage_accuracy: 0.6947 - retention_accuracy: 0.8308 - val_loss: 2.0214 - val_VS_loss: 0.6056 - val_linkage_loss: 0.6342 - val_retention_loss: 0.4793 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 2.6310 - VS_loss: 0.9838 - linkage_loss: 0.9073 - retention_loss: 0.4934 - VS_accuracy: 0.7033 - linkage_accuracy: 0.6956 - retention_accuracy: 0.8309 - val_loss: 1.8755 - val_VS_loss: 0.5928 - val_linkage_loss: 0.6226 - val_retention_loss: 0.4637 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.0880 - VS_loss: 0.6825 - linkage_loss: 0.7640 - retention_loss: 0.4724 - VS_accuracy: 0.7036 - linkage_accuracy: 0.6949 - retention_accuracy: 0.8314 - val_loss: 1.7989 - val_VS_loss: 0.5844 - val_linkage_loss: 0.6169 - val_retention_loss: 0.4539 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 1s 59ms/step - loss: 2.0268 - VS_loss: 0.6764 - linkage_loss: 0.7337 - retention_loss: 0.4881 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6971 - retention_accuracy: 0.8311 - val_loss: 1.7559 - val_VS_loss: 0.5793 - val_linkage_loss: 0.6149 - val_retention_loss: 0.4477 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.9787 - VS_loss: 0.6624 - linkage_loss: 0.7084 - retention_loss: 0.5030 - VS_accuracy: 0.7045 - linkage_accuracy: 0.6964 - retention_accuracy: 0.8313 - val_loss: 1.7299 - val_VS_loss: 0.5761 - val_linkage_loss: 0.6142 - val_retention_loss: 0.4437 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 2.3967 - VS_loss: 0.6103 - linkage_loss: 1.2247 - retention_loss: 0.4716 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6979 - retention_accuracy: 0.8313 - val_loss: 1.7141 - val_VS_loss: 0.5747 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4413 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 1.8065 - VS_loss: 0.6198 - linkage_loss: 0.6501 - retention_loss: 0.4562 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6988 - retention_accuracy: 0.8312 - val_loss: 1.7038 - val_VS_loss: 0.5735 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4398 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 4s 181ms/step - loss: 1.8402 - VS_loss: 0.6132 - linkage_loss: 0.6962 - retention_loss: 0.4568 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6988 - retention_accuracy: 0.8313 - val_loss: 1.6973 - val_VS_loss: 0.5731 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4388 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.7565 - VS_loss: 0.6132 - linkage_loss: 0.6175 - retention_loss: 0.4560 - VS_accuracy: 0.7049 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6931 - val_VS_loss: 0.5729 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4381 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 7s 293ms/step - loss: 1.7721 - VS_loss: 0.6201 - linkage_loss: 0.6218 - retention_loss: 0.4632 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6901 - val_VS_loss: 0.5725 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4377 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.7517 - VS_loss: 0.6090 - linkage_loss: 0.6234 - retention_loss: 0.4542 - VS_accuracy: 0.7048 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6881 - val_VS_loss: 0.5724 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4375 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 2s 76ms/step - loss: 1.7843 - VS_loss: 0.6126 - linkage_loss: 0.6541 - retention_loss: 0.4539 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8314 - val_loss: 1.6870 - val_VS_loss: 0.5727 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4373 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 1.7698 - VS_loss: 0.6193 - linkage_loss: 0.6181 - retention_loss: 0.4696 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8313 - val_loss: 1.6859 - val_VS_loss: 0.5725 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4372 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 1s 57ms/step - loss: 1.7442 - VS_loss: 0.6131 - linkage_loss: 0.6122 - retention_loss: 0.4569 - VS_accuracy: 0.7052 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8314 - val_loss: 1.6854 - val_VS_loss: 0.5726 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4371 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.7680 - VS_loss: 0.6068 - linkage_loss: 0.6460 - retention_loss: 0.4538 - VS_accuracy: 0.7050 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8313 - val_loss: 1.6847 - val_VS_loss: 0.5726 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4371 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 1s 60ms/step - loss: 1.7931 - VS_loss: 0.6567 - linkage_loss: 0.6161 - retention_loss: 0.4593 - VS_accuracy: 0.7051 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8313 - val_loss: 1.6842 - val_VS_loss: 0.5724 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.7442 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "61044e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.70516324],\n",
       "        [0.70516324],\n",
       "        [0.70516324],\n",
       "        ...,\n",
       "        [0.70516324],\n",
       "        [0.70516324],\n",
       "        [0.70516324]], dtype=float32),\n",
       " array([[0.699403],\n",
       "        [0.699403],\n",
       "        [0.699403],\n",
       "        ...,\n",
       "        [0.699403],\n",
       "        [0.699403],\n",
       "        [0.699403]], dtype=float32),\n",
       " array([[0.83072495],\n",
       "        [0.83072495],\n",
       "        [0.83072495],\n",
       "        ...,\n",
       "        [0.83072495],\n",
       "        [0.83072495],\n",
       "        [0.83072495]], dtype=float32)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d47f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.7671300893743793\n",
      "0.8259682224428997\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "673b9313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fd5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce875398",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "23051897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VL_interpretation</th>\n",
       "      <th>VL</th>\n",
       "      <th>VS</th>\n",
       "      <th>VR</th>\n",
       "      <th>VB</th>\n",
       "      <th>Months_to_ini_VS</th>\n",
       "      <th>VR_N</th>\n",
       "      <th>VR_size</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>=</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>=</td>\n",
       "      <td>4804.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>2737.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40275</th>\n",
       "      <td>3193.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40276</th>\n",
       "      <td>3499.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40277</th>\n",
       "      <td>3884.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40278</th>\n",
       "      <td>755.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>=</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>1</td>\n",
       "      <td>200-500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40279 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year VL_interpretation      VL  \\\n",
       "0                591.000000                       2                 =  2902.0   \n",
       "1               1018.000000                       3                 =  4804.0   \n",
       "2               2072.250000                       6                 <   200.0   \n",
       "3               2495.333333                       7                 <   200.0   \n",
       "4               2793.333333                       8                 <   200.0   \n",
       "...                     ...                     ...               ...     ...   \n",
       "40274           2737.500000                       8                 <   200.0   \n",
       "40275           3193.000000                       9                 <   200.0   \n",
       "40276           3499.666667                      10                 <   200.0   \n",
       "40277           3884.000000                      11                 <   200.0   \n",
       "40278            755.000000                       2                 =   200.0   \n",
       "\n",
       "       VS  VR  VB  Months_to_ini_VS  VR_N  VR_size  ...  msld.cum_1  \\\n",
       "0       0   0   0         69.075000     0     none  ...         0.0   \n",
       "1       0   0   0         69.075000     0     none  ...         0.0   \n",
       "2       1   0   0         69.075000     0     none  ...         0.0   \n",
       "3       1   0   0         69.075000     0     none  ...         0.0   \n",
       "4       1   0   0         69.075000     0     none  ...         0.0   \n",
       "...    ..  ..  ..               ...   ...      ...  ...         ...   \n",
       "40274   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40275   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40276   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40277   1   0   0         17.616667     0     none  ...         0.0   \n",
       "40278   0   1   0          5.150000     1  200-500  ...         0.0   \n",
       "\n",
       "       metacanc.cum_1  aids.cum_1  Depression_1 Anxiety_1  \\\n",
       "0                 0.0         0.0             0         0   \n",
       "1                 0.0         0.0             0         1   \n",
       "2                 0.0         0.0             0         0   \n",
       "3                 0.0         0.0             0         0   \n",
       "4                 0.0         0.0             0         0   \n",
       "...               ...         ...           ...       ...   \n",
       "40274             0.0         0.0             0         0   \n",
       "40275             0.0         0.0             0         0   \n",
       "40276             0.0         0.0             0         0   \n",
       "40277             0.0         0.0             0         0   \n",
       "40278             0.0         0.0             0         0   \n",
       "\n",
       "      Psychiatric_disorder_1 Alcohol_use_1 Tobacco_use_1  Illicit_drug_use_1  \\\n",
       "0                          0             0             0                   0   \n",
       "1                          0             1             1                   1   \n",
       "2                          0             0             0                   0   \n",
       "3                          0             0             0                   0   \n",
       "4                          0             0             0                   0   \n",
       "...                      ...           ...           ...                 ...   \n",
       "40274                      0             0             0                   0   \n",
       "40275                      0             0             0                   0   \n",
       "40276                      0             0             0                   0   \n",
       "40277                      0             0             0                   0   \n",
       "40278                      0             0             0                   0   \n",
       "\n",
       "      visits_1  \n",
       "0            4  \n",
       "1            2  \n",
       "2            2  \n",
       "3            8  \n",
       "4            6  \n",
       "...        ...  \n",
       "40274        3  \n",
       "40275        8  \n",
       "40276        3  \n",
       "40277        6  \n",
       "40278        4  \n",
       "\n",
       "[40279 rows x 124 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = variables[variables['model3'] != 'delete']\n",
    "data = data_origin[temp['variables'].tolist()]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6512a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = variables[variables['model3'] == 'outcome']['variables'].tolist()\n",
    "sparse_features = variables[variables['model3'] == 'cat']['variables'].tolist()\n",
    "dense_features = variables[variables['model3'] == 'num']['variables'].tolist()\n",
    "varlen_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c73d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89831765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yunqing\\AppData\\Local\\Temp\\ipykernel_46932\\2408031544.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n"
     ]
    }
   ],
   "source": [
    "encoder = {}\n",
    "# 稀疏特征编码\n",
    "for featid in sparse_features:\n",
    "    # print(f\"编码ID字段：{featid}\")\n",
    "    encoder[featid] = {uid:ucode+1 for ucode,uid in enumerate(data[featid].unique())} \n",
    "    data[featid] = data[featid].apply(lambda x: encoder[featid].get(x,0))\n",
    "    \n",
    "# 生成输入特征设置\n",
    "sparse_max_len = {f:len(encoder[f]) + 1 for f in sparse_features}\n",
    "varlens_max_len = {f:len(encoder[f]) + 1 for f in varlen_features}\n",
    "feature_names = sparse_features+varlen_features+dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c68e5be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(data.shape[0] * 0.6)\n",
    "n_val = round(data.shape[0] * 0.2)\n",
    "\n",
    "train = data[:n_train]\n",
    "val = data[n_train:(n_train+n_val)]\n",
    "test = data[(n_train+n_val):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc5fcab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建输入数据\n",
    "train_model_input = {name: train[name] if name not in varlen_features else np.stack(train[name]) for name in feature_names } #训练模型的输入，字典类型。名称和具体值\n",
    "val_model_input = {name: val[name] if name not in varlen_features else np.stack(val[name]) for name in feature_names }\n",
    "test_model_input = {name: test[name] if name not in varlen_features else np.stack(test[name]) for name in feature_names}\n",
    "\n",
    "train_labels = [train[y].values for y in target]\n",
    "val_labels = [val[y].values for y in target]\n",
    "test_labels = [test[y].values for y in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650a21b",
   "metadata": {},
   "source": [
    "### Seperate models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb13a83",
   "metadata": {},
   "source": [
    "#### VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af4905ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME_DXDATE_TESTDATE</th>\n",
       "      <th>time_window_index_year</th>\n",
       "      <th>VL_interpretation</th>\n",
       "      <th>VL</th>\n",
       "      <th>VR</th>\n",
       "      <th>VB</th>\n",
       "      <th>Months_to_ini_VS</th>\n",
       "      <th>VR_N</th>\n",
       "      <th>VR_size</th>\n",
       "      <th>prop_time</th>\n",
       "      <th>...</th>\n",
       "      <th>msld.cum_1</th>\n",
       "      <th>metacanc.cum_1</th>\n",
       "      <th>aids.cum_1</th>\n",
       "      <th>Depression_1</th>\n",
       "      <th>Anxiety_1</th>\n",
       "      <th>Psychiatric_disorder_1</th>\n",
       "      <th>Alcohol_use_1</th>\n",
       "      <th>Tobacco_use_1</th>\n",
       "      <th>Illicit_drug_use_1</th>\n",
       "      <th>visits_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1018.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4804.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2072.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2495.333333</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2793.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69.075000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.335538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32218</th>\n",
       "      <td>1693.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.799523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32219</th>\n",
       "      <td>1964.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32220</th>\n",
       "      <td>2392.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.858014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32221</th>\n",
       "      <td>2771.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.873443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32222</th>\n",
       "      <td>3022.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.966667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.887767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32223 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIME_DXDATE_TESTDATE  time_window_index_year  VL_interpretation  \\\n",
       "0                591.000000                       2                  1   \n",
       "1               1018.000000                       3                  1   \n",
       "2               2072.250000                       6                  2   \n",
       "3               2495.333333                       7                  2   \n",
       "4               2793.333333                       8                  2   \n",
       "...                     ...                     ...                ...   \n",
       "32218           1693.000000                       5                  2   \n",
       "32219           1964.000000                       6                  2   \n",
       "32220           2392.500000                       7                  2   \n",
       "32221           2771.000000                       8                  1   \n",
       "32222           3022.000000                       9                  2   \n",
       "\n",
       "           VL  VR  VB  Months_to_ini_VS  VR_N  VR_size  prop_time  ...  \\\n",
       "0      2902.0   1   1         69.075000     0        1   0.000000  ...   \n",
       "1      4804.0   1   1         69.075000     0        1   0.000000  ...   \n",
       "2       200.0   1   1         69.075000     0        1   0.151356  ...   \n",
       "3       200.0   1   1         69.075000     0        1   0.267065  ...   \n",
       "4       200.0   1   1         69.075000     0        1   0.335538  ...   \n",
       "...       ...  ..  ..               ...   ...      ...        ...  ...   \n",
       "32218   200.0   1   1         18.966667     0        1   0.799523  ...   \n",
       "32219   200.0   1   1         18.966667     0        1   0.831713  ...   \n",
       "32220   200.0   1   1         18.966667     0        1   0.858014  ...   \n",
       "32221   200.0   1   2         18.966667     0        1   0.873443  ...   \n",
       "32222   200.0   1   1         18.966667     0        1   0.887767  ...   \n",
       "\n",
       "       msld.cum_1  metacanc.cum_1  aids.cum_1  Depression_1  Anxiety_1  \\\n",
       "0             0.0             0.0         0.0             1          1   \n",
       "1             0.0             0.0         0.0             1          2   \n",
       "2             0.0             0.0         0.0             1          1   \n",
       "3             0.0             0.0         0.0             1          1   \n",
       "4             0.0             0.0         0.0             1          1   \n",
       "...           ...             ...         ...           ...        ...   \n",
       "32218         0.0             0.0         0.0             1          1   \n",
       "32219         0.0             0.0         0.0             1          1   \n",
       "32220         0.0             0.0         0.0             1          1   \n",
       "32221         0.0             0.0         0.0             1          1   \n",
       "32222         0.0             0.0         0.0             1          1   \n",
       "\n",
       "       Psychiatric_disorder_1  Alcohol_use_1  Tobacco_use_1  \\\n",
       "0                           1              1              1   \n",
       "1                           1              2              2   \n",
       "2                           1              1              1   \n",
       "3                           1              1              1   \n",
       "4                           1              1              1   \n",
       "...                       ...            ...            ...   \n",
       "32218                       1              1              1   \n",
       "32219                       1              1              1   \n",
       "32220                       1              1              1   \n",
       "32221                       1              1              1   \n",
       "32222                       1              1              1   \n",
       "\n",
       "       Illicit_drug_use_1  visits_1  \n",
       "0                       1         4  \n",
       "1                       2         2  \n",
       "2                       1         2  \n",
       "3                       1         8  \n",
       "4                       1         6  \n",
       "...                   ...       ...  \n",
       "32218                   1         4  \n",
       "32219                   1         2  \n",
       "32220                   1         6  \n",
       "32221                   1         5  \n",
       "32222                   1         4  \n",
       "\n",
       "[32223 rows x 121 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"VS\"]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41d6c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 64)                7808      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 24,449\n",
      "Trainable params: 24,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8eeb514c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 15ms/step - loss: 3267.5876 - accuracy: 0.6166 - val_loss: 2002.6642 - val_accuracy: 0.5922\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 2391.6963 - accuracy: 0.6438 - val_loss: 23766.2559 - val_accuracy: 0.8272\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 3555.5254 - accuracy: 0.7206 - val_loss: 7559.5059 - val_accuracy: 0.8493\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1261.6584 - accuracy: 0.7174 - val_loss: 3951.4124 - val_accuracy: 0.8470\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 2171.7959 - accuracy: 0.7202 - val_loss: 5442.8867 - val_accuracy: 0.8507\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 611.2400 - accuracy: 0.7538 - val_loss: 4492.0742 - val_accuracy: 0.8574\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1361.1686 - accuracy: 0.7821 - val_loss: 320.4504 - val_accuracy: 0.3984\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 1095.2764 - accuracy: 0.7713 - val_loss: 936.3812 - val_accuracy: 0.6082\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 775.3293 - accuracy: 0.7842 - val_loss: 1005.4794 - val_accuracy: 0.3314\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 236.6717 - accuracy: 0.7391 - val_loss: 71.2219 - val_accuracy: 0.8355\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 830.3497 - accuracy: 0.6911 - val_loss: 5638.3516 - val_accuracy: 0.8545\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 384.5904 - accuracy: 0.8127 - val_loss: 12511.0186 - val_accuracy: 0.8577\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 577.6745 - accuracy: 0.7985 - val_loss: 8221.6240 - val_accuracy: 0.8540\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 3s 118ms/step - loss: 640.9084 - accuracy: 0.7169 - val_loss: 7068.9541 - val_accuracy: 0.8503\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 333.2975 - accuracy: 0.7996 - val_loss: 14174.0771 - val_accuracy: 0.8563\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1116.5951 - accuracy: 0.7264 - val_loss: 3573.3416 - val_accuracy: 0.8622\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 600.3937 - accuracy: 0.6983 - val_loss: 1740.4971 - val_accuracy: 0.8720\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 388.6980 - accuracy: 0.8091 - val_loss: 1990.9277 - val_accuracy: 0.8706\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 211.8640 - accuracy: 0.7784 - val_loss: 2220.9917 - val_accuracy: 0.3417\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 421.2715 - accuracy: 0.7222 - val_loss: 382.8707 - val_accuracy: 0.7021\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "098d2101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       ...,\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       [0.9537422]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f2df1ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6904170804369414\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47246121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7117912875745964\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29189b3c",
   "metadata": {},
   "source": [
    "#### RIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba0a8c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"retention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "744555f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 64)                7808      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 24,449\n",
      "Trainable params: 24,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5e8a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 4s 122ms/step - loss: 2749.2988 - accuracy: 0.6610 - val_loss: 4585.3027 - val_accuracy: 0.5493\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1011.2532 - accuracy: 0.6524 - val_loss: 2155.1438 - val_accuracy: 0.6109\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 457.7648 - accuracy: 0.7368 - val_loss: 8436.9385 - val_accuracy: 0.3462\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1024.1942 - accuracy: 0.6631 - val_loss: 569.9102 - val_accuracy: 0.8369\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1030.1630 - accuracy: 0.6461 - val_loss: 1246.7502 - val_accuracy: 0.7286\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 609.2635 - accuracy: 0.7372 - val_loss: 470.0819 - val_accuracy: 0.7784\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 3s 116ms/step - loss: 1119.7949 - accuracy: 0.6565 - val_loss: 7122.7812 - val_accuracy: 0.2884\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1759.5548 - accuracy: 0.5950 - val_loss: 12005.5898 - val_accuracy: 0.4258\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1306.4840 - accuracy: 0.7071 - val_loss: 279.9127 - val_accuracy: 0.8011\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 843.3774 - accuracy: 0.6985 - val_loss: 980.0063 - val_accuracy: 0.7142\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 407.4015 - accuracy: 0.6715 - val_loss: 179.2237 - val_accuracy: 0.8344\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 433.3415 - accuracy: 0.7163 - val_loss: 125.0030 - val_accuracy: 0.8318\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 387.4342 - accuracy: 0.7334 - val_loss: 424.3914 - val_accuracy: 0.7857\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 659.5113 - accuracy: 0.6340 - val_loss: 134.6021 - val_accuracy: 0.8343\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 332.7946 - accuracy: 0.6980 - val_loss: 232.0895 - val_accuracy: 0.8374\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 504.3135 - accuracy: 0.7343 - val_loss: 50.4393 - val_accuracy: 0.7974\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 146.7112 - accuracy: 0.6968 - val_loss: 143.7643 - val_accuracy: 0.8360\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 269.7915 - accuracy: 0.7039 - val_loss: 521.6149 - val_accuracy: 0.7918\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 112.3028 - accuracy: 0.7928 - val_loss: 120.7328 - val_accuracy: 0.7798\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 75.9230 - accuracy: 0.7287 - val_loss: 37.3857 - val_accuracy: 0.7907\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7df8be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       ],\n",
       "       [1.       ],\n",
       "       [1.       ],\n",
       "       ...,\n",
       "       [0.9999012],\n",
       "       [0.9999926],\n",
       "       [0.9976463]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ac6c138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7329940417080437\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa570741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5230714061454171\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92654314",
   "metadata": {},
   "source": [
    "#### LTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8f1a846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data[:(n_train+n_val)].copy()\n",
    "X_train.drop(columns=target, inplace=True)\n",
    "y_train = data[:(n_train+n_val)][\"linkage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7ed74e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 64)                7808      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 24,449\n",
      "Trainable params: 24,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')   # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c18426cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 13ms/step - loss: 2130.4707 - accuracy: 0.6079 - val_loss: 15420.1895 - val_accuracy: 0.6925\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 668.9637 - accuracy: 0.6012 - val_loss: 37732.8477 - val_accuracy: 0.6926\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1357.0073 - accuracy: 0.6006 - val_loss: 9085.8936 - val_accuracy: 0.6917\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1349.6593 - accuracy: 0.6477 - val_loss: 28684.1836 - val_accuracy: 0.6337\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 469.9576 - accuracy: 0.5670 - val_loss: 9812.9795 - val_accuracy: 0.6853\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 976.9426 - accuracy: 0.6430 - val_loss: 21349.7402 - val_accuracy: 0.6379\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 527.9663 - accuracy: 0.5707 - val_loss: 5686.5347 - val_accuracy: 0.6656\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1090.1152 - accuracy: 0.6281 - val_loss: 12884.8574 - val_accuracy: 0.6670\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 825.0889 - accuracy: 0.6251 - val_loss: 27633.1113 - val_accuracy: 0.6908\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 1054.6199 - accuracy: 0.6033 - val_loss: 1609.6027 - val_accuracy: 0.5162\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1028.7819 - accuracy: 0.6689 - val_loss: 2350.0620 - val_accuracy: 0.4357\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 384.9441 - accuracy: 0.5724 - val_loss: 19193.0859 - val_accuracy: 0.6922\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 710.9646 - accuracy: 0.6252 - val_loss: 18577.8320 - val_accuracy: 0.6888\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 454.8478 - accuracy: 0.5755 - val_loss: 2936.6562 - val_accuracy: 0.6650\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 99.1857 - accuracy: 0.5926 - val_loss: 688.1073 - val_accuracy: 0.5535\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 37.3838 - accuracy: 0.5663 - val_loss: 60.0181 - val_accuracy: 0.4057\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 74.5239 - accuracy: 0.5768 - val_loss: 1211.9209 - val_accuracy: 0.6742\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 58.4656 - accuracy: 0.6057 - val_loss: 620.8475 - val_accuracy: 0.5095\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 59.0808 - accuracy: 0.5731 - val_loss: 1198.2931 - val_accuracy: 0.6739\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 37.9617 - accuracy: 0.5841 - val_loss: 690.6368 - val_accuracy: 0.6694\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train.to_numpy(), np.array(y_train), epochs=20, batch_size=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb7709fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [0.41003317],\n",
       "       [0.75006294],\n",
       "       [0.98746324]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.copy()\n",
    "X_test.drop(columns=target, inplace=True)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1c0e6b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7158639523336644\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[1], (pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "137460ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5307445522043044\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[1], pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d24f4b",
   "metadata": {},
   "source": [
    "### New MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1147ff29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a9576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=42)\n",
    "\n",
    "# 分别对 VS, VB, VR 进行 oversampling\n",
    "X_resampled_vs, y_resampled_vs = ros.fit_resample(pd.DataFrame(train_model_input).reset_index(drop=True), train_labels[0])\n",
    "X_resampled_vb, y_resampled_vb = ros.fit_resample(pd.DataFrame(train_model_input).reset_index(drop=True), train_labels[1])\n",
    "X_resampled_vr, y_resampled_vr = ros.fit_resample(pd.DataFrame(train_model_input).reset_index(drop=True), train_labels[2])\n",
    "\n",
    "# 取交集，确保 `X_resampled` 统一（使用 .loc 代替 .iloc）\n",
    "X_resampled = X_resampled_vs.reset_index(drop=True)\n",
    "\n",
    "# 重新组合 y\n",
    "y_resampled_combined = [y_resampled_vs, y_resampled_vb, y_resampled_vr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc99f3",
   "metadata": {},
   "source": [
    "### MMoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73c189ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class MmoeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,expert_dim,n_expert,n_task):\n",
    "        super(MmoeLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        self.expert_layer = [Dense(expert_dim,activation = 'relu') for i in range(n_expert)]\n",
    "        self.gate_layers = [Dense(n_expert,activation = 'softmax') for i in range(n_task)]\n",
    "    \n",
    "    def call(self,x):\n",
    "        #多个专家网络\n",
    "        E_net = [expert(x) for expert in self.expert_layer]\n",
    "        E_net = Concatenate(axis = 1)([e[:,tf.newaxis,:] for e in E_net]) #(bs,n_expert,n_dims)\n",
    "        #多个门网络\n",
    "        gate_net = [gate(x) for gate in self.gate_layers]     #n_task个(bs,n_expert)\n",
    "        \n",
    "        #每个towers等于，对应的门网络乘上所有的专家网络。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = tf.expand_dims(gate_net[i],axis = -1)  #(bs,n_expert,1)\n",
    "            _tower = tf.matmul(E_net, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower))           #(bs,expert_dim)\n",
    "            \n",
    "        return towers\n",
    "\n",
    "def build_mmoe(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim,\n",
    "              varlens_cols,varlens_max_len,n_expert,n_task,target = [],\n",
    "              dnn_hidden_units = (64,),dnn_reg_l2 = 1e-5,drop_rate = 0.1,\n",
    "                embedding_reg_l2 = 1e-6):\n",
    "    \n",
    "    \n",
    "    #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])\n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    \n",
    "    #mmoe网络层\n",
    "    towers = MmoeLayer(expert_dim,n_expert,n_task)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid', kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                     name = f,use_bias = True)(_t) for _t,f in zip(towers,target)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "79ab0030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "VL_interpretation (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VB (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VS_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VB_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "linkage_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retention_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_67 (Embedding)        (None, 1, 64)        192         VL_interpretation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_68 (Embedding)        (None, 1, 64)        192         VR[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_69 (Embedding)        (None, 1, 64)        192         VB[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_70 (Embedding)        (None, 1, 64)        384         VR_size[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_71 (Embedding)        (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_72 (Embedding)        (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_73 (Embedding)        (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_76 (Embedding)        (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_77 (Embedding)        (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_78 (Embedding)        (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_79 (Embedding)        (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_80 (Embedding)        (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_81 (Embedding)        (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_82 (Embedding)        (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_83 (Embedding)        (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_84 (Embedding)        (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_85 (Embedding)        (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_86 (Embedding)        (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_87 (Embedding)        (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_88 (Embedding)        (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_89 (Embedding)        (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_90 (Embedding)        (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_91 (Embedding)        (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_92 (Embedding)        (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_93 (Embedding)        (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_94 (Embedding)        (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_95 (Embedding)        (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_96 (Embedding)        (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_97 (Embedding)        (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_98 (Embedding)        (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_99 (Embedding)        (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_100 (Embedding)       (None, 1, 64)        192         VS_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_101 (Embedding)       (None, 1, 64)        192         VR_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_102 (Embedding)       (None, 1, 64)        192         VB_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_103 (Embedding)       (None, 1, 64)        384         VR_size_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_104 (Embedding)       (None, 1, 64)        192         linkage_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_105 (Embedding)       (None, 1, 64)        192         retention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_106 (Embedding)       (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_107 (Embedding)       (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_108 (Embedding)       (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_109 (Embedding)       (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_110 (Embedding)       (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_111 (Embedding)       (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_112 (Embedding)       (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_113 (Embedding)       (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_114 (Embedding)       (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_115 (Embedding)       (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_116 (Embedding)       (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_117 (Embedding)       (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_118 (Embedding)       (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_119 (Embedding)       (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_120 (Embedding)       (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_121 (Embedding)       (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_122 (Embedding)       (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_123 (Embedding)       (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_124 (Embedding)       (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_125 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_126 (Embedding)       (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_127 (Embedding)       (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_128 (Embedding)       (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 64)           0           embedding_67[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 64)           0           embedding_68[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 64)           0           embedding_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 64)           0           embedding_70[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 64)           0           embedding_71[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 64)           0           embedding_72[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 64)           0           embedding_73[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_74 (Flatten)            (None, 64)           0           embedding_74[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_75 (Flatten)            (None, 64)           0           embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_76 (Flatten)            (None, 64)           0           embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 64)           0           embedding_77[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_78 (Flatten)            (None, 64)           0           embedding_78[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_79 (Flatten)            (None, 64)           0           embedding_79[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_80 (Flatten)            (None, 64)           0           embedding_80[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_81 (Flatten)            (None, 64)           0           embedding_81[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_82 (Flatten)            (None, 64)           0           embedding_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_83 (Flatten)            (None, 64)           0           embedding_83[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_84 (Flatten)            (None, 64)           0           embedding_84[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_85 (Flatten)            (None, 64)           0           embedding_85[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_86 (Flatten)            (None, 64)           0           embedding_86[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_87 (Flatten)            (None, 64)           0           embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_88 (Flatten)            (None, 64)           0           embedding_88[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_89 (Flatten)            (None, 64)           0           embedding_89[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_90 (Flatten)            (None, 64)           0           embedding_90[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_91 (Flatten)            (None, 64)           0           embedding_91[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_92 (Flatten)            (None, 64)           0           embedding_92[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_93 (Flatten)            (None, 64)           0           embedding_93[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_94 (Flatten)            (None, 64)           0           embedding_94[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_95 (Flatten)            (None, 64)           0           embedding_95[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_96 (Flatten)            (None, 64)           0           embedding_96[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_97 (Flatten)            (None, 64)           0           embedding_97[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_98 (Flatten)            (None, 64)           0           embedding_98[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_99 (Flatten)            (None, 64)           0           embedding_99[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_100 (Flatten)           (None, 64)           0           embedding_100[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_101 (Flatten)           (None, 64)           0           embedding_101[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_102 (Flatten)           (None, 64)           0           embedding_102[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_103 (Flatten)           (None, 64)           0           embedding_103[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_104 (Flatten)           (None, 64)           0           embedding_104[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_105 (Flatten)           (None, 64)           0           embedding_105[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_106 (Flatten)           (None, 64)           0           embedding_106[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_107 (Flatten)           (None, 64)           0           embedding_107[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_108 (Flatten)           (None, 64)           0           embedding_108[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_109 (Flatten)           (None, 64)           0           embedding_109[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_110 (Flatten)           (None, 64)           0           embedding_110[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_111 (Flatten)           (None, 64)           0           embedding_111[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_112 (Flatten)           (None, 64)           0           embedding_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)           (None, 64)           0           embedding_113[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_114 (Flatten)           (None, 64)           0           embedding_114[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_115 (Flatten)           (None, 64)           0           embedding_115[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_116 (Flatten)           (None, 64)           0           embedding_116[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_117 (Flatten)           (None, 64)           0           embedding_117[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_118 (Flatten)           (None, 64)           0           embedding_118[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_119 (Flatten)           (None, 64)           0           embedding_119[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_120 (Flatten)           (None, 64)           0           embedding_120[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_121 (Flatten)           (None, 64)           0           embedding_121[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_122 (Flatten)           (None, 64)           0           embedding_122[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_123 (Flatten)           (None, 64)           0           embedding_123[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_124 (Flatten)           (None, 64)           0           embedding_124[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_125 (Flatten)           (None, 64)           0           embedding_125[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_126 (Flatten)           (None, 64)           0           embedding_126[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_127 (Flatten)           (None, 64)           0           embedding_127[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_128 (Flatten)           (None, 64)           0           embedding_128[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4027)         0           flatten_67[0][0]                 \n",
      "                                                                 flatten_68[0][0]                 \n",
      "                                                                 flatten_69[0][0]                 \n",
      "                                                                 flatten_70[0][0]                 \n",
      "                                                                 flatten_71[0][0]                 \n",
      "                                                                 flatten_72[0][0]                 \n",
      "                                                                 flatten_73[0][0]                 \n",
      "                                                                 flatten_74[0][0]                 \n",
      "                                                                 flatten_75[0][0]                 \n",
      "                                                                 flatten_76[0][0]                 \n",
      "                                                                 flatten_77[0][0]                 \n",
      "                                                                 flatten_78[0][0]                 \n",
      "                                                                 flatten_79[0][0]                 \n",
      "                                                                 flatten_80[0][0]                 \n",
      "                                                                 flatten_81[0][0]                 \n",
      "                                                                 flatten_82[0][0]                 \n",
      "                                                                 flatten_83[0][0]                 \n",
      "                                                                 flatten_84[0][0]                 \n",
      "                                                                 flatten_85[0][0]                 \n",
      "                                                                 flatten_86[0][0]                 \n",
      "                                                                 flatten_87[0][0]                 \n",
      "                                                                 flatten_88[0][0]                 \n",
      "                                                                 flatten_89[0][0]                 \n",
      "                                                                 flatten_90[0][0]                 \n",
      "                                                                 flatten_91[0][0]                 \n",
      "                                                                 flatten_92[0][0]                 \n",
      "                                                                 flatten_93[0][0]                 \n",
      "                                                                 flatten_94[0][0]                 \n",
      "                                                                 flatten_95[0][0]                 \n",
      "                                                                 flatten_96[0][0]                 \n",
      "                                                                 flatten_97[0][0]                 \n",
      "                                                                 flatten_98[0][0]                 \n",
      "                                                                 flatten_99[0][0]                 \n",
      "                                                                 flatten_100[0][0]                \n",
      "                                                                 flatten_101[0][0]                \n",
      "                                                                 flatten_102[0][0]                \n",
      "                                                                 flatten_103[0][0]                \n",
      "                                                                 flatten_104[0][0]                \n",
      "                                                                 flatten_105[0][0]                \n",
      "                                                                 flatten_106[0][0]                \n",
      "                                                                 flatten_107[0][0]                \n",
      "                                                                 flatten_108[0][0]                \n",
      "                                                                 flatten_109[0][0]                \n",
      "                                                                 flatten_110[0][0]                \n",
      "                                                                 flatten_111[0][0]                \n",
      "                                                                 flatten_112[0][0]                \n",
      "                                                                 flatten_113[0][0]                \n",
      "                                                                 flatten_114[0][0]                \n",
      "                                                                 flatten_115[0][0]                \n",
      "                                                                 flatten_116[0][0]                \n",
      "                                                                 flatten_117[0][0]                \n",
      "                                                                 flatten_118[0][0]                \n",
      "                                                                 flatten_119[0][0]                \n",
      "                                                                 flatten_120[0][0]                \n",
      "                                                                 flatten_121[0][0]                \n",
      "                                                                 flatten_122[0][0]                \n",
      "                                                                 flatten_123[0][0]                \n",
      "                                                                 flatten_124[0][0]                \n",
      "                                                                 flatten_125[0][0]                \n",
      "                                                                 flatten_126[0][0]                \n",
      "                                                                 flatten_127[0][0]                \n",
      "                                                                 flatten_128[0][0]                \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 VL[0][0]                         \n",
      "                                                                 Months_to_ini_VS[0][0]           \n",
      "                                                                 VR_N[0][0]                       \n",
      "                                                                 prop_time[0][0]                  \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 VL_1[0][0]                       \n",
      "                                                                 Months_to_ini_VS_1[0][0]         \n",
      "                                                                 VR_N_1[0][0]                     \n",
      "                                                                 prop_time_1[0][0]                \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 64)           257792      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          8320        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 64)           8256        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64)           0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "mmoe_layer_2 (MmoeLayer)        [(None, 32), (None,  13650       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            33          mmoe_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "linkage (Dense)                 (None, 1)            33          mmoe_layer_2[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "retention (Dense)               (None, 1)            33          mmoe_layer_2[0][2]               \n",
      "==================================================================================================\n",
      "Total params: 303,477\n",
      "Trainable params: 303,477\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_mmoe(\n",
    "    sparse_features, dense_features, sparse_max_len, embed_dim=64, expert_dim=32,\n",
    "    n_task=3, n_expert=6, varlens_cols=varlen_features, varlens_max_len=varlens_max_len,\n",
    "    dnn_hidden_units=(64, 128, 64), target=target, dnn_reg_l2=0.001, drop_rate=0.1\n",
    ")\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[\"AUC\"])  # AUC 适用于不平衡数据\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dfc4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **确保 X_resampled 经过 Oversampling**\n",
    "train_model_input_resampled = {\n",
    "    name: X_resampled[name].values if name not in varlen_features \n",
    "    else np.stack(X_resampled[name].values) for name in feature_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ee5cbd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_resampled_combined format not supported!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     train_labels_resampled \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m         y_resampled_combined\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     11\u001b[0m         y_resampled_combined\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     12\u001b[0m         y_resampled_combined\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     13\u001b[0m     ]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_resampled_combined format not supported!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: y_resampled_combined format not supported!"
     ]
    }
   ],
   "source": [
    "# **如果 y_resampled_combined 是 DataFrame，先转换成 numpy**\n",
    "if isinstance(y_resampled_combined, np.ndarray):\n",
    "    train_labels_resampled = [\n",
    "        y_resampled_combined[:, 0],  # VS 任务\n",
    "        y_resampled_combined[:, 1],  # VB 任务\n",
    "        y_resampled_combined[:, 2]   # VR 任务\n",
    "    ]\n",
    "elif isinstance(y_resampled_combined, pd.DataFrame):\n",
    "    train_labels_resampled = [\n",
    "        y_resampled_combined.iloc[:, 0].values,\n",
    "        y_resampled_combined.iloc[:, 1].values,\n",
    "        y_resampled_combined.iloc[:, 2].values\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(\"y_resampled_combined format not supported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "738c44b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_labels_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m      2\u001b[0m     train_model_input_resampled,  \u001b[38;5;66;03m# 用 Oversampled 数据\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain_labels_resampled\u001b[49m,  \u001b[38;5;66;03m# 用 Oversampled 标签\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(val_model_input, val_labels), \n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_labels_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_model_input_resampled,  # 用 Oversampled 数据\n",
    "    train_labels_resampled,  # 用 Oversampled 标签\n",
    "    validation_data=(val_model_input, val_labels), \n",
    "    batch_size=1000, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9b462f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.7047897],\n",
       "        [0.7047897],\n",
       "        [0.7047897],\n",
       "        ...,\n",
       "        [0.7047897],\n",
       "        [0.7047897],\n",
       "        [0.7047897]], dtype=float32),\n",
       " array([[0.6987062],\n",
       "        [0.6987062],\n",
       "        [0.6987062],\n",
       "        ...,\n",
       "        [0.6987062],\n",
       "        [0.6987062],\n",
       "        [0.6987062]], dtype=float32),\n",
       " array([[0.8310056],\n",
       "        [0.8310056],\n",
       "        [0.8310056],\n",
       "        ...,\n",
       "        [0.8310056],\n",
       "        [0.8310056],\n",
       "        [0.8310056]], dtype=float32)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "272a7542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7768123138033763\n",
      "0.7671300893743793\n",
      "0.8259682224428997\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "64d5f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a88ab23",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8d037f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPoolLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(MeanPoolLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        mask = tf.expand_dims(tf.cast(mask,tf.float32),axis = -1)\n",
    "        x = x * mask\n",
    "        return K.sum(x, axis=self.axis) / (K.sum(mask, axis=self.axis) + 1e-9)\n",
    "\n",
    "class PleLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    n_experts:list,每个任务使用几个expert。[2,3]第一个任务使用2个expert，第二个任务使用3个expert。\n",
    "    n_expert_share:int,共享的部分设置的expert个数。\n",
    "    expert_dim:int,每个专家网络输出的向量维度。\n",
    "    n_task:int,任务个数。\n",
    "    '''\n",
    "    def __init__(self,n_task,n_experts,expert_dim,n_expert_share,dnn_reg_l2 = 1e-5):\n",
    "        super(PleLayer, self).__init__()\n",
    "        self.n_task = n_task\n",
    "        \n",
    "        # 生成多个任务特定网络和1个共享网络。\n",
    "        self.E_layer = []\n",
    "        for i in range(n_task):\n",
    "            sub_exp = [Dense(expert_dim,activation = 'relu') for j in range(n_experts[i])]\n",
    "            self.E_layer.append(sub_exp)\n",
    "            \n",
    "        self.share_layer = [Dense(expert_dim,activation = 'relu') for j in range(n_expert_share)]\n",
    "        #定义门控网络\n",
    "        self.gate_layers = [Dense(n_expert_share+n_experts[i],kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                                  activation = 'softmax') for i in range(n_task)]\n",
    "\n",
    "    def call(self,x):\n",
    "        #特定网络和共享网络\n",
    "        E_net = [[expert(x) for expert in sub_expert] for sub_expert in self.E_layer]\n",
    "        share_net = [expert(x) for expert in self.share_layer]\n",
    "        \n",
    "        #门的权重乘上，指定任务和共享任务的输出。\n",
    "        towers = []\n",
    "        for i in range(self.n_task):\n",
    "            g = self.gate_layers[i](x)\n",
    "            g = tf.expand_dims(g,axis = -1) #(bs,n_expert_share+n_experts[i],1)\n",
    "            _e = share_net+E_net[i]  \n",
    "            _e = Concatenate(axis = 1)([expert[:,tf.newaxis,:] for expert in _e]) #(bs,n_expert_share+n_experts[i],expert_dim)\n",
    "            _tower = tf.matmul(_e, g,transpose_a=True)\n",
    "            towers.append(Flatten()(_tower)) #(bs,expert_dim)\n",
    "        return towers\n",
    "\n",
    "def build_ple(sparse_cols,dense_cols,sparse_max_len,embed_dim,expert_dim = 4,\n",
    "              varlens_cols = [],varlens_max_len = [],dnn_hidden_units = (64,64),\n",
    "              n_task = 2,n_experts = [2,2],n_expert_share = 4,dnn_reg_l2 = 1e-6,\n",
    "              drop_rate = 0.0,embedding_reg_l2 = 1e-6,targets = []):\n",
    "\n",
    "   #输入部分，分为sparse,varlens,dense部分。\n",
    "    sparse_inputs = {f:Input([1],name = f) for f in sparse_cols}\n",
    "    dense_inputs = {f:Input([1],name = f) for f in dense_cols}\n",
    "    varlens_inputs = {f:Input([None,1],name = f) for f in varlens_cols}\n",
    "        \n",
    "    input_embed = {}\n",
    "    #离散特征，embedding到k维\n",
    "    for f in sparse_cols:\n",
    "        _input = sparse_inputs[f]\n",
    "        embedding = Embedding(sparse_max_len[f], embed_dim, \n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(embedding_reg_l2)) \n",
    "        input_embed[f] =Flatten()(embedding(_input)) #(bs,k)\n",
    "        \n",
    "    #多标签离散变量\n",
    "    for f in varlens_inputs:\n",
    "        _input = varlens_inputs[f]\n",
    "        mask = Masking(mask_value = 0).compute_mask(_input)\n",
    "        embedding = Embedding(varlens_max_len[f], embed_dim,\n",
    "            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        _embed =Reshape([-1,embed_dim])(embedding(_input))\n",
    "        out_embed = MeanPoolLayer(axis=1)(_embed,mask)\n",
    "        input_embed[f] = out_embed\n",
    "        \n",
    "    input_embed.update(dense_inputs) #加入连续变量\n",
    "    input_embed = Concatenate(axis = -1)([input_embed[f] for f in input_embed])    \n",
    "                                  \n",
    "    for num in dnn_hidden_units:\n",
    "        input_embed = Dropout(drop_rate)(Dense(num,activation = 'relu',\n",
    "                    kernel_regularizer=regularizers.l2(dnn_reg_l2))(input_embed))\n",
    "    #Ple网络层\n",
    "    towers = PleLayer(n_task,n_experts,expert_dim,n_expert_share)(input_embed)\n",
    "    outputs = [Dense(1,activation = 'sigmoid',kernel_regularizer=regularizers.l2(dnn_reg_l2),\n",
    "                       name = f,use_bias = True)(_t) for f,_t in zip(targets,towers)]\n",
    "    inputs = [sparse_inputs[f] for f in sparse_inputs]+[varlens_inputs[f] for f in varlens_inputs]\\\n",
    "                +[dense_inputs[f] for f in dense_inputs]\n",
    "    model = Model(inputs,outputs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9dc35582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "VL_interpretation (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VB (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "race (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "risk (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "region (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline_interpretation (Inp [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "county (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VS_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VB_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_size_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "linkage_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "retention_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld_1 (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Depression_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Anxiety_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Psychiatric_disorder_1 (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Alcohol_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tobacco_use_1 (InputLayer)      [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Illicit_drug_use_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_176 (Embedding)       (None, 1, 64)        192         VL_interpretation[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "embedding_177 (Embedding)       (None, 1, 64)        192         VR[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_178 (Embedding)       (None, 1, 64)        192         VB[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_179 (Embedding)       (None, 1, 64)        384         VR_size[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_180 (Embedding)       (None, 1, 64)        192         sex[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_181 (Embedding)       (None, 1, 64)        320         race[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_182 (Embedding)       (None, 1, 64)        320         risk[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_183 (Embedding)       (None, 1, 64)        192         region[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_184 (Embedding)       (None, 1, 64)        192         VL_baseline_interpretation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "embedding_185 (Embedding)       (None, 1, 64)        192         mi[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_186 (Embedding)       (None, 1, 64)        192         chf[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_187 (Embedding)       (None, 1, 64)        192         pvd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_188 (Embedding)       (None, 1, 64)        192         cevd[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_189 (Embedding)       (None, 1, 64)        192         dementia[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_190 (Embedding)       (None, 1, 64)        192         cpd[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_191 (Embedding)       (None, 1, 64)        192         rheumd[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_192 (Embedding)       (None, 1, 64)        192         pud[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_193 (Embedding)       (None, 1, 64)        192         mld[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "embedding_194 (Embedding)       (None, 1, 64)        192         diab[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_195 (Embedding)       (None, 1, 64)        192         diabwc[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_196 (Embedding)       (None, 1, 64)        192         hp[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_197 (Embedding)       (None, 1, 64)        192         rend[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_198 (Embedding)       (None, 1, 64)        192         canc[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_199 (Embedding)       (None, 1, 64)        192         msld[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_200 (Embedding)       (None, 1, 64)        192         metacanc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_201 (Embedding)       (None, 1, 64)        192         aids[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_202 (Embedding)       (None, 1, 64)        192         Depression[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_203 (Embedding)       (None, 1, 64)        192         Anxiety[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_204 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_205 (Embedding)       (None, 1, 64)        192         Alcohol_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_206 (Embedding)       (None, 1, 64)        192         Tobacco_use[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_207 (Embedding)       (None, 1, 64)        192         Illicit_drug_use[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "embedding_208 (Embedding)       (None, 1, 64)        3008        county[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_209 (Embedding)       (None, 1, 64)        192         VS_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_210 (Embedding)       (None, 1, 64)        192         VR_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_211 (Embedding)       (None, 1, 64)        192         VB_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_212 (Embedding)       (None, 1, 64)        384         VR_size_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_213 (Embedding)       (None, 1, 64)        192         linkage_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_214 (Embedding)       (None, 1, 64)        192         retention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_215 (Embedding)       (None, 1, 64)        192         mi_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_216 (Embedding)       (None, 1, 64)        192         chf_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_217 (Embedding)       (None, 1, 64)        192         pvd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_218 (Embedding)       (None, 1, 64)        192         cevd_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_219 (Embedding)       (None, 1, 64)        192         dementia_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_220 (Embedding)       (None, 1, 64)        192         cpd_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_221 (Embedding)       (None, 1, 64)        192         rheumd_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_222 (Embedding)       (None, 1, 64)        192         pud_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_223 (Embedding)       (None, 1, 64)        192         mld_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_224 (Embedding)       (None, 1, 64)        192         diab_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_225 (Embedding)       (None, 1, 64)        192         diabwc_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_226 (Embedding)       (None, 1, 64)        192         hp_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_227 (Embedding)       (None, 1, 64)        192         rend_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_228 (Embedding)       (None, 1, 64)        192         canc_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_229 (Embedding)       (None, 1, 64)        192         msld_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_230 (Embedding)       (None, 1, 64)        192         metacanc_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_231 (Embedding)       (None, 1, 64)        192         aids_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_232 (Embedding)       (None, 1, 64)        192         Depression_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_233 (Embedding)       (None, 1, 64)        192         Anxiety_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_234 (Embedding)       (None, 1, 64)        192         Psychiatric_disorder_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_235 (Embedding)       (None, 1, 64)        192         Alcohol_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_236 (Embedding)       (None, 1, 64)        192         Tobacco_use_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_237 (Embedding)       (None, 1, 64)        192         Illicit_drug_use_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_176 (Flatten)           (None, 64)           0           embedding_176[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_177 (Flatten)           (None, 64)           0           embedding_177[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_178 (Flatten)           (None, 64)           0           embedding_178[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_179 (Flatten)           (None, 64)           0           embedding_179[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_180 (Flatten)           (None, 64)           0           embedding_180[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_181 (Flatten)           (None, 64)           0           embedding_181[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_182 (Flatten)           (None, 64)           0           embedding_182[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_183 (Flatten)           (None, 64)           0           embedding_183[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_184 (Flatten)           (None, 64)           0           embedding_184[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_185 (Flatten)           (None, 64)           0           embedding_185[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_186 (Flatten)           (None, 64)           0           embedding_186[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_187 (Flatten)           (None, 64)           0           embedding_187[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_188 (Flatten)           (None, 64)           0           embedding_188[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_189 (Flatten)           (None, 64)           0           embedding_189[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_190 (Flatten)           (None, 64)           0           embedding_190[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_191 (Flatten)           (None, 64)           0           embedding_191[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_192 (Flatten)           (None, 64)           0           embedding_192[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_193 (Flatten)           (None, 64)           0           embedding_193[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_194 (Flatten)           (None, 64)           0           embedding_194[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_195 (Flatten)           (None, 64)           0           embedding_195[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_196 (Flatten)           (None, 64)           0           embedding_196[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_197 (Flatten)           (None, 64)           0           embedding_197[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_198 (Flatten)           (None, 64)           0           embedding_198[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_199 (Flatten)           (None, 64)           0           embedding_199[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_200 (Flatten)           (None, 64)           0           embedding_200[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_201 (Flatten)           (None, 64)           0           embedding_201[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_202 (Flatten)           (None, 64)           0           embedding_202[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_203 (Flatten)           (None, 64)           0           embedding_203[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_204 (Flatten)           (None, 64)           0           embedding_204[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_205 (Flatten)           (None, 64)           0           embedding_205[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_206 (Flatten)           (None, 64)           0           embedding_206[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_207 (Flatten)           (None, 64)           0           embedding_207[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_208 (Flatten)           (None, 64)           0           embedding_208[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_209 (Flatten)           (None, 64)           0           embedding_209[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_210 (Flatten)           (None, 64)           0           embedding_210[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_211 (Flatten)           (None, 64)           0           embedding_211[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_212 (Flatten)           (None, 64)           0           embedding_212[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_213 (Flatten)           (None, 64)           0           embedding_213[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_214 (Flatten)           (None, 64)           0           embedding_214[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_215 (Flatten)           (None, 64)           0           embedding_215[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_216 (Flatten)           (None, 64)           0           embedding_216[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_217 (Flatten)           (None, 64)           0           embedding_217[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_218 (Flatten)           (None, 64)           0           embedding_218[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_219 (Flatten)           (None, 64)           0           embedding_219[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_220 (Flatten)           (None, 64)           0           embedding_220[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_221 (Flatten)           (None, 64)           0           embedding_221[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_222 (Flatten)           (None, 64)           0           embedding_222[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_223 (Flatten)           (None, 64)           0           embedding_223[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_224 (Flatten)           (None, 64)           0           embedding_224[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_225 (Flatten)           (None, 64)           0           embedding_225[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_226 (Flatten)           (None, 64)           0           embedding_226[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_227 (Flatten)           (None, 64)           0           embedding_227[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_228 (Flatten)           (None, 64)           0           embedding_228[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_229 (Flatten)           (None, 64)           0           embedding_229[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_230 (Flatten)           (None, 64)           0           embedding_230[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_231 (Flatten)           (None, 64)           0           embedding_231[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_232 (Flatten)           (None, 64)           0           embedding_232[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_233 (Flatten)           (None, 64)           0           embedding_233[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_234 (Flatten)           (None, 64)           0           embedding_234[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_235 (Flatten)           (None, 64)           0           embedding_235[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_236 (Flatten)           (None, 64)           0           embedding_236[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_237 (Flatten)           (None, 64)           0           embedding_237[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TIME_DXDATE_TESTDATE (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_window_index_year (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL (InputLayer)                 [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_yr (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dx_mth (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "CD4_baseline (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_baseline (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "New_Diagnoses_Rate (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "PrEP_to_Need_Ratio (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pcp_rate (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME2 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME3 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEME4 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "RPL_THEMES (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VL_1 (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Months_to_ini_VS_1 (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "VR_N_1 (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prop_time_1 (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mi.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "chf.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pvd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cevd.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dementia.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cpd.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rheumd.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pud.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mld.cum_1 (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diab.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "diabwc.cum_1 (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hp.cum_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rend.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "canc.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "msld.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "metacanc.cum_1 (InputLayer)     [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aids.cum_1 (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "visits_1 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 4027)         0           flatten_176[0][0]                \n",
      "                                                                 flatten_177[0][0]                \n",
      "                                                                 flatten_178[0][0]                \n",
      "                                                                 flatten_179[0][0]                \n",
      "                                                                 flatten_180[0][0]                \n",
      "                                                                 flatten_181[0][0]                \n",
      "                                                                 flatten_182[0][0]                \n",
      "                                                                 flatten_183[0][0]                \n",
      "                                                                 flatten_184[0][0]                \n",
      "                                                                 flatten_185[0][0]                \n",
      "                                                                 flatten_186[0][0]                \n",
      "                                                                 flatten_187[0][0]                \n",
      "                                                                 flatten_188[0][0]                \n",
      "                                                                 flatten_189[0][0]                \n",
      "                                                                 flatten_190[0][0]                \n",
      "                                                                 flatten_191[0][0]                \n",
      "                                                                 flatten_192[0][0]                \n",
      "                                                                 flatten_193[0][0]                \n",
      "                                                                 flatten_194[0][0]                \n",
      "                                                                 flatten_195[0][0]                \n",
      "                                                                 flatten_196[0][0]                \n",
      "                                                                 flatten_197[0][0]                \n",
      "                                                                 flatten_198[0][0]                \n",
      "                                                                 flatten_199[0][0]                \n",
      "                                                                 flatten_200[0][0]                \n",
      "                                                                 flatten_201[0][0]                \n",
      "                                                                 flatten_202[0][0]                \n",
      "                                                                 flatten_203[0][0]                \n",
      "                                                                 flatten_204[0][0]                \n",
      "                                                                 flatten_205[0][0]                \n",
      "                                                                 flatten_206[0][0]                \n",
      "                                                                 flatten_207[0][0]                \n",
      "                                                                 flatten_208[0][0]                \n",
      "                                                                 flatten_209[0][0]                \n",
      "                                                                 flatten_210[0][0]                \n",
      "                                                                 flatten_211[0][0]                \n",
      "                                                                 flatten_212[0][0]                \n",
      "                                                                 flatten_213[0][0]                \n",
      "                                                                 flatten_214[0][0]                \n",
      "                                                                 flatten_215[0][0]                \n",
      "                                                                 flatten_216[0][0]                \n",
      "                                                                 flatten_217[0][0]                \n",
      "                                                                 flatten_218[0][0]                \n",
      "                                                                 flatten_219[0][0]                \n",
      "                                                                 flatten_220[0][0]                \n",
      "                                                                 flatten_221[0][0]                \n",
      "                                                                 flatten_222[0][0]                \n",
      "                                                                 flatten_223[0][0]                \n",
      "                                                                 flatten_224[0][0]                \n",
      "                                                                 flatten_225[0][0]                \n",
      "                                                                 flatten_226[0][0]                \n",
      "                                                                 flatten_227[0][0]                \n",
      "                                                                 flatten_228[0][0]                \n",
      "                                                                 flatten_229[0][0]                \n",
      "                                                                 flatten_230[0][0]                \n",
      "                                                                 flatten_231[0][0]                \n",
      "                                                                 flatten_232[0][0]                \n",
      "                                                                 flatten_233[0][0]                \n",
      "                                                                 flatten_234[0][0]                \n",
      "                                                                 flatten_235[0][0]                \n",
      "                                                                 flatten_236[0][0]                \n",
      "                                                                 flatten_237[0][0]                \n",
      "                                                                 TIME_DXDATE_TESTDATE[0][0]       \n",
      "                                                                 time_window_index_year[0][0]     \n",
      "                                                                 VL[0][0]                         \n",
      "                                                                 Months_to_ini_VS[0][0]           \n",
      "                                                                 VR_N[0][0]                       \n",
      "                                                                 prop_time[0][0]                  \n",
      "                                                                 dx_yr[0][0]                      \n",
      "                                                                 dx_mth[0][0]                     \n",
      "                                                                 age[0][0]                        \n",
      "                                                                 CD4_baseline[0][0]               \n",
      "                                                                 VL_baseline[0][0]                \n",
      "                                                                 mi.cum[0][0]                     \n",
      "                                                                 chf.cum[0][0]                    \n",
      "                                                                 pvd.cum[0][0]                    \n",
      "                                                                 cevd.cum[0][0]                   \n",
      "                                                                 dementia.cum[0][0]               \n",
      "                                                                 cpd.cum[0][0]                    \n",
      "                                                                 rheumd.cum[0][0]                 \n",
      "                                                                 pud.cum[0][0]                    \n",
      "                                                                 mld.cum[0][0]                    \n",
      "                                                                 diab.cum[0][0]                   \n",
      "                                                                 diabwc.cum[0][0]                 \n",
      "                                                                 hp.cum[0][0]                     \n",
      "                                                                 rend.cum[0][0]                   \n",
      "                                                                 canc.cum[0][0]                   \n",
      "                                                                 msld.cum[0][0]                   \n",
      "                                                                 metacanc.cum[0][0]               \n",
      "                                                                 aids.cum[0][0]                   \n",
      "                                                                 New_Diagnoses_Rate[0][0]         \n",
      "                                                                 PrEP_to_Need_Ratio[0][0]         \n",
      "                                                                 pcp_rate[0][0]                   \n",
      "                                                                 RPL_THEME1[0][0]                 \n",
      "                                                                 RPL_THEME2[0][0]                 \n",
      "                                                                 RPL_THEME3[0][0]                 \n",
      "                                                                 RPL_THEME4[0][0]                 \n",
      "                                                                 RPL_THEMES[0][0]                 \n",
      "                                                                 visits[0][0]                     \n",
      "                                                                 VL_1[0][0]                       \n",
      "                                                                 Months_to_ini_VS_1[0][0]         \n",
      "                                                                 VR_N_1[0][0]                     \n",
      "                                                                 prop_time_1[0][0]                \n",
      "                                                                 mi.cum_1[0][0]                   \n",
      "                                                                 chf.cum_1[0][0]                  \n",
      "                                                                 pvd.cum_1[0][0]                  \n",
      "                                                                 cevd.cum_1[0][0]                 \n",
      "                                                                 dementia.cum_1[0][0]             \n",
      "                                                                 cpd.cum_1[0][0]                  \n",
      "                                                                 rheumd.cum_1[0][0]               \n",
      "                                                                 pud.cum_1[0][0]                  \n",
      "                                                                 mld.cum_1[0][0]                  \n",
      "                                                                 diab.cum_1[0][0]                 \n",
      "                                                                 diabwc.cum_1[0][0]               \n",
      "                                                                 hp.cum_1[0][0]                   \n",
      "                                                                 rend.cum_1[0][0]                 \n",
      "                                                                 canc.cum_1[0][0]                 \n",
      "                                                                 msld.cum_1[0][0]                 \n",
      "                                                                 metacanc.cum_1[0][0]             \n",
      "                                                                 aids.cum_1[0][0]                 \n",
      "                                                                 visits_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 64)           257792      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64)           0           dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 64)           4160        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64)           0           dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "ple_layer_2 (PleLayer)          [(None, 16), (None,  5785        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "VS (Dense)                      (None, 1)            17          ple_layer_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "linkage (Dense)                 (None, 1)            17          ple_layer_2[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "retention (Dense)               (None, 1)            17          ple_layer_2[0][2]                \n",
      "==================================================================================================\n",
      "Total params: 283,148\n",
      "Trainable params: 283,148\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建模型，训练和评估\n",
    "model = build_ple(sparse_features,dense_features,sparse_max_len,embed_dim = 64,expert_dim = 16,\n",
    "          varlens_cols = varlen_features,varlens_max_len = varlens_max_len,dnn_hidden_units = (64,64),\n",
    "          n_task = 3,n_experts = [1,1,1],n_expert_share = 2,dnn_reg_l2 = 0.001,\n",
    "          drop_rate = 0.1,embedding_reg_l2 = 0.001,targets = target)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(adam, loss = 'binary_crossentropy' ,metrics = [\"accuracy\"],)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bacf6e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25/25 [==============================] - 13s 166ms/step - loss: 1871.6349 - VS_loss: 1003.0266 - linkage_loss: 249.8846 - retention_loss: 618.4240 - VS_accuracy: 0.6005 - linkage_accuracy: 0.5925 - retention_accuracy: 0.6945 - val_loss: 2194.8425 - val_VS_loss: 435.8506 - val_linkage_loss: 1372.0815 - val_retention_loss: 386.5444 - val_VS_accuracy: 0.8035 - val_linkage_accuracy: 0.6878 - val_retention_accuracy: 0.8189\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 822.6893 - VS_loss: 235.4770 - linkage_loss: 54.2323 - retention_loss: 532.5888 - VS_accuracy: 0.6716 - linkage_accuracy: 0.6028 - retention_accuracy: 0.6365 - val_loss: 207.5065 - val_VS_loss: 114.1879 - val_linkage_loss: 26.4861 - val_retention_loss: 66.4294 - val_VS_accuracy: 0.7099 - val_linkage_accuracy: 0.6513 - val_retention_accuracy: 0.8347\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 128.3707 - VS_loss: 90.0404 - linkage_loss: 9.6802 - retention_loss: 28.2863 - VS_accuracy: 0.6579 - linkage_accuracy: 0.6594 - retention_accuracy: 0.7963 - val_loss: 326.7338 - val_VS_loss: 325.1087 - val_linkage_loss: 0.6889 - val_retention_loss: 0.6140 - val_VS_accuracy: 0.8015 - val_linkage_accuracy: 0.6965 - val_retention_accuracy: 0.8350\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 127.0943 - VS_loss: 103.3145 - linkage_loss: 6.0964 - retention_loss: 17.3977 - VS_accuracy: 0.6586 - linkage_accuracy: 0.6892 - retention_accuracy: 0.7291 - val_loss: 167.2270 - val_VS_loss: 165.5578 - val_linkage_loss: 0.7723 - val_retention_loss: 0.6349 - val_VS_accuracy: 0.7793 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 126.0151 - VS_loss: 111.7624 - linkage_loss: 1.6053 - retention_loss: 12.3950 - VS_accuracy: 0.7028 - linkage_accuracy: 0.6970 - retention_accuracy: 0.8248 - val_loss: 112.4666 - val_VS_loss: 111.0333 - val_linkage_loss: 0.6446 - val_retention_loss: 0.5204 - val_VS_accuracy: 0.8086 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 18.7580 - VS_loss: 16.4074 - linkage_loss: 1.0289 - retention_loss: 1.0782 - VS_accuracy: 0.7103 - linkage_accuracy: 0.6975 - retention_accuracy: 0.8265 - val_loss: 2.5600 - val_VS_loss: 1.2428 - val_linkage_loss: 0.6298 - val_retention_loss: 0.4863 - val_VS_accuracy: 0.7218 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 2.9253 - VS_loss: 1.2913 - linkage_loss: 0.7362 - retention_loss: 0.7321 - VS_accuracy: 0.7407 - linkage_accuracy: 0.6986 - retention_accuracy: 0.8292 - val_loss: 1.6974 - val_VS_loss: 0.4746 - val_linkage_loss: 0.6180 - val_retention_loss: 0.4732 - val_VS_accuracy: 0.8204 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 2.5386 - VS_loss: 1.2769 - linkage_loss: 0.6348 - retention_loss: 0.5130 - VS_accuracy: 0.7658 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8302 - val_loss: 1.6510 - val_VS_loss: 0.4745 - val_linkage_loss: 0.6158 - val_retention_loss: 0.4617 - val_VS_accuracy: 0.8216 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 2.0650 - VS_loss: 0.7390 - linkage_loss: 0.6569 - retention_loss: 0.5773 - VS_accuracy: 0.7808 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8303 - val_loss: 1.6297 - val_VS_loss: 0.4730 - val_linkage_loss: 0.6150 - val_retention_loss: 0.4558 - val_VS_accuracy: 0.8229 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 1.8130 - VS_loss: 0.5801 - linkage_loss: 0.6247 - retention_loss: 0.5251 - VS_accuracy: 0.7821 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8307 - val_loss: 1.6174 - val_VS_loss: 0.4708 - val_linkage_loss: 0.6147 - val_retention_loss: 0.4514 - val_VS_accuracy: 0.8219 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 1.7538 - VS_loss: 0.5451 - linkage_loss: 0.6342 - retention_loss: 0.4953 - VS_accuracy: 0.7894 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8308 - val_loss: 1.6031 - val_VS_loss: 0.4628 - val_linkage_loss: 0.6145 - val_retention_loss: 0.4478 - val_VS_accuracy: 0.8250 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.7263 - VS_loss: 0.5437 - linkage_loss: 0.6208 - retention_loss: 0.4845 - VS_accuracy: 0.7939 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8307 - val_loss: 1.5938 - val_VS_loss: 0.4577 - val_linkage_loss: 0.6143 - val_retention_loss: 0.4451 - val_VS_accuracy: 0.8263 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.7382 - VS_loss: 0.5606 - linkage_loss: 0.6191 - retention_loss: 0.4823 - VS_accuracy: 0.7965 - linkage_accuracy: 0.6991 - retention_accuracy: 0.8309 - val_loss: 1.5835 - val_VS_loss: 0.4506 - val_linkage_loss: 0.6142 - val_retention_loss: 0.4429 - val_VS_accuracy: 0.8298 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 1.7140 - VS_loss: 0.5528 - linkage_loss: 0.6191 - retention_loss: 0.4664 - VS_accuracy: 0.8026 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8311 - val_loss: 1.5765 - val_VS_loss: 0.4462 - val_linkage_loss: 0.6141 - val_retention_loss: 0.4410 - val_VS_accuracy: 0.8314 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 1.6852 - VS_loss: 0.5208 - linkage_loss: 0.6212 - retention_loss: 0.4681 - VS_accuracy: 0.8102 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8308 - val_loss: 1.5719 - val_VS_loss: 0.4430 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4400 - val_VS_accuracy: 0.8335 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.6309 - VS_loss: 0.4766 - linkage_loss: 0.6209 - retention_loss: 0.4587 - VS_accuracy: 0.8137 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8310 - val_loss: 1.5650 - val_VS_loss: 0.4376 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4390 - val_VS_accuracy: 0.8357 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.6300 - VS_loss: 0.4788 - linkage_loss: 0.6146 - retention_loss: 0.4623 - VS_accuracy: 0.8179 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8310 - val_loss: 1.5603 - val_VS_loss: 0.4338 - val_linkage_loss: 0.6140 - val_retention_loss: 0.4384 - val_VS_accuracy: 0.8369 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.8106 - VS_loss: 0.4942 - linkage_loss: 0.6362 - retention_loss: 0.6062 - VS_accuracy: 0.8200 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8311 - val_loss: 1.5559 - val_VS_loss: 0.4302 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4380 - val_VS_accuracy: 0.8384 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 1.6632 - VS_loss: 0.4903 - linkage_loss: 0.6141 - retention_loss: 0.4853 - VS_accuracy: 0.8221 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8310 - val_loss: 1.5580 - val_VS_loss: 0.4331 - val_linkage_loss: 0.6139 - val_retention_loss: 0.4377 - val_VS_accuracy: 0.8365 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 1.6595 - VS_loss: 0.4740 - linkage_loss: 0.6202 - retention_loss: 0.4921 - VS_accuracy: 0.8181 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8306 - val_loss: 1.5570 - val_VS_loss: 0.4326 - val_linkage_loss: 0.6138 - val_retention_loss: 0.4376 - val_VS_accuracy: 0.8368 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.6382 - VS_loss: 0.4578 - linkage_loss: 0.6191 - retention_loss: 0.4883 - VS_accuracy: 0.8229 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8311 - val_loss: 1.5485 - val_VS_loss: 0.4245 - val_linkage_loss: 0.6138 - val_retention_loss: 0.4374 - val_VS_accuracy: 0.8416 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 1.6374 - VS_loss: 0.4408 - linkage_loss: 0.6150 - retention_loss: 0.5089 - VS_accuracy: 0.8261 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8311 - val_loss: 1.5446 - val_VS_loss: 0.4212 - val_linkage_loss: 0.6137 - val_retention_loss: 0.4373 - val_VS_accuracy: 0.8431 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.5841 - VS_loss: 0.4355 - linkage_loss: 0.6130 - retention_loss: 0.4632 - VS_accuracy: 0.8314 - linkage_accuracy: 0.6992 - retention_accuracy: 0.8309 - val_loss: 1.5322 - val_VS_loss: 0.4092 - val_linkage_loss: 0.6135 - val_retention_loss: 0.4373 - val_VS_accuracy: 0.8499 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 2s 67ms/step - loss: 1.5707 - VS_loss: 0.4245 - linkage_loss: 0.6140 - retention_loss: 0.4602 - VS_accuracy: 0.8390 - linkage_accuracy: 0.6993 - retention_accuracy: 0.8311 - val_loss: 1.5172 - val_VS_loss: 0.3948 - val_linkage_loss: 0.6134 - val_retention_loss: 0.4371 - val_VS_accuracy: 0.8572 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 1.5586 - VS_loss: 0.4156 - linkage_loss: 0.6142 - retention_loss: 0.4571 - VS_accuracy: 0.8472 - linkage_accuracy: 0.6994 - retention_accuracy: 0.8313 - val_loss: 1.5057 - val_VS_loss: 0.3837 - val_linkage_loss: 0.6134 - val_retention_loss: 0.4370 - val_VS_accuracy: 0.8638 - val_linkage_accuracy: 0.6964 - val_retention_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_model_input, train_labels,validation_data = (val_model_input,val_labels),\n",
    "                    batch_size=1000, epochs=25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "836081dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.7822732 ],\n",
       "        [0.78229797],\n",
       "        [0.84526813],\n",
       "        ...,\n",
       "        [0.84526813],\n",
       "        [0.84526813],\n",
       "        [0.827006  ]], dtype=float32),\n",
       " array([[0.7036179],\n",
       "        [0.7036938],\n",
       "        [0.693956 ],\n",
       "        ...,\n",
       "        [0.693956 ],\n",
       "        [0.693956 ],\n",
       "        [0.697632 ]], dtype=float32),\n",
       " array([[0.81969744],\n",
       "        [0.81991976],\n",
       "        [0.84267193],\n",
       "        ...,\n",
       "        [0.84267193],\n",
       "        [0.84267193],\n",
       "        [0.83497804]], dtype=float32)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_model_input)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18425062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8799652432969215\n",
      "0.7671300893743793\n",
      "0.8259682224428997\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_labels[0], (pred[0] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[1], (pred[1] > 0.5).astype(int)))\n",
    "print(accuracy_score(test_labels[2], (pred[2] > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "130118d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7557411274414134\n",
      "0.5263010105505759\n",
      "0.49108132484530875\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(test_labels[0], pred[0]))\n",
    "print(roc_auc_score(test_labels[1], pred[1]))\n",
    "print(roc_auc_score(test_labels[2], pred[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d6e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tfgpu] *",
   "language": "python",
   "name": "conda-env-.conda-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
